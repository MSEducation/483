[[Googlebot]]

CATEGORIES: Google software, Web crawlers, Bots

Googlebot is the search bot software used by Google, which collects documents from the web to build a searchable index for the Google Search engine.
If a webmaster wishes to restrict the information on their site available to a Googlebot, or another well-behaved spider, they can do so with the appropriate directives in a robots.txt file,[tpl]cite web|title=Webmaster Tools |url=http://www.google.co.uk/intl/en_uk/webmasters/bot.html [/tpl] or by adding the meta tag  to the web page. Googlebot requests to Web servers are identifiable by a user-agent string containing "Googlebot" and a host address containing "googlebot.com".Exact Googlebot client info can be found in Google-cached copies of pages which display such data to visitors. For example, see http://web.archive.org/web/19991128232321/http://ipid.shat.net/
Currently, Googlebot follows HREF links and SRC links.  There is increasing evidence Googlebot can execute JavaScript and parse content generated by Ajax calls as well.[tpl]cite web|title=Googlebot makes POST requests via AJAX |url=http://www.thumbtack.com/engineering/googlebot-makes-post-requests-via-ajax/[/tpl][tpl]cite web|title=Google, the Jig is Up! Googlebot is actually a browser...|url=http://www.distilled.net/blog/seo/google-stop-playing-the-jig-is-still-up-guest-post/[/tpl] There are many theories regarding how advanced Googlebot's ability is to process JavaScript, with opinions ranging from minimal ability derived from custom interpreters.[tpl]cite web|title=Googlebot's Javascript Interpreter: A Diagnostic|url=http://www.thegooglecache.com/white-hat-seo/googlebots-javascript-interpreter-a-diagnostic/[/tpl][tpl]cite web|title=Googlebot is Chrome|url=http://ipullrank.com/googlebot-is-chrome/[/tpl] Googlebot discovers pages by harvesting all of the links on every page it finds. It then follows these links to other web pages. New web pages must be linked to from other known pages on the web in order to be crawled and indexed or manually submitted by the webmaster.
A problem which webmasters have often noted with the Googlebot is that it takes up an enormous amount of bandwidth.[tpl]Citation needed|date=March 2011[/tpl]  This can cause websites to exceed their bandwidth limit and be taken down temporarily. This is especially troublesome for mirror sites which host many gigabytes of data. Google provides "Webmaster Tools" that allow website owners to throttle the crawl rate.[tpl]cite web|url=https://www.google.com/webmasters/|title=Google - Webmasters|publisher=Google.com |date= |accessdate=2012-12-15[/tpl]

==References==

==External links==


