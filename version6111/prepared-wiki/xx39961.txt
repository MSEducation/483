[[Lagrange multiplier]]

CATEGORIES: Multivariable calculus, Mathematical optimization, Mathematical and quantitative methods (economics)

In mathematical optimization, the method of Lagrange multipliers (named after Joseph Louis Lagrange) is a strategy for finding the local maxima and minima of a function subject to equality constraints.
For instance (see Figure 1), consider the optimization problem
We need both [tpl]mvar|f[/tpl] and [tpl]mvar|g[/tpl] to have continuous first partial derivatives.  We introduce a new variable ([tpl]mvar|λ[/tpl]) called a Lagrange multiplier and study the Lagrange function (or Lagrangian) defined by
where the [tpl]mvar|λ[/tpl] term may be either added or subtracted. If [tpl]math|f(x0, y0)[/tpl] is a maximum of [tpl]math|f(x, y)[/tpl] for the original constrained problem, then there exists [tpl]math|λ0[/tpl] such that [tpl]math|(x0, y0, λ0)[/tpl] is a stationary point for the Lagrange function (stationary points are those points where the partial derivatives of [tpl]mvar|Λ[/tpl] are zero, i.e., [tpl]math|∇Λ [tpl]=[/tpl] 0[/tpl]). However, not all stationary points yield a solution of the original problem. Thus, the method of Lagrange multipliers yields a necessary condition for optimality in constrained problems.[tpl]cite book  | last = Bertsekas  | first = Dimitri P.| authorlink = Dimitri P. Bertsekas | title = Nonlinear Programming| edition = Second  | publisher = Athena Scientific | year = 1999  | location = Cambridge, MA.  | isbn = 1-886529-00-0 [/tpl][tpl]springer | id=Lagrange_multipliers | title=Lagrange multipliers| first=I.B. | last=Vapnyarskii [/tpl].[ref]
[tpl]cite book|last1=Hiriart-Urruty|first1=Jean-Baptiste|last2=Lemaréchal|first2=Claude|chapter=XII Abstract duality for practitioners|title=Convex analysis and minimization algorithms, Volume II: Advanced theory and bundle methods|series=Grundlehren der Mathematischen Wissenschaften Principles of Mathematical Sciences| volume=306 |publisher=Springer-Verlag |location=Berlin|year=1993|pages=136–193 (and Bibliographical comments on pp. 334–335)| isbn=3-540-56852-2|mr=1295240|authorlink2=Claude Lemaréchal[/tpl][/ref] Sufficient conditions for a minimum or maximum also exist.

==Introduction==

One of the most common problems in calculus is that of finding maxima or minima (in general, "extrema") of a function, but it is often difficult to find a closed form for the function being extremized. Such difficulties often arise when one wishes to maximize or minimize a function subject to fixed outside conditions or constraints. The method of Lagrange multipliers is a powerful tool for solving this class of problems without the need to explicitly solve the conditions and use them to eliminate extra variables.
Consider the two-dimensional problem introduced above:
Lagrange multipliers relies on the intuition that at a maximum f(x, y) cannot be increasing in the direction of any neighboring point where [tpl]math|g [tpl]=[/tpl] c[/tpl]. If it were, we could walk along [tpl]math|g [tpl]=[/tpl] c[/tpl] to get higher, meaning that the starting point wasn't actually the maximum.
We can visualize contours of [tpl]mvar|f[/tpl] given by [tpl]math|f(x, y) [tpl]=[/tpl] d[/tpl] for various values of [tpl]mvar|d[/tpl], and the contour of [tpl]mvar|g[/tpl] given by [tpl]math|g(x, y) [tpl]=[/tpl] c[/tpl].
Suppose we walk along the contour line with [tpl]math|g [tpl]=[/tpl] c[/tpl]. We are interested in finding points where [tpl]mvar|f[/tpl] does not change as we walk, since these points might be maxima. There are two ways this could happen: First, we could be following a contour line of [tpl]mvar|f[/tpl], since by definition [tpl]mvar|f[/tpl] does not change as we walk along its contour lines. This would mean that the contour lines of [tpl]mvar|f[/tpl] and [tpl]mvar|g[/tpl] are parallel here. The second possibility is that we have reached a "level" part of [tpl]mvar|f[/tpl], meaning that [tpl]mvar|f[/tpl] does not change in any direction.
To check the first possibility, notice that since the gradient of a function is perpendicular to the contour lines, the contour lines of [tpl]mvar|f[/tpl] and [tpl]mvar|g[/tpl]  are parallel if and only if the gradients of [tpl]mvar|f[/tpl] and [tpl]mvar|g[/tpl] are parallel. Thus we want points [tpl]math|(x, y)[/tpl] where [tpl]math|g(x, y) [tpl]=[/tpl] c[/tpl] and
for some [tpl]mvar|λ[/tpl]
where
are the respective gradients. The constant [tpl]mvar|λ[/tpl] is required because although the two gradient vectors are parallel, the magnitudes of the gradient vectors are generally not equal. (The negative is traditional). This constant is called the Lagrange multiplier.
Notice that this method also solves the second possibility: if [tpl]mvar|f[/tpl] is level, then its gradient is zero, and setting [tpl]math|λ [tpl]=[/tpl] 0[/tpl] is a solution regardless of [tpl]mvar|g[/tpl].
To incorporate these conditions into one equation, we introduce an auxiliary function
and solve
The constrained extrema of [tpl]mvar|f[/tpl] are critical points of the Lagrangian [tpl]mvar|Λ[/tpl], but they are not local extrema of [tpl]mvar|Λ[/tpl] (see Example 2 below).
One may reformulate the Lagrangian as a Hamiltonian, in which case the solutions are local minima for the Hamiltonian. This is done in optimal control theory, in the form of Pontryagin's minimum principle.
The fact that solutions of the Lagrangian are not necessarily extrema also poses difficulties for numerical optimization. This can be addressed by computing the magnitude of the gradient, as the zeros of the magnitude are necessarily local minima, as illustrated in the numerical optimization example.

==Handling multiple constraints==

