</ref> would disapprove of government filtering viewpoints on moral or political issues, agreeing that this could become support for [[propaganda]]. Many<ref>[tpl]cite news| url=http://news.bbc.co.uk/2/hi/technology/8517829.stm | work=BBC News | title=Google and Yahoo raise doubts over planned net filters | date=16 February 2010 | accessdate=30 April 2010[/tpl]</ref> would also find it unacceptable that an ISP, whether by law or by the ISP's own choice, should deploy such software without allowing the users to disable the filtering for their own connections. In the United States, the [[First Amendment to the United States Constitution|First Amendment]] has been cited in calls to criminalise forced internet censorship. (See [[Content-control software#Legal actions|section below]])
Without adequate governmental supervision, content-filtering software could enable private companies to censor as they please. (See Religious or political censorship, below). Government utilisation or encouragement of content-control software is a component of Internet Censorship (not to be confused with Internet Surveillance, in which content is monitored and not necessarilly restricted). The governments of countries such as the People's Republic of China, and Cuba are current examples of countries in which this ethically controversial activity is alleged to have taken place.

===Legal actions===

In 1998, a United States federal district court in Virginia ruled that the imposition of mandatory filtering in a public library violates the First Amendment of the U.S. Bill of Rights.[tpl]cite web|url=http://www.tomwbell.com/NetLaw/Ch04/Loudoun.html |title=Mainstream Loudon v. Board of Trustees of the Loudon County Library, 24 F. Supp. 2d 552 (E.D. Va. 1998) |publisher=Tomwbell.com |date= |accessdate=25 October 2009[/tpl]
In 1996 the US Congress passed the Communications Decency Act, banning indecency on the Internet. Civil liberties groups challenged the law under the First Amendment and in 1997 the Supreme Court ruled in their favor.[tpl]cite news |url=https://supreme.justia.com/cases/federal/us/521/844/case.html |title=Reno v. American Civil Liberties Union - 521 U.S. 844 (1997) |work=U.S. Reports |date=26 June 1997 |publisher=Justia.com[/tpl] Part of the civil liberties argument, especially from groups like the Electronic Frontier Foundation, was that parents who wanted to block sites could use their own content-filtering software, making government involvement unnecessary.[tpl]Citation needed|date=February 2007[/tpl]
In the late 1990s, groups such as the Censorware Project began reverse-engineering the content-control software and decrypting the blacklists to determine what kind of sites the software blocked. This led to legal action alleging violation of the "Cyber Patrol" license agreement.[tpl]cite web|url=http://w2.eff.org/legal/cases/Microsystems_v_Scandinavia_Online/?f=20000316_verif_complaint.html |title=Microsystems v Scandinavia Online, Verified Complaint |work=Civil No. 00CV10488, United States District Court, District of Massachusetts |author=Attorneys for Microsystems Software, Inc. and Mattel, Inc. |publisher=Electronic Frontier Foundation |date=15 March 2000 |accessdate=25 October 2009[/tpl] They discovered that such tools routinely blocked unobjectionable sites while also failing to block intended targets. (See Over-zealous filtering, below).
Some content-control software companies responded by claiming that their filtering criteria were backed by intensive manual checking. The companies' opponents argued, on the other hand, that performing the necessary checking would require resources greater than the companies possessed and that therefore their claims were not valid.[tpl]cite web |url=http://www7.nationalacademies.org/itas/whitepaper_1.html |title=Electronic Frontier Foundation White Paper 1 for NRC project on Tools and Strategies for Protecting Kids from Pornography and Their Applicability to Other Inappropriate Internet Content |author=Seth Finkelstein, Consulting Programmer; Lee Tien, Senior Staff Attorney, EFF |publisher=National Academy of Sciences |archiveurl = http://web.archive.org/web/20060419190143/http://www7.nationalacademies.org/itas/whitepaper_1.html |archivedate=19 April 2006[/tpl]
The Motion Picture Association successfully obtained a UK ruling enforcing ISPs to use content-control software to prevent copyright infringement by their subscribers.[tpl]cite news |title=Sky, Virgin Media Asked to Block Piracy Site Newzbin2|url=http://www.bbc.co.uk/news/technology-15653434 |publisher=BBC News |date=9 November 2011  |accessdate=26 March 2012 [/tpl]

===Religious, anti-religious, and political censorship===

Many types of content-control software have been shown to block sites based on the religious and political leanings of the company owners. Examples include blocking several religious sites[tpl]cite web|author=Kelly Wilson |url=http://hometown.aol.com/Mjolnir13/test.htm |title=Hometown Has Been Shutdown - People Connection Blog: AIM Community Network |publisher=Hometown.aol.com |date=2008-11-06 |accessdate=2009-10-25[/tpl][tpl]cite web|url=http://members.tripod.com/~Trifold/NOTICE.html |title=Notice!! |publisher=Members.tripod.com |date= |accessdate=2009-10-25[/tpl] (including the Web site of the Vatican), many political sites, and sites about gay/lesbians.[tpl]cite web |url=http://www.glaad.org/media/archive_detail.php?id=103& |title=http://www.glaad.org/media/archive_detail.php?id=103&[/tpl][tpl]Dead link|date=October 2009[/tpl] X-Stop was shown to block sites such as the Quaker web site, the National Journal of Sexual Orientation Law, the Heritage Foundation, and parts of The Ethical Spectacle.[tpl]cite web|url=http://www.spectacle.org/cs/burt.html |title=The Mind of a Censor |publisher=Spectacle.org |date= |accessdate=2009-10-25[/tpl] CYBERsitter blocks out sites like National Organization for Women.[tpl]cite web|url=http://www.spectacle.org/alert/peace.html |title=CYBERsitter: Where do we not want you to go today? |publisher=Spectacle.org |date= |accessdate=2009-10-25[/tpl] Nancy Willard, an academic researcher and attorney, pointed out that many U.S. public schools and libraries use the same filtering software that many Christian organizations use.[tpl]cite web|url=http://www.csriu.org/onlinedocs/documents/religious2.html |title=See: Filtering Software: The Religious Connection |publisher=Csriu.org |date= |accessdate=2009-10-25[/tpl] Cyber Patrol, a product developed by The Anti-Defamation League and Mattel's The Learning Company,[tpl]cite web|url=http://www.adl.org/presrele/mise_00/3081-00.asp |title=See: ADL and The Learning Company Develop Educational Software |publisher=adl.org |date= |accessdate=2011-08-26[/tpl] has been found to block not only political sites it deems to be engaging in 'hate speech' but also human rights web sites, such as Amnesty International's web page about Israel and gay-rights web sites, such as glaad.org.[tpl]cite web|url=http://www.peacefire.org/censorware/Cyber_Patrol/ |title=See: Cyber Patrol Examined |publisher=peacefire.org |date= |accessdate=2011-08-26[/tpl]

==Content labeling==

Content labeling may be considered another form of content-control software. In 1994, the Internet Content Rating Association (ICRA) — now part of the Family Online Safety Institute — developed a content rating system for online content providers. Using an online questionnaire a webmaster describes the nature of his web content. A small file is generated that contains a condensed, computer readable digest of this description that can then be used by content filtering software to block or allow that site.
ICRA labels come in a variety of formats.[tpl]cite web |url=http://www.fosi.org/icra/#tech |title=ICRA: Technical standards used |accessdate=2008-07-04 |work= |publisher=FOSI |date= [/tpl] These include the World Wide Web Consortium's Resource Description Framework (RDF) as well as Platform for Internet Content Selection (PICS) labels used by Microsoft's Internet Explorer Content Advisor.[tpl]cite web |url=http://www.microsoft.com/windows/ie/ie6/using/howto/security/contentadv/config.mspx |title=Browse the Web with Internet Explorer 6 and Content Advisor |accessdate= |work= |publisher=Microsoft |date=March 26, 2003 [/tpl]
ICRA labels are an example of self-labeling. Similarly, in 2006 the Association of Sites Advocating Child Protection (ASACP) initiated the Restricted to Adults self-labeling initiative. ASACP members were concerned that various forms of legislation being proposed in the United States were going to have the effect of forcing adult companies to label their content.[tpl]cite web |url=http://www.asacp.org/page.php?content=news&item=511 |title=ASACP Participates in Financial Coalition Against Child Pornography  |accessdate=2008-07-04 |work= |publisher= |date=November 20, 2007 [/tpl] The RTA label, unlike ICRA labels, does not require a webmaster to fill out a questionnaire or sign up to use. Like ICRA the RTA label is free. Both labels are recognized by a wide variety of content-control software.
The Voluntary Content Rating (VCR) system was devised by Solid Oak Software for their CYBERsitter filtering software, as an alternative to the PICS system, which some critics deemed too complex. It employs HTML metadata tags embedded within web page documents to specify the type of content contained in the document. Only two levels are specified, mature and adult, making the specification extremely simple.

==Use in public libraries==

===United States===

The use of Internet filters or content-control software varies widely in public libraries in the United States, since Internet use policies are established by the local library board. Many libraries adopted Internet filters after Congress conditioned the receipt of universal service discounts on the use of Internet filters through the Children's Internet Protection Act (CIPA). Other libraries do not install content control software, believing that acceptable use policies and educational efforts address the issue of children accessing age-inappropriate content while preserving adult users' right to freely access information. Some libraries use Internet filters on computers used by children only. Some libraries that employ content-control software allow the software to be deactivated on a case-by-case basis on application to a librarian; libraries that are subject to CIPA are required to have a policy that allows adults to request that the filter be disabled without having to explain the reason for their request.
Many legal scholars believe that a number of legal cases, in particular Reno v. American Civil Liberties Union, established that the use of content-control software in libraries is a violation of the First Amendment.[tpl]cite web |url=http://www.spectacle.org/cs/library.bak |title=Purchase of blocking software by public libraries is unconstitutional |accessdate= |last=Wallace |first=Jonathan D. |coauthors= |date=November 9, 1997 |work= |publisher=[/tpl] The Children's Internet Protection Act CIPA and the June 2003 case United States v. American Library Association found CIPA constitutional as a condition placed on the receipt of federal funding, stating that First Amendment concerns were dispelled by the law's provision that allowed adult library users to have the filtering software disabled, without having to explain the reasons for their request. The plurality decision left open a future "as-applied" Constitutional challenge, however. In November 2006, a lawsuit was filed against the North Central Regional Library District (NCRL) in Washington State for its policy of refusing to disable restrictions upon requests of adult patrons, but CIPA was not challenged in that matter.[tpl]cite web |url=http://www.aclu-wa.org/detail.cfm?id=557 |title=ACLU Suit Seeks Access to Information on Internet for Library Patrons |accessdate= |work= |publisher=ACLU of Washington |date=November 16, 2006 [/tpl] In May 2010, the Washington State Supreme Court provided an opinion after it was asked to certify a question referred by the United States District Court for the Eastern District of Washington: “Whether a public library, consistent with Article I, § 5 of the Washington Constitution, may filter Internet access for all patrons without disabling Web sites containing constitutionally-protected speech upon the request of an adult library patron.” The Washington State Supreme Court ruled that NCRL’s internet filtering policy did not violate Article I, Section 5 of the Washington State Constitution. The Court said: “It appears to us that NCRL’s filtering policy is reasonable and accords with its mission and these policies and is viewpoint neutral. It appears that no article I, section 5 content-based violation exists in this case. NCRL’s essential mission is to promote reading and lifelong learning. As NCRL maintains, it is reasonable to impose restrictions on Internet access in order to maintain an environment that is conducive to study and contemplative thought.” The case now returns to federal court.
In March 2007, Virginia passed a law similar to CIPA that requires public libraries receiving state funds to use content-control software. Like CIPA, the law requires libraries to disable filters for an adult library user when requested to do so by the user.[tpl]cite news |first=Michael |last=Sluss |authorlink= |coauthors= |title=Kaine signs library bill: The legislation requires public libraries to block obscene material with Internet filters |url=http://www.roanoke.com/politics/wb/wb/xp-109919 |work= |publisher=The Roanoke Times |date=March 23, 2007 |accessdate= [/tpl]

===Australia===

The Australian Internet Safety Advisory Body has information about "practical advice on Internet safety, parental control and filters for the protection of children, students and families" that also includes public libraries.[tpl]cite web |url=http://www.pcw.vic.edu.au/Our%20School/Parents%20Guide%20to%20Internet%20Safety.pdf |title=NetAlert: Parents Guide to Internet Safety |publisher=Australian Communications and Media Authority |date=2 August 2007 |accessdate=24 June 2013[/tpl]
NetAlert, the software made available free of charge by the Australian government, was allegedly cracked by a 16 year old student, Tom Wood, less than a week after its release in August 2007. Wood supposedly bypassed the $84 million filter in about half an hour to highlight problems with the government's approach to Internet content filtering.[tpl]cite news |url=http://www.smh.com.au/news/National/Teenager-cracks-govts-84m-porn-filter/2007/08/25/1187462562907.html |title=Teenager cracks govt's $84m porn filter |agency=Australian Associated Press (AAP) |work=Sydney Morning Herald |publisher=Fairfax Digital |date=25 August 2007 |accessdate=24 June 2013[/tpl]
The Australian Government has introduced legislation that requires ISP's to "restrict access to age restricted content (commercial MA15+ content and R18+ content) either hosted in Australia or provided from Australia" that was due to commence from 20 January 2008, known as Cleanfeed.[tpl]cite web |url=http://www.acma.gov.au/webwr/_assets/main/lib310563/ras_declaration_2007.pdf |title=Restricted Access Systems Declaration 2007 |publisher=Australian Communications and Media Authority (ACMA) |year=2007 |accessdate=24 June 2013[/tpl]
Cleanfeed is a proposed mandatory ISP level content filtration system. It was proposed by the Beazley led Australian Labor Party opposition in a 2006 press release, with the intention of protecting children who were vulnerable due to claimed parental computer illiteracy. It was announced on 31 December 2007 as a policy to be implemented by the Rudd ALP government, and initial tests in Tasmania have produced a 2008 report. Cleanfeed is funded in the current budget, and is moving towards an Expression of Interest for live testing with ISPs in 2008. Public opposition and criticism have emerged, led by the EFA and gaining irregular mainstream media attention, with a majority of Australians reportedly "strongly against" its implementation.[tpl]cite web|url=http://nocleanfeed.com/learn.html |title=Learn - No Clean Feed - Stop Internet Censorship in Australia |publisher=Electronic Frontiers Australia |date= |accessdate=25 October 2009[/tpl] Criticisms include its expense, inaccuracy (it will be impossible to ensure only illegal sites are blocked) and the fact that it will be compulsory, which can be seen as an intrusion on free speech rights. Another major criticism point has been that although the filter is claimed to stop certain materials, the underground rings dealing in such materials will not be affected. The filter might also provide a false sense of security for parents, who might supervise children less while using the Internet, achieving the exact opposite effect.[tpl]or|date=June 2013[/tpl] Cleanfeed is a responsibility of Senator Conroy's portfolio.

===Denmark===

In Denmark it is stated policy that it will "prevent inappropriate Internet sites from being accessed from children's libraries across Denmark."[tpl]cite web|url=http://www.prnewswire.com/cgi-bin/stories.pl?ACCT=104&STORY=/www/story/07-27-2006/0004404991&EDATE= |title=Danish Ministry of Culture Chooses SonicWALL CMS 2100 Content Filter to Keep Children's Libraries Free of Unacceptable Material |publisher=Prnewswire.com |date= |accessdate=2009-10-25[/tpl] "'It is important that every library in the country has the opportunity to protect children against pornographic material when they are using library computers. It is a main priority for me as Culture Minister to make sure children can surf the net safely at libraries,' states Brian Mikkelsen in a press-release of the Danish Ministry of Culture."[tpl]cite web|url=http://www.saferinternet.org/ww/en/pub/insafe/news/articles/0606/dk.htm |title=Danish Minister of Culture offers Internet filters to libraries |publisher=Saferinternet.org |date= |accessdate=2009-10-25[/tpl]

===United Kingdom===

==Bypassing filters==

Content filtering in general can "be bypassed entirely by tech-savvy individuals". Blocking content on circumvention advice "not...guarantee that users won't eventually be able to find a way around the filter."[tpl]cite web |url=http://www.cityvision.edu/wiki/understanding-content-filtering-faq-nonprofits |title=Understanding Content Filtering: An FAQ for Nonprofits |last=Satterfield |first=Brian |date=4 June 2007 |publisher=Techsoup.org |accessdate=24 June 2013[/tpl]
Some software may be bypassed successfully by using alternative protocols such as FTP or telnet or HTTPS, conducting searches in a different language, using a proxy server or a circumventor such as Psiphon. Also cached web pages returned by Google or other searches could bypass some controls as well. Web syndication services may provide alternate paths for content. Some of the more poorly-designed programs can be shut down by killing their processes: for example, in Microsoft Windows through the Windows Task Manager, or in Mac OS X using Force Quit or Activity Monitor. Numerous workarounds and counters to workarounds from content-control software creators exist.
Google services are often blocked by filters, but these may most often be bypassed by using https:// in place of http:// since content filtering software is not able to interpret content under secure connections (in this case SSL).
Many content filters have an option which allows authorized people to bypass the content filter. This is especially useful in environments where the computer is being supervised and the content filter is aggressively blocking Web sites that need to be accessed.[tpl]Citation needed|date=March 2009[/tpl]
An encrypted VPN can be used as means of bypassing content control software, especially if the content control software is installed on an Internet gateway or firewall.
Sometimes, the antivirus software with web protection may stop the content-control filter.[tpl]citation needed|date=June 2013[/tpl]

==Products and services==

Some ISPs offer parental control options. Some offer security software which includes parental controls. Mac OS X v10.4 offers parental controls for several applications (Mail, Finder, iChat, Safari & Dictionary). Microsoft's Windows Vista operating system also includes content-control software.
Content filtering technology exists in two major forms: application gateway or packet inspection. For HTTP access the application gateway is called a web-proxy or just a proxy. Such web-proxies can inspect both the initial request and the returned web page using arbitrarily complex rules and will not return any part of the page to the requester until a decision is made. In addition they can make substitutions in whole or for any part of the returned result. Packet inspection filters do not initially interfere with the connection to the server but inspect the data in the connection as it goes past, at some point the filter may decide that the connection is to be filtered and it will then disconnect it by injecting a TCP-Reset or similar faked packet. The two techniques can be used together with the packet filter monitoring a link until it sees an HTTP connection starting to an IP address that has content that needs filtering. The packet filter then redirects the connection to the web-proxy which can perform detailed filtering on the website without having to pass through all unfiltered connections. This combination is quite popular because it can significantly reduce the cost of the system.
Gateway-based content control software may be more difficult to bypass than desktop software as the user does not have physical access to the filtering device. However, many of the techniques in the Bypassing filters section still work.

==See also==

==References==

==External links==


