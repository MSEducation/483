[[Differential calculus]]

CATEGORIES: Differential calculus

In mathematics, differential calculus is a subfield of calculus concerned with the study of the rates at which quantities change. It is one of the two traditional divisions of calculus, the other being integral calculus.
The primary objects of study in differential calculus are the derivative of a function, related notions such as the differential, and their applications. The derivative of a function at a chosen input value describes the rate of change of the function near that input value.  The process of finding a derivative is called differentiation. Geometrically, the derivative at a point is the slope of the tangent line to the graph of the function at that point, provided that the derivative exists and is defined at that point. For a real-valued function of a single real variable, the derivative of a function at a point generally determines the best linear approximation to the function at that point. 
Differential calculus and integral calculus are connected by the fundamental theorem of calculus, which states that differentiation is the reverse process to integration.
Differentiation has applications to nearly all quantitative disciplines. For example, in physics, the derivative of the displacement of a moving body with respect to time is the velocity of the body, and the derivative of velocity with respect to time is acceleration. Newton's second law of motion states that the derivative of the momentum of a body equals the force applied to the body.  The reaction rate of a chemical reaction is a derivative. In operations research, derivatives determine the most efficient ways to transport materials and design factories. 
Derivatives are frequently used to find the maxima and minima of a function.  Equations involving derivatives are called differential equations and are fundamental in describing natural phenomena.  Derivatives and their generalizations appear in many fields of mathematics, such as complex analysis, functional analysis, differential geometry, measure theory and abstract algebra.

==The derivative==

Suppose that x and y are real numbers and that y is a function of x, that is, for every value of x, there is a corresponding value of y. This relationship can be written as y = f(x). If f(x) is the equation for a straight line, then there are two real numbers m and b such that [tpl]nobreak|y [tpl]=[/tpl] m x + b[/tpl]. m is called the slope and can be determined from the formula:
where the symbol Δ (the uppercase form of the Greek letter Delta) is an abbreviation for "change in". It follows that [tpl]nobreak|Δy [tpl]=[/tpl] m Δx[/tpl].
A general function is not a line, so it does not have a slope. The derivative of f at the point x is the slope of the linear approximation to f at the point x. It is usually denoted [tpl]nowrap|f ′(x)[/tpl] or dy/dx. Together with the value of f at x, the derivative of f determines the best linear approximation, or linearization, of f near the point x.  This latter property is usually taken as the definition of the derivative.
A closely related notion is the differential of a function.
When x and y are real variables, the derivative of f at x is the slope of the tangent line to the graph of f at x.  Because the source and target of f are one-dimensional, the derivative of f is a real number.  If x and y are vectors, then the best linear approximation to the graph of f depends on how f changes in several directions at once.  Taking the best linear approximation in a single direction determines a partial derivative, which is usually denoted ∂y/∂x.  The linearization of f in all directions at once is called the total derivative.

==History of differentiation==

The concept of a derivative in the sense of a tangent line is a very old one, familiar to Greek geometers such as 
Euclid (c. 300 BC), Archimedes (c. 287–212 BC) and Apollonius of Perga (c. 262–190 BC).See Euclid's Elements, The Archimedes Palimpsest and [tpl]MacTutor Biography|id=Apollonius|title=Apollonius of Perga[/tpl] Archimedes also introduced the use of infinitesimals, although these were primarily used to study areas and volumes rather than derivatives and tangents; see Archimedes' use of infinitesimals.
The use of infinitesimals to study rates of change can be found in Indian mathematics, perhaps as early as 500 AD, when the astronomer and mathematician Aryabhata (476–550) used infinitesimals to study the motion of the moon.[tpl]MacTutor Biography|id=Aryabhata_I|title=Aryabhata the Elder[/tpl] The use of infinitesimals to compute rates of change was developed significantly by Bhāskara II (1114–1185); indeed, it has been arguedIan G. Pearce. Bhaskaracharya II. that many of the key notions of differential calculus can be found in his work, such as "Rolle's theorem".[tpl]Cite journal|first=T. A. A.|last=Broadbent|title=Reviewed work(s): The History of Ancient Indian Mathematics by C. N. Srinivasiengar|journal=The Mathematical Gazette|volume=52|issue=381|date=October 1968|pages=307–8|doi=10.2307/3614212|jstor=3614212|last2=Kline|first2=M.|postscript=[tpl]inconsistent citations[/tpl][/tpl] The Persian mathematician, Sharaf al-Dīn al-Tūsī (1135–1213), was the first to discover the derivative of cubic polynomials, an important result in differential calculus;J. L. Berggren (1990). "Innovation and Tradition in Sharaf al-Din al-Tusi's Muadalat", Journal of the American Oriental Society 110 (2), p. 304-309. his Treatise on Equations developed concepts related to differential calculus, such as the derivative function and the maxima and minima of curves, in order to solve cubic equations which may not have positive solutions.[tpl]MacTutor|id=Al-Tusi_Sharaf|title=Sharaf al-Din al-Muzaffar al-Tusi[/tpl]
The modern development of calculus is usually credited to Isaac Newton (1643–1727) and Gottfried Leibniz (1646–1716), who provided independentNewton began his work in 1666 and Leibniz began his in 1676. However, Leibniz published his first paper in 1684, predating Newton's publication in 1693. It is possible that Leibniz saw drafts of Newton's work in 1673 or 1676, or that Newton made use of Leibniz's work to refine his own. Both Newton and Leibniz claimed that the other plagiarized their respective works. This resulted in a bitter controversy between the two men over who first invented calculus which shook the mathematical community in the early 18th century. and unified approaches to differentiation and derivatives. The key insight, however, that earned them this credit, was the fundamental theorem of calculus relating differentiation and integration: this rendered obsolete most previous methods for computing areas and volumes,This was a monumental achievement, even though a restricted version had been proven previously by James Gregory (1638–1675), and some key examples can be found in the work of Pierre de Fermat (1601–1665). which had not been significantly extended since the time of Ibn al-Haytham (Alhazen).Victor J. Katz (1995), "Ideas of Calculus in Islam and India", Mathematics Magazine 68 (3): 163-174 & 173-4 For their ideas on derivatives, both Newton and Leibniz built on significant earlier work by mathematicians such as Isaac Barrow (1630–1677), René Descartes (1596–1650), Christiaan Huygens (1629–1695), Blaise Pascal (1623–1662) and John Wallis (1616–1703). Isaac Barrow is generally given credit for the early development of the derivative.Eves, H. (1990). Nevertheless, Newton and Leibniz remain key figures in the history of differentiation, not least because Newton was the first to apply differentiation to theoretical physics, while Leibniz systematically developed much of the notation still used today.
Since the 17th century many mathematicians have contributed to the theory of differentiation. In the 19th century, calculus was put on a much more rigorous footing by mathematicians such as Augustin Louis Cauchy (1789–1857), Bernhard Riemann (1826–1866), and Karl Weierstrass (1815–1897). It was also during this period that the differentiation was generalized to Euclidean space and the complex plane.

==Applications of derivatives==

===Optimization===

If f is a differentiable function on R (or an open interval) and x is a local maximum or a local minimum of f, then the derivative of f at x is zero; points where [tpl]nobreak|f(x) [tpl]=[/tpl] 0[/tpl] are called critical points or stationary points (and the value of f at x is called a critical value). (The definition of a critical point is sometimes extended to include points where the derivative does not exist.) Conversely, a critical point x of f can be analysed by considering the second derivative of f at x:
This is called the second derivative test. An alternative approach, called the first derivative test, involves considering the sign of the f on each side of the critical point.
Taking derivatives and solving for critical points is therefore often a simple way to find local minima or maxima, which can be useful in optimization. By the extreme value theorem, a continuous function on a closed interval must attain its minimum and maximum values at least once. If the function is differentiable, the minima and maxima can only occur at critical points or endpoints.
This also has applications in graph sketching: once the local minima and maxima of a differentiable function have been found, a rough plot of the graph can be obtained from the observation that it will be either increasing or decreasing between critical points.
In higher dimensions, a critical point of a scalar valued function is a point at which the gradient is zero. The second derivative test can still be used to analyse critical points by considering the eigenvalues of the Hessian matrix of second partial derivatives of the function at the critical point. If all of the eigenvalues are positive, then the point is a local minimum; if all are negative, it is a local maximum.  If there are some positive and some negative eigenvalues, then the critical point is a saddle point, and if none of these cases hold (i.e., some of the eigenvalues are zero) then the test is inconclusive.

====Calculus of variations====

One example of an optimization problem is: Find the shortest curve between two points on a surface, assuming that the curve must also lie on the surface. If the surface is a plane, then the shortest curve is a line. But if the surface is, for example, egg-shaped, then the shortest path is not immediately clear. These paths are called geodesics, and one of the simplest problems in the calculus of variations is finding geodesics. Another example is: Find the smallest area surface filling in a closed curve in space. This surface is called a minimal surface and it, too, can be found using the calculus of variations.

===Physics===

Calculus is of vital importance in physics: many physical processes are described by equations involving derivatives, called differential equations. Physics is particularly concerned with the way quantities change and evolve over time, and the concept of the "time derivative" — the rate of change over time — is essential for the precise definition of several important concepts. In particular, the time derivatives of an object's position are significant in Newtonian physics:
For example, if an object's position on a line is given by
then the object's velocity is
and the object's acceleration is
which is constant.

===Differential equations===

A differential equation is a relation between a collection of functions and their derivatives.  An ordinary differential equation is a differential equation that relates functions of one variable to their derivatives with respect to that variable.  A partial differential equation is a differential equation that relates functions of more than one variable to their partial derivatives.  Differential equations arise naturally in the physical sciences, in mathematical modelling, and within mathematics itself.  For example, Newton's second law, which describes the relationship between acceleration and force, can be stated as the ordinary differential equation
The heat equation in one space variable, which describes how heat diffuses through a straight rod, is the partial differential equation
Here u(x,t) is the temperature of the rod at position x and time t and α is a constant that depends on how fast heat diffuses through the rod.

===Mean value theorem===

The mean value theorem gives a relationship between values of the derivative and values of the original function.  If f(x) is a real-valued function and a and b are numbers with 


