</ref> This XR film had three [[Photographic emulsion|emulsion]] layers, an upper layer having an [[Film speed#ASA|ASA]] speed rating of 400, a middle layer with an intermediate rating, and a lower layer with an ASA rating of 0.004. The film was processed in a manner similar to [[Color photography#"Modern" color film|color films]], and each layer produced a different color.<ref>C. W. Wyckoff. Experimental extended exposure response film. ''Society of Photographic Instrumentation Engineers Newsletter'', June–July, 1962, pp. 16-20.</ref> The dynamic range of this extended range film has been estimated as 1:10<sup>8</sup>.<ref>Michael Goesele, et al., "High Dynamic Range Techniques in Graphics: from Acquisition to Display", [http://www.mpi-inf.mpg.de/resources/tmo/EG05_HDRTutorial_Complete.pdf Eurographics 2005 Tutorial T7]</ref> It has been used to photograph nuclear explosions,<ref>[http://www.fas.org/irp/threat/mctl98-2/p2sec05.pdf ''The Militarily Critical Technologies List''] (1998), pages II-5-100 and II-5-107.</ref> for astronomical photography,<ref>Andrew T. Young and Harold Boeschenstein, Jr., ''Isotherms in the region of Proclus at a phase angle of 9.8 degrees'', Scientific Report No. 5, Harvard, College Observatory: Cambridge, Massachusetts, 1964.</ref> for spectrographic research,<ref>[tpl]cite journal |first=R. L. |last=Bryant |first2=G. J. |last2=Troup |first3=R. G. |last3=Turner |title=The use of a high-intensity-range photographic film for recording extended diffraction patterns and for spectrographic work |journal=Journal of Scientific Instruments |volume=42 |issue=2 |year=1965 |pages=116 |doi=10.1088/0950-7671/42/2/315 [/tpl]</ref> and for medical imaging.<ref>[tpl]cite journal |first=Leslie M. |last=Eber |first2=Haervey M. |last2=Greenberg |first3=John M. |last3=Cooke |first4=Richard |last4=Gorlin |title=Dynamic Changes in Left Ventricular Free Wall Thickness in the Human Heart |journal=Circulation |volume=39 |year=1969 |issue=4 |pages=455–464 |doi=10.1161/01.CIR.39.4.455 [/tpl]</ref> Wyckoff's detailed pictures of nuclear explosions appeared on the cover of ''[[Life magazine|Life]]'' magazine in the mid-1950s.

===Late-twentieth century===

The concept of neighborhood tone mapping was applied to video cameras by a group from the Technion in Israel led by Prof. Y.Y.Zeevi who filed for a patent on this concept in 1988.[tpl]Ref patent |country=US |status=application |number=5144442 |title=Wide dynamic range camera |pubdate=1992-09-01 |fdate=1991-11-21 |inventor=Ginosar, R., Hilsenrath, O., Zeevi, Y.[/tpl] In 1993 the first commercial medical camera was introduced that performed real time capturing of multiple images with different exposures, and producing an HDR video image, by the same group.[tpl]cite journal |author=Technion – Israel Institute of Technology |title= Adaptive Sensitivity |url=http://visl.technion.ac.il/research/isight/AS/ |year=1993[/tpl]
Modern HDR imaging uses a completely different approach, based on making a high-dynamic-range luminance or light map using only global image operations (across the entire image), and then tone mapping this result. Global HDR was first introduced in 1993"Compositing Multiple Pictures of the Same Scene", by Steve Mann, in IS&T's 46th Annual Conference, Cambridge, Massachusetts, May 9–14, 1993 resulting in a mathematical theory of differently exposed pictures of the same subject matter that was published in 1995 by Steve Mann and Rosalind Picard.[tpl]cite web |url=http://wearcam.org/is_t95_myversion.pdf |title=On Being ‘Undigital’ With Digital Cameras: Extending Dynamic Range By Combining Differently Exposed Pictures |author=S. Mann, R. W. Picard[/tpl]
The advent of consumer digital cameras produced a new demand for HDR imaging to improve the light response of digital camera sensors, which had a much smaller dynamic range than film. Steve Mann developed and patented the global-HDR method for producing digital images having extended dynamic range at the MIT Media Laboratory.[tpl]ref patent |country=US |number=5828793 |status=application |title=Method and apparatus for producing digital images having extended dynamic ranges |pubdate=1998-10-27 |fdate=1996-05-06 |inventor=Steve Mann[/tpl] Mann's method involved a two-step procedure: (1) generate one floating point image array by global-only image operations (operations that affect all pixels identically, without regard to their local neighborhoods); and then (2) convert this image array, using local neighborhood processing (tone-remapping, etc.), into an HDR image. The image array generated by the first step of Mann's process is called a lightspace image, lightspace picture, or radiance map. Another benefit of global-HDR imaging is that it provides access to the intermediate light or radiance map, which has been used for computer vision, and other image processing operations.
In 2005, Adobe Systems introduced several new features in Photoshop CS2 including Merge to HDR, 32 bit floating point image support, and HDR tone mapping.[tpl]cite web |url=http://www.luminous-landscape.com/tutorials/hdr.shtml |title=Merge to HDR in Photoshop CS2 |accessdate=2009-08-27[/tpl]

==Video==

While custom high-dynamic-range digital video solutions had been developed for industrial manufacturing during the 1980s, it was not until the early 2000s that several scholarly research efforts used consumer-grade sensors and cameras.[tpl]cite journal |pages=319–25 |doi=10.1145/1201775.882270 |chapter=High dynamic range video |title=ACM SIGGRAPH 2003 Papers – on SIGGRAPH '03 |year=2003 |last1=Kang |first1=Sing Bing |last2=Uyttendaele |first2=Matthew |last3=Winder |first3=Simon |last4=Szeliski |first4=Richard |isbn=1-58113-709-5[/tpl] A few companies such as RED[tpl]dead link|date=October 2011[/tpl] and Arri[tpl]dead link|date=October 2011[/tpl] have been developing digital sensors capable of a higher dynamic range. RED EPIC-X can capture HDRx images with a user selectable 1-3 stops of additional highlight latitude in the 'x' channel. The 'x' channel can be merged with the normal channel in post production software. With the advent of low-cost consumer digital cameras, many amateurs began posting tone mapped HDR time-lapse videos on the Internet, essentially a sequence of still photographs in quick succession. In 2010 the independent studio Soviet Montage produced an example of HDR video from disparately exposed video streams using a beam splitter and consumer grade HD video cameras.[tpl]cite web |title=HDR video accomplished using dual 5D Mark IIs, is exactly what it sounds like|url=http://www.engadget.com/2010/09/09/hdr-video-accomplished-using-dual-5d-mark-iis-is-exactly-what-i/|work=Engadget[/tpl] Similar methods have been described in the academic literature in 2001[tpl]cite web |title=A Real Time High Dynamic Range Light Probe|url=http://gl.ict.usc.edu/Research/rtlp/[/tpl] and 2007.[tpl]cite journal |pages=32–42 |doi=10.1109/MCG.2007.45 |title=Optical Splitting Trees for High-Precision Monocular Imaging |year=2007 |last1=McGuire |first1=Morgan |last2=Matusik |first2=Wojciech |last3=Pfister |first3=Hanspeter |last4=Chen |first4=Billy |last5=Hughes |first5=John |last6=Nayar |first6=Shree |journal=IEEE Computer Graphics and Applications |volume=27 |issue=2 |pmid=17388201[/tpl]
Modern movies have often been filmed with cameras featuring a higher dynamic range, and legacy movies can be upgraded even if manual intervention would be needed for some frames (as this happened in the past with black&white films’ upgrade to color). Also, special effects, especially those in which real and synthetic footage are seamlessly mixed, require both HDR shooting and rendering. HDR video is also needed in all applications in which capturing temporal aspects of changes in the scene demands high accuracy. This is especially important in monitoring of some industrial processes such as welding, predictive driver assistance systems in automotive industry, surveillance systems, to name just a few possible applications. HDR video can be also considered to speed up the image acquisition in all applications, in which a large number of static HDR images are needed, as for example in image-based methods in computer graphics. Finally, with the spread of TV sets with enhanced dynamic range, broadcasting HDR video may become important, but may take a long time to occur due to standardization issues. For this particular application, enhancing current low-dynamic range rendering (LDR) video signal to HDR by intelligent TV sets seems to be a more viable near-term solution.[tpl]cite book |title=High Dynamic Range Video |edition=First |author=Karol Myszkowski, Rafal Mantiuk, and Grzegorz Krawczyk |publisher=Morgan & Claypool |year=2008 |isbn=978-1-59829-215-2 |page=20 |url=http://books.google.com/?id=PVPggnBIC-wC&printsec=frontcover&dq=ISBN:+9781598292145#v=onepage&q=ISBN%3A%209781598292145&f=false[/tpl]

==Example==

This is an example of four standard dynamic range images that are combined to produce two resulting tone mapped images.
 
 
Image:StLouisArchMultExpEV-4.72.JPG|–4 stops
Image:StLouisArchMultExpEV-1.82.JPG|–2 stops
Image:StLouisArchMultExpEV+1.51.JPG|+2 stops
Image:StLouisArchMultExpEV+4.09.JPG|+4 stops

File:StLouisArchMultExpCDR.jpg|Simple contrast reduction
File:StLouisArchMultExpToneMapped.jpg|Local tone mapping

==HDR sensors==

More and more CMOS image sensors now have high dynamic range capability within the pixels themselves. Such pixels are intrinsically non-linear (by design) so that the wide dynamic range of the scene is non-linearly compressed into a smaller dynamic range electronic representation inside the pixel.[tpl]cite book |title=High Dynamic Range Imaging: Sensors and Architectures |edition=First |author=Arnaud Darmont |publisher=SPIE press |year=2012 |isbn=978-0-81948-830-5 |url=http://spie.org/x648.html?product_id=903927[/tpl] Such sensors are used in extreme dynamic range applications like welding or automotive.
Some other sensors designed for use in security applications can automatically provide two or more images for each frame, with changing exposure. For example a sensor for 30fps video will give out 60fps with the odd frames at a short exposure time and the even frames at a longer exposure time. Some of the sensor may even combine the two images on-chip so that a wider dynamic range without in-pixel compression is directly available to the user for display or processing.

==See also==

==References==


