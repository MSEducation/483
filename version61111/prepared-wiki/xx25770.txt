[[Eliezer Yudkowsky]]

CATEGORIES: 1979 births, Living people, American bloggers, Artificial intelligence researchers, Singularitarianism, Transhumanists, Fan fiction writers

Eliezer Shlomo Yudkowsky (born September 11, 1979[tpl]CN|date=February 2014[/tpl]) is an American blogger, writer, and advocate for Friendly artificial intelligence.

==Biography==

Yudkowsky is a resident of Berkeley, California. Largely self-educated Singularity Rising, by James Miller[tpl]rp|38[/tpl], he co-founded the nonprofit Machine Intelligence Research Institute (formerly the Singularity Institute for Artificial Intelligence) in 2000 and continues to be employed there as a full-time Research Fellow.[tpl]cite book|author=Kurzweil, Ray|title=The Singularity Is Near|publisher=Viking Penguin|location=New York, US|year=2005|isbn=0-670-03384-7|authorlink=Ray_Kurzweil[/tpl][tpl]rp|599[/tpl]

==Work==

Yudkowsky's interests focus on Artificial Intelligence theory for self-understanding, self-modification, and recursive self-improvement, and on artificial-intelligence architectures and decision theories for stable motivational structures (Friendly AI and Coherent Extrapolated Volition in particular).[tpl]rp|420[/tpl] Yudkowsky's most recent work is on decision theory for problems of self-modification and Newcomblike problems.[tpl]clarify|date=February 2014[/tpl]
Yudkowsky was, along with Robin Hanson, one of the principal contributors to the blog Overcoming Bias[tpl]cite web|url=http://www.overcomingbias.com/about|title=Overcoming Bias: About|publisher=Robin Hanson|accessdate=2012-02-01[/tpl][tpl]primary-inline|date=February 2014[/tpl] sponsored by the Future of Humanity Institute of Oxford University. In early 2009[tpl]CN|date=March 2014[/tpl], he helped to found LessWrong, a "community blog devoted to refining the art of human rationality".[tpl]rp|37[/tpl]
Yudkowsky contributed two chapters to Oxford philosopher Nick Bostrom's and Milan Ćirković's edited volume Global Catastrophic Risks.[tpl]cite book|editor1-last=Bostrom|editor1-first=Nick|editor1-link=Nick_Bostrom|editor2-last=Ćirković|editor2-first=Milan M.|title=Global Catastrophic Risks|publisher=Oxford University Press|location=Oxford, UK|year=2008|isbn=978-0-19-857050-9|pages=91–119, 308–345[/tpl]

===Fan fiction===

Yudkowsky has also written several works[tpl]CN|date=March 2014[/tpl] of science fiction and other fiction. His lengthy Harry Potter fan fiction story Harry Potter and the Methods of Rationality illustrates topics in cognitive science and rationality[tpl]rp|37[/tpl] (The New Yorker described it as "recasting the original story in an attempt to explain Harry's wizardry through the scientific method"pg 54, "No Death, No Taxes: The libertarian futurism of a Silicon Valley billionaire"), and has been reviewed by authors David Brin[ref][tpl]cite web|author=David Brin |url=http://davidbrin.blogspot.com/2010/06/secret-of-college-life-plus.html |title=CONTRARY BRIN: A secret of college life... plus controversies and science! |publisher=Davidbrin.blogspot.com |date=2010-06-21 |accessdate=2012-08-31[/tpl]

==References==

==Publications==

==Further reading==

==External links==


