[[Brain–computer interface]]

CATEGORIES: Brain–computer interfacing, Human–computer interaction, Neuroprosthetics, Neural engineering, User interface techniques, Virtual reality, DARPA projects

A brain–computer interface (BCI), often called a mind-machine interface (MMI), or sometimes called a direct neural interface (DNI), synthetic telepathy interface (STI) or a brain–machine interface (BMI), is a direct communication pathway between the brain and an external device. BCIs are often directed at assisting, augmenting, or repairing human cognitive or sensory-motor functions.
Research on BCIs began in the 1970s at the University of California Los Angeles (UCLA) under a grant from the National Science Foundation, followed by a contract from DARPA.[tpl]cite journal|pmid=4583653|doi=10.1146/annurev.bb.02.060173.001105|year=1973|last1=Vidal|first1=JJ|title=Toward direct brain-computer communication|volume=2|pages=157–80|journal=Annual review of biophysics and bioengineering[/tpl][tpl]cite journal|author=J. Vidal|title=Real-Time Detection of Brain Events in EEG|journal=IEEE Proceedings|year=1977|url=http://www.cs.ucla.edu/~vidal/Real_Time_Detection.pdf|volume=65|pages=633–641|doi=10.1109/PROC.1977.10542|issue=5[/tpl] The papers published after this research also mark the first appearance of the expression brain–computer interface in scientific literature.
The field of BCI research and development has since focused primarily on neuroprosthetics applications that aim at restoring damaged hearing, sight and movement. Thanks to the remarkable cortical plasticity of the brain, signals from implanted prostheses can, after adaptation, be handled by the brain like natural sensor or effector channels.[tpl]cite journal|pmid=10896180|year=2000|last1=Levine|first1=SP|last2=Huggins|first2=JE|last3=Bement|first3=SL|last4=Kushwaha|first4=RK|last5=Schuh|first5=LA|last6=Rohde|first6=MM|last7=Passaro|first7=EA|last8=Ross|first8=DA|last9=Elisevich|first9=KV|title=A direct brain interface based on event-related potentials|volume=8|issue=2|pages=180–5|journal=IEEE transactions on rehabilitation engineering : a publication of the IEEE Engineering in Medicine and Biology Society|doi=10.1109/86.847809|display-authors=9[/tpl]
Following years of animal experimentation, the first neuroprosthetic devices implanted in humans appeared in the mid-1990s.

==History==

The history of brain–computer interfaces (BCIs) starts with Hans Berger's discovery of the electrical activity of the human brain and the development of electroencephalography (EEG). In 1924 Berger was the first to record human brain activity by means of EEG. Berger was able to identify oscillatory activity in the brain by analyzing EEG traces. One wave he identified was the alpha wave (8–13 Hz), also known as Berger's wave.
Berger's first recording device was very rudimentary. He inserted silver wires under the scalps of his patients. These were later replaced by silver foils attached to the patients' head by rubber bandages. Berger connected these sensors to a Lippmann capillary electrometer, with disappointing results. More sophisticated measuring devices, such as the Siemens double-coil recording galvanometer, which displayed electric voltages as small as one ten thousandth of a volt, led to success.
Berger analyzed the interrelation of alternations in his EEG wave diagrams with brain diseases. EEGs permitted completely new possibilities for the research of human brain activities.

==BCI versus neuroprosthetics==

Neuroprosthetics is an area of neuroscience concerned with neural prostheses.  That is, using artificial devices to replace the function of impaired nervous systems and brain related problems, or of sensory organs. The most widely used neuroprosthetic device is the cochlear implant which, as of December 2010, had been implanted in approximately 220,000 people worldwide.[tpl]cite web|url= http://www.nidcd.nih.gov/health/hearing/pages/coch.aspx|title= Cochlear Implants|author= NIH Publication No. 11-4798|date= 1 March 2011|publisher= National Institute on Deafness and Other Communication Disorders[/tpl] There are also several neuroprosthetic devices that aim to restore vision, including retinal implants.
The difference between BCIs and neuroprosthetics is mostly in how the terms are used: neuroprosthetics typically connect the nervous system to a device, whereas BCIs usually connect the brain (or nervous system) with a computer system. Practical neuroprosthetics can be linked to any part of the nervous system—for example, peripheral nerves—while the term "BCI" usually designates a narrower class of systems which interface with the central nervous system.
The terms are sometimes, however, used interchangeably. Neuroprosthetics and BCIs seek to achieve the same aims, such as restoring sight, hearing, movement, ability to communicate, and even cognitive function. Both use similar experimental methods and surgical techniques.

==Animal BCI research==

Several laboratories have managed to record signals from monkey and rat cerebral cortices to operate BCIs to produce movement. Monkeys have navigated computer cursors on screen and commanded robotic arms to perform simple tasks simply by thinking about the task and seeing the visual feedback, but without any motor output.Miguel Nicolelis et al. (2001) Duke neurobiologist has developed system that allows monkeys to control robot arms via brain signals In May 2008 photographs that showed a monkey at the University of Pittsburgh Medical Center operating a robotic arm by thinking were published in a number of well known science journals and magazines.[tpl]cite web| last = Baum| first = Michele| title = Monkey Uses Brain Power to Feed Itself With Robotic Arm| publisher = Pitt Chronicle| date = 6 September 2008| url = http://www.chronicle.pitt.edu/?p=1478| accessdate = 2009-07-06[/tpl] Other research on cats has decoded their neural visual signals.

===Early work===

In 1969 the operant conditioning studies of Fetz and colleagues,
at the Regional Primate Research Center and Department of Physiology and Biophysics, University of Washington School of Medicine in Seattle, showed for the first time that monkeys could learn to control the deflection of a biofeedback meter arm with neural activity.[tpl]cite journal|doi=10.1126/science.163.3870.955|title=Operant Conditioning of Cortical Unit Activity|year=1969|last1=Fetz|first1=E. E.|journal=Science|volume=163|pmid=4974291|issue=3870|bibcode = 1969Sci...163..955F|pages=955–8 [/tpl] Similar work in the 1970s established that monkeys could quickly learn to voluntarily control the firing rates of individual and multiple neurons in the primary motor cortex if they were rewarded for generating appropriate patterns of neural activity.[tpl]cite journal|doi=10.1016/0014-4886(78)90252-2|pmid=101388|year=1978|last1=Schmidt|first1=EM|last2=McIntosh|first2=JS|last3=Durelli|first3=L|last4=Bak|first4=MJ|title=Fine control of operantly conditioned firing patterns of cortical neurons|volume=61|issue=2|pages=349–69|journal=Experimental neurology[/tpl]
Studies that developed algorithms to reconstruct movements from motor cortex neurons, which control movement, date back to the 1970s. In the 1980s, Apostolos Georgopoulos at Johns Hopkins University found a mathematical relationship between the electrical responses of single motor cortex neurons in rhesus macaque monkeys and the direction in which they moved their arms (based on a cosine function). He also found that dispersed groups of neurons, in different areas of the monkey's brains, collectively controlled motor commands, but was able to record the firings of neurons in only one area at a time, because of the technical limitations imposed by his equipment.[tpl]cite journal|doi=10.1126/science.2911737|title=Mental rotation of the neuronal population vector|year=1989|last1=Georgopoulos|first1=A.|last2=Lurito|first2=J.|last3=Petrides|first3=M|last4=Schwartz|first4=A.|last5=Massey|first5=J.|journal=Science|volume=243|pmid=2911737|issue=4888|bibcode = 1989Sci...243..234G|pages=234–6 [/tpl]
There has been rapid development in BCIs since the mid-1990s.[tpl]cite journal|pmid=16859758|url=http://www.cs.uu.nl/docs/vakken/mmpi/papers/Lebedev%202006.pdf|year=2006|last1=Lebedev|first1=MA|last2=Nicolelis|first2=MA|title=Brain-machine interfaces: past, present and future|volume=29|issue=9|pages=536–46|doi=10.1016/j.tins.2006.07.004|journal=Trends in neurosciences[/tpl] Several groups have been able to capture complex brain motor cortex signals by recording from neural ensembles (groups of neurons) and using these to control external devices.

===Prominent research successes===

====Kennedy and Yang Dan====

Phillip Kennedy (who later founded Neural Signals in 1987) and colleagues built the first intracortical brain–computer interface by implanting neurotrophic-cone electrodes into monkeys.[tpl]Citation needed|date=February 2012[/tpl]
thumb|Yang Dan and colleagues' recordings of cat vision using a BCI implanted in the lateral geniculate nucleus (top row: original image; bottom row: recording)  In 1999, researchers led by Yang Dan at the University of California, Berkeley decoded neuronal firings to reproduce images seen by cats. The team used an array of electrodes embedded in the thalamus (which integrates all of the brain’s sensory input) of sharp-eyed cats. Researchers targeted 177 brain cells in the thalamus lateral geniculate nucleus area, which decodes signals from the retina. The cats were shown eight short movies, and their neuron firings were recorded. Using mathematical filters, the researchers decoded the signals to generate movies of what the cats saw and were able to reconstruct recognizable scenes and moving objects.[tpl]cite journal|url=http://www.stanley.bme.gatech.edu/publications/stanley_dan_1999.pdf|pmid=10479703|year=1999|last1=Stanley|first1=GB|last2=Li|first2=FF|last3=Dan|first3=Y|title=Reconstruction of natural scenes from ensemble responses in the lateral geniculate nucleus|volume=19|issue=18|pages=8036–42|journal=Journal of Neuroscience[/tpl] Similar results in humans have since been achieved by researchers in Japan (see below).

====Nicolelis====

Miguel Nicolelis, a professor at Duke University, in Durham, North Carolina, has been a prominent proponent of using multiple electrodes spread over a greater area of the brain to obtain neuronal signals to drive a BCI. Such neural ensembles are said to reduce the variability in output produced by single electrodes, which could make it difficult to operate a BCI.
After conducting initial studies in rats during the 1990s, Nicolelis and his colleagues developed BCIs that decoded brain activity in owl monkeys and used the devices to reproduce monkey movements in robotic arms. Monkeys have advanced reaching and grasping abilities and good hand manipulation skills, making them ideal test subjects for this kind of work.
By 2000 the group succeeded in building a BCI that reproduced owl monkey movements while the monkey operated a joystick or reached for food.[tpl]cite journal|doi=10.1038/35042582|year=2000|last1=Nicolelis|first1=Miguel A. L.|last2=Wessberg|first2=Johan|last3=Stambaugh|first3=Christopher R.|last4=Kralik|first4=Jerald D.|last5=Beck|first5=Pamela D.|last6=Laubach|first6=Mark|last7=Chapin|first7=John K.|last8=Kim|first8=Jung|last9=Biggs|first9=S. James|journal=Nature|volume=408|pmid=11099043|title=Real-time prediction of hand trajectory by ensembles of cortical neurons in primates|issue=6810|pages=361–5|display-authors=9[/tpl] The BCI operated in real time and could also control a separate robot remotely over Internet protocol. But the monkeys could not see the arm moving and did not receive any feedback, a so-called open-loop BCI.
Later experiments by Nicolelis using rhesus monkeys succeeded in closing the feedback loop and reproduced monkey reaching and grasping movements in a robot arm. With their deeply cleft and furrowed brains, rhesus monkeys are considered to be better models for human neurophysiology than owl monkeys. The monkeys were trained to reach and grasp objects on a computer screen by manipulating a joystick while corresponding movements by a robot arm were hidden.[tpl]cite journal|pmid=14624244|year=2003|last1=Carmena|first1=JM|last2=Lebedev|first2=MA|last3=Crist|first3=RE|last4=O'Doherty|first4=JE|last5=Santucci|first5=DM|last6=Dimitrov|first6=DF|last7=Patil|first7=PG|last8=Henriquez|first8=CS|last9=Nicolelis|first9=MA|title=Learning to control a brain-machine interface for reaching and grasping by primates|volume=1|issue=2|pages=E42|doi=10.1371/journal.pbio.0000042|pmc=261882|journal=PLoS Biology|display-authors=9[/tpl][tpl]cite journal|doi=10.1523/JNEUROSCI.4088-04.2005|title=Cortical Ensemble Adaptation to Represent Velocity of an Artificial Actuator Controlled by a Brain-Machine Interface|year=2005|last1=Lebedev|first1=M. A.|journal=Journal of Neuroscience|volume=25|pmid=15888644|last2=Carmena|first2=JM|last3=O'Doherty|first3=JE|last4=Zacksenhouse|first4=M|last5=Henriquez|first5=CS|last6=Principe|first6=JC|last7=Nicolelis|first7=MA|issue=19|pages=4681–93[/tpl] The monkeys were later shown the robot directly and learned to control it by viewing its movements. The BCI used velocity predictions to control reaching movements and simultaneously predicted handgripping force.

====Donoghue, Schwartz and Andersen====

Other laboratories which have developed BCIs and algorithms that decode neuron signals include those run by John Donoghue at Brown University, Andrew Schwartz at the University of Pittsburgh and Richard Andersen at Caltech. These researchers have been able to produce working BCIs, even using recorded signals from far fewer neurons than did Nicolelis (15–30 neurons versus 50–200 neurons).
Donoghue's group reported training rhesus monkeys to use a BCI to track visual targets on a computer screen(closed-loop BCI) with or without assistance of a joystick.[tpl]cite journal|pmid=11894084|year=2002|last1=Serruya|first1=MD|last2=Hatsopoulos|first2=NG|last3=Paninski|first3=L|last4=Fellows|first4=MR|last5=Donoghue|first5=JP|title=Instant neural control of a movement signal|volume=416|issue=6877|pages=141–2|doi=10.1038/416141a|journal=Nature|bibcode = 2002Natur.416..141S [/tpl] Schwartz's group created a BCI for three-dimensional tracking in virtual reality and also reproduced BCI control in a robotic arm.[tpl]cite journal|doi=10.1126/science.1070291|title=Direct Cortical Control of 3D Neuroprosthetic Devices|year=2002|last1=Taylor|first1=D. M.|journal=Science|volume=296|pmid=12052948|last2=Tillery|first2=SI|last3=Schwartz|first3=AB|issue=5574|bibcode = 2002Sci...296.1829T|pages=1829–32 [/tpl] The same group also created headlines when they demonstrated that a monkey could feed itself pieces of fruit and marshmallows using a robotic arm controlled by the animal's own brain signals.Pitt team to build on brain-controlled arm, Pittsburgh Tribune Review, 5 September 2006.[tpl]YouTube|gnWSah4RD2E[/tpl][tpl]cite journal|pmid=18509337|url=http://www.nature.com/nature/journal/v453/n7198/full/nature06996.html|year=2008|last1=Velliste|first1=M|last2=Perel|first2=S|last3=Spalding|first3=MC|last4=Whitford|first4=AS|last5=Schwartz|first5=AB|title=Cortical control of a prosthetic arm for self-feeding|volume=453|pages=1098–101|doi=10.1038/nature06996|journal=Nature|issue=7198|bibcode = 2008Natur.453.1098V [/tpl]
Andersen's group used recordings of premovement activity from the posterior parietal cortex in their BCI, including signals created when experimental animals anticipated receiving a reward.[tpl]cite journal|doi=10.1126/science.1097938|title=Cognitive Control Signals for Neural Prosthetics|year=2004|last1=Musallam|first1=S.|journal=Science|volume=305|pmid=15247483|last2=Corneil|first2=BD|last3=Greger|first3=B|last4=Scherberger|first4=H|last5=Andersen|first5=RA|issue=5681|bibcode = 2004Sci...305..258M|pages=258–62 [/tpl]

====Other research====

In addition to predicting kinematic and kinetic parameters of limb movements, BCIs that predict electromyographic or electrical activity of the muscles of primates are being developed.[tpl]cite journal|doi=10.1111/j.1460-9568.2005.04320.x|title=Frontal and parietal cortical ensembles predict single-trial muscle activity during reaching movements in primates|year=2005|last1=Santucci|first1=David M.|last2=Kralik|first2=Jerald D.|last3=Lebedev|first3=Mikhail A.|last4=Nicolelis|first4=Miguel A. L.|journal=European Journal of Neuroscience|volume=22|pmid=16190906|issue=6|pages=1529–40[/tpl] Such BCIs could be used to restore mobility in paralyzed limbs by electrically stimulating muscles.
Miguel Nicolelis and colleagues demonstrated that the activity of large neural ensembles can predict arm position. This work made possible creation of BCIs that read arm movement intentions and translate them into movements of artificial actuators. Carmena and colleagues programmed the neural coding in a BCI that allowed a monkey to control reaching and grasping movements by a robotic arm. Lebedev and colleagues argued that brain networks reorganize to create a new representation of the robotic appendage in addition to the representation of the animal's own limbs.
The biggest impediment to BCI technology at present is the lack of a sensor modality that provides safe, accurate and robust access to brain signals. It is conceivable or even likely, however, that such a sensor will be developed within the next twenty years. The use of such a sensor should greatly expand the range of communication functions that can be provided using a BCI.
Development and implementation of a BCI system is complex and time consuming. In response to this problem, Dr. Gerwin Schalk has been developing a general-purpose system for BCI research, called BCI2000. BCI2000 has been in development since 2000 in a project led by the Brain–Computer Interface R&D Program at the Wadsworth Center of the New York State Department of Health in Albany, New York, USA.
A new 'wireless' approach uses light-gated ion channels such as Channelrhodopsin to control the activity of genetically defined subsets of neurons in vivo. In the context of a simple learning task, illumination of transfected cells in the somatosensory cortex influenced the decision making process of freely moving mice.[tpl]cite journal|pmid=18094685|year=2008|last1=Huber|first1=D|last2=Petreanu|first2=L|last3=Ghitani|first3=N|last4=Ranade|first4=S|last5=Hromádka|first5=T|last6=Mainen|first6=Z|last7=Svoboda|first7=K|title=Sparse optical microstimulation in barrel cortex drives learned behaviour in freely moving mice|volume=451|issue=7174|pages=61–4|doi=10.1038/nature06445|journal=Nature|bibcode = 2008Natur.451...61H|pmc=3425380 [/tpl]
The use of BMIs has also led to a deeper understanding of neural networks and the central nervous system. Research has shown that despite the inclination of neuroscientists to believe that neurons have the most effect when working together, single neurons can be conditioned through the use of BMIs to fire at a pattern that allows primates to control motor outputs. The use of BMIs has led to development of the single neuron insufficiency principle which states that even with a well tuned firing rate single neurons can only carry a narrow amount of information and therefore the highest level of accuracy is achieved by recording firings of the collective ensemble. Other principles discovered with the use of BMIs include the neuronal multitasking principle, the neuronal mass principle, the neural degeneracy principle, and the plasticity principle.Nicolelis, Miguel A. L., Lebedev, Mikhail A. “Principles of Neural Ensemble Physiology Underlying the Operation of Brain-Machine Interfaces.” Nature Reviews Neuroscience. Volume 10. Issue 7 (July 2009): Pages 530-540.

====The BCI Award====

The Annual BCI Research Award, endowed with 3,000 USD, is awarded in recognition of outstanding and innovative research in the field of Brain-Computer Interfaces. Each year, a renowned research laboratory is asked to judge the submitted projects and to award the prize. The jury consists of world-leading BCI experts recruited by the awarding laboratory. Following list consists the winners of the BCI Award:

==Human BCI research==

===Invasive BCIs===

====Vision====

Invasive BCI research has targeted repairing damaged sight and providing new functionality for people with paralysis. Invasive BCIs are implanted directly into the grey matter of the brain during neurosurgery. Because they lie in the grey matter, invasive devices produce the highest quality signals of BCI devices but are prone to scar-tissue build-up, causing the signal to become weaker, or even non-existent, as the body reacts to a foreign object in the brain.
In vision science, direct brain implants have been used to treat non-congenital (acquired) blindness. One of the first scientists to produce a working brain interface to restore sight was private researcher William Dobelle.
Dobelle's first prototype was implanted into "Jerry", a man blinded in adulthood, in 1978. A single-array BCI containing 68 electrodes was implanted onto Jerry’s visual cortex and succeeded in producing phosphenes, the sensation of seeing light. The system included cameras mounted on glasses to send signals to the implant. Initially, the implant allowed Jerry to see shades of grey in a limited field of vision at a low frame-rate. This also required him to be hooked up to a mainframe computer, but shrinking electronics and faster computers made his artificial eye more portable and now enable him to perform simple tasks unassisted.Vision quest, Wired Magazine, September 2002
In 2002, Jens Naumann, also blinded in adulthood, became the first in a series of 16 paying patients to receive Dobelle’s second generation implant, marking one of the earliest commercial uses of BCIs. The second generation device used a more sophisticated implant enabling better mapping of phosphenes into coherent vision. Phosphenes are spread out across the visual field in what researchers call "the starry-night effect". Immediately after his implant, Jens was able to use his imperfectly restored vision to drive an automobile slowly around the parking area of the research institute.Naumann, J. Search for Paradise: A Patient's Account of the Artificial Vision Experiment (2012), Xlibris Corporation, ISBN 1-479-7092-04 Unfortunately, Dr. Dobelle died in 2004obituary - Dr. William H. Dobelle before his processes and developments were documented. Subsequently, when Mr. Naumann and the other patients in the program began having problems with their vision, there was no relief and they eventually lost their "sight" again. Mr. Naumann wrote about his experience with Dr. Dobelle's work in Search for Paradise: A Patient's Account of the Artificial Vision Experiment and has returned to his farm in Southeast Ontario, Canada, to resume his normal activities.Mr. Jen Naumann's high-tech paradise lost

====Movement====

BCIs focusing on motor neuroprosthetics aim to either restore movement in individuals with paralysis or provide devices to assist them, such as interfaces with computers or robot arms.
Researchers at Emory University in Atlanta, led by Philip Kennedy and Roy Bakay, were first to install a brain implant in a human that produced signals of high enough quality to simulate movement. Their patient, Johnny Ray (1944–2002), suffered from ‘locked-in syndrome’ after suffering a brain-stem stroke in 1997. Ray’s implant was installed in 1998 and he lived long enough to start working with the implant, eventually learning to control a computer cursor; he died in 2002 of a brain aneurysm.[tpl]cite journal|doi=10.1097/00001756-199806010-00007|pmid=9665587|year=1998|last1=Kennedy|first1=PR|last2=Bakay|first2=RA|title=Restoration of neural output from a paralyzed patient by a direct brain connection|volume=9|issue=8|pages=1707–11|journal=NeuroReport[/tpl]
Tetraplegic Matt Nagle became the first person to control an artificial hand using a BCI in 2005 as part of the first nine-month human trial of Cyberkinetics’s BrainGate chip-implant. Implanted in Nagle’s right precentral gyrus (area of the motor cortex for arm movement), the 96-electrode BrainGate implant allowed Nagle to control a robotic arm by thinking about moving his hand as well as a computer cursor, lights and TV.[tpl]cite journal| author = Leigh R. Hochberg| coauthors = Mijail D. Serruya, Gerhard M. Friehs, Jon A. Mukand, Maryam Saleh, Abraham H. Caplan, Almut Branner, David Chen, Richard D. Penn and John P. Donoghue| date = 13 July 2006| title = Neuronal ensemble control of prosthetic devices by a human with tetraplegia| journal = Nature| volume = 442| issue =7099|pages = 164–171| doi = 10.1038/nature04970| pmid = 16838014| bibcode=2006Natur.442..164H[/tpl] One year later, professor Jonathan Wolpaw received the prize of the Altran Foundation for Innovation to develop a Brain Computer Interface with electrodes located on the surface of the skull, instead of directly in the brain.
More recently, research teams led by the Braingate group at Brown University[tpl]cite journal|last=Hochberg|first=Leigh R.|author2=et al.|year=2012|doi=10.1038/nature11076|bibcode = 2012Natur.485..372H |title=Reach and grasp by people with tetraplegia using a neurally controlled robotic arm|journal=Nature|volume=485|issue=7398|pages=372–5|pmid=22596161|pmc=3640850[/tpl] and a group led by University of Pittsburgh Medical Center,[tpl]cite journal|last=Collinger|first=Jennifer L.|author2=et al.|year=2013|doi=10.1016/S0140-6736(12)61816-9|title=High-performance neuroprosthetic control by an individual with tetraplegia|journal=The Lancet|volume=381|issue=9866|pages=557[/tpl] both in collaborations with the United States Department of Veterans Affairs, have demonstrated further success in direct control of robotic prosthetic limbs with many degrees of freedom using direct connections to arrays of neurons in the motor cortex of patients with tetraplegia.

===Partially invasive BCIs===

Partially invasive BCI devices are implanted inside the skull but rest outside the brain rather than within the grey matter. They produce better resolution signals than non-invasive BCIs where the bone tissue of the cranium deflects and deforms signals and have a lower risk of forming scar-tissue in the brain than fully invasive BCIs.
Electrocorticography (ECoG) measures the electrical activity of the brain taken from beneath the skull in a similar way to non-invasive electroencephalography (see below), but the electrodes are embedded in a thin plastic pad that is placed above the cortex, beneath the dura mater.Serruya MD, Donoghue JP. (2003) Chapter III: Design Principles of a Neuromotor Prosthetic Device in Neuroprosthetics: Theory and Practice, ed. Kenneth W. Horch, Gurpreet S. Dhillon. Imperial College Press. ECoG technologies were first trialed in humans in 2004 by Eric Leuthardt and Daniel Moran from Washington University in St Louis. In a later trial, the researchers enabled a teenage boy to play Space Invaders using his ECoG implant.Teenager moves video icons just by imagination, press release, Washington University in St Louis, 9 October 2006 This research indicates that control is rapid, requires minimal training, and may be an ideal tradeoff with regards to signal fidelity and level of invasiveness.
(Note: these electrodes had not been implanted in the patient with the intention of developing a BCI. The patient had been suffering from severe epilepsy and the electrodes were temporarily implanted to help his physicians localize seizure foci; the BCI researchers simply took advantage of this.)[tpl]Citation needed|date=September 2012[/tpl]
Signals can be either subdural or epidural, but are not taken from within the brain parenchyma itself. It has not been studied extensively until recently due to the limited access of subjects. Currently, the only manner to acquire the signal for study is through the use of patients requiring invasive monitoring for localization and resection of an epileptogenic focus.
ECoG is a very promising intermediate BCI modality because it has higher spatial resolution, better signal-to-noise ratio, wider frequency range, and less training requirements than scalp-recorded EEG, and at the same time has lower technical difficulty, lower clinical risk, and probably superior long-term stability than intracortical single-neuron recording. This feature profile and recent evidence of the high level of control with minimal training requirements shows potential for real world application for people with motor disabilities.[tpl]cite news |first= Takafumi|last= Yanagisawa|authorlink= |title=Electrocorticograpic Control of Prosthetic Arm in Paralyzed Patients |doi=10.1002/ana.22613 |quote= ECoG- Based BCI has advantage in signal and durability that are absolutely necessary for clinical application|work=American Neurological Association |year= 2011  |accessdate=19 January 2012 [/tpl][tpl]cite news |first= Pei|last= X|authorlink= |title=Decoding Vowels and Consonants in Spoken and Imagined Words Using Electrocorticographic Signals in Humans |pmid=21750369 |quote= Justin Williams, a biomedical engineer at the university, has already transformed the ECoG implant into a micro device that can be installed with a minimum of fuss.  It has been tested in animals for a long period of time – the micro ECoG stays in place and doesn’t seem to negatively affect the immune system.|work=J Neural Eng 046028th ser. 8.4  |year=2011  |accessdate=12 February 2012 [/tpl]
Light Reactive Imaging BCI devices are still in the realm of theory. These would involve implanting a laser inside the skull. The laser would be trained on a single neuron and the neuron's reflectance measured by a separate sensor. When the neuron fires, the laser light pattern and wavelengths it reflects would change slightly. This would allow researchers to monitor single neurons but require less contact with tissue and reduce the risk of scar-tissue build-up.[tpl]Citation needed|date=March 2012[/tpl]

===Non-invasive BCIs===

As well as invasive experiments, there have also been experiments in humans using non-invasive neuroimaging technologies as interfaces. Signals recorded in this way have been used to power muscle implants and restore partial movement in an experimental volunteer. Although they are easy to wear, non-invasive implants produce poor signal resolution because the skull dampens signals, dispersing and blurring the electromagnetic waves created by the neurons. Although the waves can still be detected it is more difficult to determine the area of the brain that created them or the actions of individual neurons.

====EEG====

=====Overview=====

Electroencephalography (EEG) is the most studied potential non-invasive interface, mainly due to its fine temporal resolution, ease of use, portability and low set-up cost. The technology is highly susceptible to noise however. Another substantial barrier to using EEG as a brain–computer interface is the extensive training required before users can work the technology. For example, in experiments beginning in the mid-1990s, Niels Birbaumer at the University of Tübingen in Germany trained severely paralysed people to self-regulate the slow cortical potentials in their EEG to such an extent that these signals could be used as a binary signal to control a computer cursor.Just short of telepathy: can you interact with the outside world if you can't even blink an eye?, Psychology Today, May–June 2003 (Birbaumer had earlier trained epileptics to prevent impending fits by controlling this low voltage wave.) The experiment saw ten patients trained to move a computer cursor by controlling their brainwaves. The process was slow, requiring more than an hour for patients to write 100 characters with the cursor, while training often took many months.
Another research parameter is the type of oscillatory activity that is measured. Birbaumer's later research with Jonathan Wolpaw at New York State University has focused on developing technology that would allow users to choose the brain signals they found easiest to operate a BCI, including mu and beta rhythms.
A further parameter is the method of feedback used and this is shown in studies of P300 signals. Patterns of P300 waves are generated involuntarily (stimulus-feedback) when people see something they recognize and may allow BCIs to decode categories of thoughts without training patients first. By contrast, the biofeedback methods described above require learning to control brainwaves so the resulting brain activity can be detected.
Lawrence Farwell and Emanuel Donchin developed an EEG-based brain–computer interface in the 1980s.[tpl]cite journal|pmid=2461285|year=1988|last1=Farwell|first1=LA|last2=Donchin|first2=E|title=Talking off the top of your head: toward a mental prosthesis utilizing event-related brain potentials|volume=70|issue=6|pages=510–23|journal=Electroencephalography and clinical neurophysiology|doi=10.1016/0013-4694(88)90149-6[/tpl] Their "mental prosthesis" used the P300 brainwave response to allow subjects, including one paralyzed Locked-In syndrome patient, to communicate words, letters and simple commands to a computer and thereby to speak through a speech synthesizer driven by the computer. A number of similar devices have been developed since then. In 2000, for example, research by Jessica Bayliss at the University of Rochester showed that volunteers wearing virtual reality helmets could control elements in a virtual world using their P300 EEG readings, including turning lights on and off and bringing a mock-up car to a stop.Press release, University of Rochester, 3 May 2000
While an EEG based brain-computer interface has been pursued extensively by a number of research labs, recent advancements made by Bin He and his team at the University of Minnesota suggest the potential of an EEG based brain-computer interface to accomplish tasks close to invasive brain-computer interface. Using advanced functional neuroimaging including BOLD functional MRI and EEG source imaging, Bin He and co-workers identified the co-variation and co-localization of electrophysiological and hemodynamic signals induced by motor imagination.[tpl]cite journal|pmid=19850134|year=2010|last1=Yuan|first1=H|title=Negative covariation between task-related responses in alpha/beta-band activity and BOLD in human sensorimotor cortex: an EEG and fMRI study of motor imagery and movements|volume=49|issue=3|pages=2596–2606|journal=NeuroImage|doi=10.1016/j.neuroimage.2009.10.028|last2=Liu|first2=Tao|last3=Szarkowski|first3=Rebecca|last4=Rios|first4=Cristina|last5=Ashe|first5=James|last6=He|first6=Bin|pmc=2818527[/tpl]
Refined by a neuroimaging approach and by a training protocol, Bin He and co-workers demonstrated the ability of a non-invasive EEG based brain-computer interface to control the flight of a virtual helicopter in 3-dimensional space, based upon motor imagination.[tpl]cite journal|pmid=22046274|year=2011|last1=Doud|first1=AJ|title=Continuous Three-Dimensional Control of a Virtual Helicopter Using a Motor Imagery Based Brain-Computer Interface|volume=6|issue=10|pages=e26322|journal=PLoS ONE|doi=10.1371/journal.pone.0026322|editor1-last=Gribble|editor1-first=Paul L|last2=Lucas|first2=John P.|last3=Pisansky|first3=Marc T.|last4=He|first4=Bin|pmc=3202533|bibcode = 2011PLoSO...626322D [/tpl] In June 2013 it was announced that Bin He had developed the technique to enable a remote-control helicopter to be guided through an obstacle course.[tpl]cite web |url=http://www.bbc.co.uk/news/science-environment-22764978 |title=Thought-guided helicopter takes off |publisher=bbc.co.uk |date=5 June 2013 |accessdate=5 June 2013[/tpl]
In addition to a brain-computer interface based on brain waves, as recorded from scalp EEG electrodes, Bin He and co-workers explored a virtual EEG signal-based brain-computer interface by first solving the EEG inverse problem and then used the resulting virtual EEG for brain-computer interface tasks. Well-controlled studies suggested the merits of such a source analysis based brain-computer interface.[tpl]cite journal|pmid=15876632|year=2004|last1=Qin|first1=L|title=Motor imagery classification by means of source analysis for brain-computer interface applications|volume=1|issue=3|pages=135–141|journal=Journal of Neural Engineering|doi=10.1088/1741-2560/1/3/002|last2=Ding|first2=Lei|last3=He|first3=Bin|bibcode = 2004JNEng...1..135Q [/tpl]

=====Dry active electrode arrays=====

In the early 1990s Babak Taheri, at University of California, Davis demonstrated the first single and also multichannel dry active electrode arrays using micro-machining. The single channel dry EEG electrode construction and results were published in 1994.[tpl]cite journal|doi=10.1016/0013-4694(94)90053-1|title=A dry electrode for EEG recording☆|year=1994|last1=Taheri|first1=B|last2=Knight|first2=R|last3=Smith|first3=R|journal=Electroencephalography and Clinical Neurophysiology|volume=90|pmid=7514984|issue=5|pages=376–83[/tpl] The arrayed electrode was also demonstrated to perform well compared to Silver/Silver Chloride electrodes. The device consisted of four sites of sensors with integrated electronics to reduce noise by impedance matching. The advantages of such electrodes are: (1) no electrolyte used, (2) no skin preparation, (3) significantly reduced sensor size, and (4) compatibility with EEG monitoring systems. The active electrode array is an integrated system made of an array of capacitive sensors with local integrated circuitry housed in a package with batteries to power the circuitry. This level of integration was required to achieve the functional performance obtained by the electrode.
The electrode was tested on an electrical test bench and on human subjects in four modalities of EEG activity, namely: (1) spontaneous EEG, (2) sensory event-related potentials, (3) brain stem potentials, and (4) cognitive event-related potentials. The performance of the dry electrode compared favorably with that of the standard wet electrodes in terms of skin preparation, no gel requirements (dry), and higher signal-to-noise ratio.[tpl]cite journal|bibcode=1994PhDT........82A |title=Active Micromachined Scalp Electrode Array for Eeg Signal Recording |author=Alizadeh-Taheri, Babak |journal=PhD thesis |publisher=University of California |year=1994|pages=82[/tpl]
In 1999 researchers at Case Western Reserve University, in Cleveland, Ohio, led by Hunter Peckham, used 64-electrode EEG skullcap to return limited hand movements to quadriplegic Jim Jatich. As Jatich concentrated on simple but opposite concepts like up and down, his beta-rhythm EEG output was analysed using software to identify patterns in the noise. A basic pattern was identified and used to control a switch: Above average activity was set to on, below average off. As well as enabling Jatich to control a computer cursor the signals were also used to drive the nerve controllers embedded in his hands, restoring some movement.The Next BrainiacsWired Magazine, August 2001.

====Prosthesis control====

Non-invasive BCIs have also been applied to enable brain-control of prosthetic upper and lower extremity devices in people with paralysis. For example, Gert Pfurtscheller of Graz University of Technology and colleagues demonstrated a BCI-controlled functional electrical stimulation system to restore upper extremity movements in a person with tetraplegia due to spinal cord injury.[tpl]cite doi|10.1016/S0304-3940(03)00947-9[/tpl] Between 2012 and 2013, researchers at the University of California, Irvine demonstrated for the first time that it is possible to use BCI technology to restore brain-controlled walking after spinal cord injury. In their study, a person with paraplegia due to spinal cord injury was able to operate a BCI-robotic gait orthosis to regain basic brain-controlled ambulation.[tpl]cite web |url=http://www.jneuroengrehab.com/content/10/1/111/abstract |title=Brain-computer interface controlled robotic gait orthosis |work=Journal of NeuroEngineering and Rehabilitation 2013, 10:111[/tpl]Subject with Paraplegia Operates BCI-controlled RoGO (4x) at YouTube.com

====Other research====

Electronic neural networks have been deployed which shift the learning phase from the user to the computer. Experiments by scientists at the Fraunhofer Society in 2004 using neural networks led to noticeable improvements within 30 minutes of training.Artificial Neural Net Based Signal Processing for Interaction with Peripheral Nervous System. In: Proceedings of the 1st International IEEE EMBS Conference on Neural Engineering. pp. 134–137.  20–22 March 2003.
Experiments by Eduardo Miranda, at the University of Plymouth in the UK, has aimed to use EEG recordings of mental activity associated with music to allow the disabled to express themselves musically through an encephalophone.Mental ways to make music, Cane, Alan, Financial Times, London (UK), 22 April 2005, p. 12 Ramaswamy Palaniappan has pioneered the development of BCI for use in biometrics to identify/authenticate a person.[tpl]cite doi|10.1007/s00500-004-0439-7[/tpl] The method has also been suggested for use as PIN generation device (for example in ATM and internet banking transactions.New research to find out if your thoughts can be used to verify passwords. Retrieved on 2012-09-20. The group which is now at University of Wolverhampton has previously developed analogue cursor control using thoughts.When mind over matter has a whole new meaning (From Gazette). Gazette-news.co.uk (13 April 2011). Retrieved on 2012-05-29.
Researchers at the University of Twente in the Netherlands have been conducting research on using BCIs for non-disabled individuals, proposing that BCIs could improve error handling, task performance, and user experience and that they could broaden the user spectrum.[tpl]cite journal | author = Gürkök H., Nijholt A. | year = 2012 | title = Brain-Computer Interfaces for Multimodal Interaction: A Survey and Principles | url = | journal = Int. J. Hum. Comput. Interaction | volume = 28 | issue = 5| pages = 292–307 | doi = 10.1080/10447318.2011.582022 [/tpl] They particularly focused on BCI games,D. Plass-Oude Bos, B. Reuderink, B. van de Laar, H. Gürkök, C. Mühl, M. Poel, A. Nijholt, D. Heylen. "Brain-Computer Interfacing and Games" Brain-Computer Interfaces 2010: 149–178 [tpl]doi|10.1007/978-1-84996-272-8 10[/tpl] suggesting that BCI games could provide challenge, fantasy and sociality to game players and could, thus, improve player experience.[tpl]cite journal | author = Gürkök H., Nijholt A., Poel M. | year = 2012| title = Brain-Computer Interface Games: Towards a Framework | url = | journal = ICEC | volume = 2012 | issue = | pages = 373–380 | doi = 10.1007/978-3-642-33542-6_33 | series = Lecture Notes in Computer Science | isbn = 978-3-642-33541-9 [/tpl]
The Emotiv company has been selling a commercial video game controller, known as The Epoc, since December 2009. The Epoc uses electromagnetic sensors.Emotiv Epoc "brain-wave" PC controller delayed until 2009. News.bigdownload.com (1 December 2008). Retrieved on 2012-05-29.
The first BCI session with 100% accuracy (based on 80 right-hand and 80 left-hand movement imaginations) was recorded in 1998 by Christoph Guger. The BCI system used 27 electrodes overlaying the sensorimotor cortex, weighted the electrodes with Common Spatial Patterns, calculated the running variance and used a linear discriminant analysis.[tpl]cite journal | author = Guger C., Ramoser H., Pfurtscheller G. |date=Dec 2000 | title = Real-time analysis with subject-specific spatial patterns | url = | journal = IEEE Trans Rehabil Eng. | volume = 8 | issue = 4| pages = 447–56 | doi = 10.1109/86.895947 | pmid = 11204035 [/tpl]
Research is ongoing into military use of BCIs and since the 1970s DARPA has been funding research on this topic. The current focus of research is user-to-user communication through analysis of neural signals.[tpl]cite web| last = Drummond| first = Katie| title = Pentagon Preps Soldier Telepathy Push| publisher = Wired Magazine|date = 14 May 2009| url =http://www.wired.com/dangerroom/2009/05/pentagon-preps-soldier-telepathy-push| accessdate = 2009-05-06[/tpl] The project "Silent Talk" aims to detect and analyze the word-specific neural signals, using EEG, which occur before speech is vocalized, and to see if the patterns are generalizable.[tpl]cite web| last = DARPA| title = Department of Defense Fiscal Year (FY) 2010 Budget Estimates May 2009| publisher = DARPA|date = May 2009| url =http://www.darpa.mil/WorkArea/DownloadAsset.aspx?id=538| accessdate = 2011-07-25[/tpl]

====MEG and MRI====

Magnetoencephalography (MEG) and functional magnetic resonance imaging (fMRI) have both been used successfully as non-invasive BCIs.Ranganatha Sitaram, Andrea Caria, Ralf Veit, Tilman Gaber, Giuseppina Rota, Andrea Kuebler and Niels Birbaumer(2007) "FMRI Brain–Computer Interface: A Tool for Neuroscientific Research and Treatment" In a widely reported experiment, fMRI allowed two users being scanned to play Pong in real-time by altering their haemodynamic response or brain blood flow through biofeedback techniques.Mental ping-pong could aid paraplegics, Nature, 27 August 2004
fMRI measurements of haemodynamic responses in real time have also been used to control robot arms with a seven second delay between thought and movement.To operate robot only with brain, ATR and Honda develop BMI base technology, Tech-on, 26 May 2006
In 2008 research developed in the Advanced Telecommunications Research (ATR) Computational Neuroscience Laboratories in Kyoto, Japan, allowed the scientists to reconstruct images directly from the brain and display them on a computer in black and white at a resolution of 10x10 pixels. The article announcing these achievements was the cover story of the journal Neuron of 10 December 2008.
In 2011 researchers from UC Berkeley published a study reporting second-by-second reconstruction of videos watched by the study's subjects, from fMRI data. This was achieved by creating a statistical model relating visual patterns in videos shown to the subjects, to the brain activity caused by watching the videos. This model was then used to look up the 100 one-second video segments, in a database of 18 million seconds of random YouTube videos, whose visual patterns most closely matched the brain activity recorded when subjects watched a new video. These 100 one-second video extracts were then combined into a mashed-up image that resembled the video being watched.

====Neurogaming====

Currently, there is a new field of gaming called Neurogaming, which uses non-invasive BCI in order to improve gameplay so that users can interact with a console without the use of a traditional controller.[tpl]YouTube|Qz2XR3xcx60[/tpl] Some Neurogaming software use a player's brain waves, heart rate, expressions, pupil dilation, and even emotions to complete tasks or effect the mood of the game.[tpl]cite web|url= http://venturebeat.com/2013/01/17/let-the-neurogames-begin/|title= Neurogaming[/tpl] For example, game developers at Emotiv have created non-invasive BCI that will determine the mood of a player and adjust music or scenery accordingly. This new form of interaction between player and software will enable a player to have a more realistic gaming experience.[tpl]YouTube|T7CiiWBwMgw[/tpl] Because there will be less disconnect between a player and console, Neurogaming will allow individuals to utilize their "psychological state"[tpl]cite web|url=  http://advancedbrainmonitoring.com/neurogaming-berka-2010-2/|title= Merging Cognitive Neuroscience & Virtual Simulation in an Interactive Training Platform[/tpl] and have their reactions transfer to games in real-time.
However, since Neurogaming is still in its first stages, not much is written about the new industry. The first NeuroGaming Conference was held in San Francisco on May 1–2, 2013.http://www.neurogamingconf.com/

====BCI Control Strategies in Neurogaming====

=====Motor Imagery=====

Motor imagery involves the imagination of the movement of various body parts resulting in sensorimotor cortex activation,which modulates sensorimotor oscillations in the EEG. This can be detected by the BCI to infer a user’s intent. Motor imagery typically requires a number of sessions of training before acceptable control of the BCI is acquired. These training sessions may take a number of hours over several days before users can consistently employ the technique with acceptable levels of precision.Regardless of the duration of the training session,users are unable to master the control scheme.This results in very slow pace of the gameplay .[tpl]cite journal|last1=Coyle|first1=Damien|last2=Marshall|first2=David|last3=Wilson|first3=Shane|last4=Callaghan|first4=Michael|title=Games, Gameplay, and BCI: The State of the Art|volume=5|issue=2|page = 83|url=https://ieeexplore.ieee.org/xpls/icp.jsp?arnumber=6518141[/tpl]

=====Bio/Neurofeedback for Passive BCI Designs=====

Biofeedback is used to monitor a subject’s mental relaxation.In some cases, biofeedback does not monitor electroencephalography (EEG), but instead bodily parameters such as electromyography(EMG), galvanic skin resistance (GSR), and heart rate variability (HRV).Many biofeedback systems are used to treat certain disorders such as attention deficit hyperactivity disorder (ADHD), sleep problems in children,teeth grinding, and chronic pain. EEG biofeedback systems typically monitor four different bands (theta: 4–7 Hz, alpha:8–12 Hz, SMR: 12–15 Hz, beta: 15–18 Hz) and challenge the subject to control them. Passive BCI involves using BCI to enrich human–machine interaction with implicit information on the actual user’s state, for example, simulations to detect when users intend to push brakes during an emergency car stopping procedure. Game developers using passive BCIs need to acknowledge that through repetition of game levels the user’s cognitive state will change or adapt. Within the first play
of a level, the user will react to things differently from during the second play: for example, the user will be less surprised at an event in the game if he/she is expecting it.

=====Visual Evoked Potential (VEP)=====

A VEP is an electrical potential recorded after a subject is presented with a type of visual stimuli. There are several types of VEPs.
Steady-state visually evoked potentials (SSVEPs) use potentials generated by exciting the retina, using visual stimuli modulated at certain frequencies. SSVEP’s stimuli are often formed from alternating checkerboard patterns and at times simply use flashing images  . The frequency of the phase reversal of the stimulus used can be clearly distinguished in the spectrum of an EEG; this makes detection of SSVEP stimuli relatively easy . SSVEP has proved to be successful within many BCI systems . This is due to several factors , the signal elicited is measurable in as large a population as the transient VEP and blink movement and electro cardiographic artefacts do not affect the frequencies monitored. In addition, the SSVEP signal is exceptionally robust; the topographic organization of the primary visual cortex is such that a broader area obtains afferents from the central or fovial region of the visual field .SSVEP does have several problems however. As SSVEPs use flashing stimuli to infer a user’s intent, the user must gaze at one of the flashing or iterating symbols in order to interact with the system. It is, therefore, likely that the symbols could become irritating and uncomfortable to use during longer play sessions, which can often last more than an hour which may not be an ideal gameplay.
Another type of VEP used with applications is the P300 potential. The P300 event-related potential is a positive peak in the EEG that occurs at roughly 300 ms after the appearance of a target stimulus (a stimulus for which the user is waiting or seeking) or oddball stimuli . The P300 amplitude decreases as the target stimuli and the ignored stimuli grow more similar.The P300 is thought to be related to a higher level attention process or an orienting response Using P300 as a control scheme has the advantage of the participant only having to attend limited training sessions. The first application to use the P300 model was the P300 matrix . Within this system, a subject would choose a letter from a grid of 6 by 6 letters and numbers. The rows and columns of the grid flashed sequentially and every time the selected “choice letter” was illuminated the user’s P300 was (potentially) elicited. However, the communication process, at approximately 17 characters per minute , was quite slow. The P300 is a BCI that offers a discrete selection rather than a continuous control mechanism. The advantage of P300 use within games is that the player does not have to teach himself/herself how to use a completely new control system and so only has to undertake short training instances, to learn the gameplay mechanics and basic use of the BCI paradigm.

===Synthetic telepathy/silent communication===

In a $6.3 million Army initiative to invent devices for telepathic communication, Gerwin Schalk, underwritten in a $2.2 million grant, found that it is possible to use ECoG signals to discriminate the vowels and consonants embedded in spoken and in imagined words.  The results shed light on the distinct mechanisms associated with production of vowels and consonants, and could provide the basis for brain-based communication using imagined speech.[tpl]cite news |first= Pei|last= X|authorlink= |title=Decoding Vowels and Consonants in Spoken and Imagined Words Using Electrocorticographic Signals in Humans |pmid=21750369 |quote=|work=J Neural Eng 046028th ser. 8.4  |year=2011  |accessdate=12 February 2012 [/tpl][tpl]cite news |first= Pagan|last= Kennedy|authorlink= |title=The Cyborg in Us All |url=http://www.nytimes.com/2011/09/18/magazine/the-cyborg-in-us-all.html?pagewanted=all |quote=|work=New York Times |date=18 September 2011  |accessdate=28 January 2012 [/tpl]
Research into synthetic telepathy using subvocalization is taking place at the University of California, Irvine under lead scientist Mike D'Zmura. The first such communication took place in the 1960s using EEG to create Morse code using brain alpha waves. Using EEG to communicate imagined speech is less accurate than the invasive method of placing an electrode between the skull and the brain.[tpl]cite news|title= Army Developing‘synthetic telepathy’|url= http://www.nbcnews.com/id/27162401/#.Uidehm25fIV|accessdate=13 Oct 2008 |newspaper=Discovery News|date=13 Oct 2008|author= Eric Bland[/tpl] On February 27, 2013 Duke University researchers successfully connected the brains of two rats with electronic interfaces that allowed them to directly share information, in the first-ever direct brain-to-brain interface.[tpl]cite news|title=One Rat Thinks, and Another Reacts|author=James Gorman|url=http://www.nytimes.com/2013/03/01/science/new-research-suggests-two-rat-brains-can-be-linked.html|work=New York Times|date=28 February 2013|accessdate=28 February 2013[/tpl][tpl]cite web|url=http://www.guardian.co.uk/science/2013/feb/28/brains-rats-connected-share-information|title=Brain-to-brain interface lets rats share information via internet|work=The Guardian|date=1 March 2013|accessdate=2 March 2013[/tpl]

===Commercialization===

John Donoghue and fellow researchers founded Cyberkinetics. The company markets its electrode arrays under the BrainGate product name and has set the development of practical BCIs for humans as its major goal. The BrainGate is based on the Utah Array developed by Dick Normann.
Philip Kennedy founded Neural Signals in 1987 to develop BCIs that would allow paralysed patients to communicate with the outside world and control external devices. As well as an invasive BCI, the company also sells an implant to restore speech. Neural Signals' "Brain Communicator" BCI device uses glass cones containing microelectrodes coated with proteins to encourage the electrodes to bind to neurons.
Although 16 paying patients were treated using William Dobelle's vision BCI, new implants ceased within a year of Dobelle's death in 2004. A company controlled by Dobelle, Avery Biomedical Devices, and Stony Brook University are continuing development of the implant, which has not yet received Food and Drug Administration approval for human implantation in the United States.Press release, Stony Brook University Center for Biotechnology, 1 May 2006
Ambient, at a TI developers conference in early 2008, demonstrated a product they have in development called The Audeo. The Audeo aims to create a human–computer interface for communication without the need of physical motor control or speech production. Using signal processing, unpronounced speech can be translated from intercepted neurological signals.Speak Your Mind. Theaudeo.com. Retrieved on 2012-05-29.
Mindball is a product, developed and commercialized by the Swedish company Interactive Productline, in which players compete to control a ball's movement across a table by becoming more relaxed and focused.Welcome to Mind Ball. Vivifeye.com (8 March 2012). Retrieved on 2012-05-29. Interactive Productline's objective is to develop and sell easily understandable EEG products that train the ability to relax and focus.Interactive Productline|About us. Mindball.se. Retrieved on 2012-05-29.
An Austrian company called Guger Technologies or[tpl]cite web|title=Guger Technologies|url=http://www.gtec.at[/tpl] g.tec, has been offering Brain Computer Interface systems since 1999. The company provides base BCI models as development platforms for the research community to build upon, including the P300 Speller, Motor Imagery, and Steady-State Visual Evoked Potential. g.tec recently developed the g.SAHARA dry electrode system, which can provide signals comparable to gel-based systems.Guger et al., 2012, Frontiers in Neuroscience
Spanish company Starlab, entered this market in 2009 with a wireless 4-channel system called Enobio. In 2011 Enobio 8 and 20 channel (CE Medical) was released and is now commercialised by Starlab spin-off Neuroelectrics Designed for medical and research purposes the system provides an all in one solution and a platform for application development.[tpl]cite web|title=ENOBIO|url=http://neuroelectrics.com/enobio[/tpl]
There are three main consumer-devices commercial-competitors in this area (launch date mentioned in brackets) which have launched such devices primarily for gaming- and PC-users:
In 2009, the world's first personal EEG-based spelling system came to the market: intendiX. The system can work with passive, active, or new dry EEG electrodes. The first version used P300 activity to type on a keyboard-like matrix. Besides writing text, the patient can also use the system to trigger an alarm, let the computer speak the written text, print out or copy the text into an e-mail or to send commands to external devices. In March 2012, g.tec debuted a new intendiX module called the Screen Overlay Control Interface (SOCI) that could allow users to play World of Warcraft or Angry Birds.
Mind Solutions Inc. holds a patent for an EEG device currently in prototype phase, and has also developed multiple software applications for future use with their headset. These software applications have been used primarily on EEG devices currently on the market. Their software is geared towards aiding the handicapped and a platform for future generation gaming. It has 3 software titles complete and on the market that currently require an Emotiv headset to run.http://www.mindsolutionscorp.com/

==Cell-culture BCIs==

Researchers have built devices to interface with neural cells and entire neural networks in cultures outside animals. As well as furthering research on animal implantable devices, experiments on cultured neural tissue have focused on building problem-solving networks, constructing basic computers and manipulating robotic devices. Research into techniques for stimulating and recording from individual neurons grown on semiconductor chips is sometimes referred to as neuroelectronics or neurochips.[tpl]cite journal|doi=10.1523/JNEUROSCI.1051-07.2007|title=Interfacing Neurons with Carbon Nanotubes: Electrical Signal Transfer and Synaptic Stimulation in Cultured Brain Circuits|year=2007|last1=Mazzatenta|first1=A.|last2=Giugliano|first2=M.|last3=Campidelli|first3=S.|last4=Gambazzi|first4=L.|last5=Businaro|first5=L.|last6=Markram|first6=H.|last7=Prato|first7=M.|last8=Ballerini|first8=L.|journal=Journal of Neuroscience|volume=27|pmid=17596441|issue=26|pages=6931–6[/tpl]
Development of the first working neurochip was claimed by a Caltech team led by Jerome Pine and Michael Maher in 1997.Press release, Caltech, 27 October 1997 The Caltech chip had room for 16 neurons.
In 2003 a team led by Theodore Berger, at the University of Southern California, started work on a neurochip designed to function as an artificial or prosthetic hippocampus. The neurochip was designed to function in rat brains and was intended as a prototype for the eventual development of higher-brain prosthesis. The hippocampus was chosen because it is thought to be the most ordered and structured part of the brain and is the most studied area. Its function is to encode experiences for storage as long-term memories elsewhere in the brain.Coming to a brain near you, Wired News, 22 October 2004
Thomas DeMarse at the University of Florida used a culture of 25,000 neurons taken from a rat's brain to fly a F-22 fighter jet aircraft simulator.'Brain' in a dish flies flight simulator, CNN, 4 November 2004 After collection, the cortical neurons were cultured in a petri dish and rapidly began to reconnect themselves to form a living neural network. The cells were arranged over a grid of 60 electrodes and used to control the pitch and yaw functions of the simulator. The study's focus was on understanding how the human brain performs and learns computational tasks at a cellular level.

==Ethical considerations==

Important ethical, legal and societal issues related to brain-computer interfacing are:[tpl]cite journal|last1=Clausen|first1=Jens|title=Man, machine and in between|journal=Nature|volume=457|page=1080|year=2009|doi=10.1038/4571080a|issue=7233|bibcode = 2009Natur.457.1080C [/tpl][tpl]cite journal|last1=Haselager|first1=Pim|last2=Vlek|first2=Rutger|last3=Hill|first3=Jeremy|last4=Nijboer|first4=Femke|title=A note on ethical aspects of BCI|journal=Neural Networks|volume=22|page=1352|year=2009|doi=10.1016/j.neunet.2009.06.046|issue=9[/tpl][tpl]cite journal|last1=Tamburrini|first1=Guglielmo|title=Brain to Computer Communication: Ethical Perspectives on Interaction Models|journal=Neuroethics|volume=2|page=137|year=2009|doi=10.1007/s12152-009-9040-1|issue=3[/tpl][tpl]cite journal|last1=Nijboer|first1=Femke|last2=Clausen|first2=Jens|last3=Allison|first3=Brendan Z|last4=Haselager|first4=Pim|title=Stakeholders' opinions on ethical issues related to brain-computer interfacing|journal=Neuroethics|doi=10.1007/s12152-011-9132-6|year=2011|volume=6|issue=3|pages=541[/tpl]
Clausen stated in 2009 that “BCIs pose ethical challenges, but these are conceptually similar to those that bioethicists have addressed for other realms of therapy”. Moreover, he suggests that bioethics is well-prepared to deal with the issues that arise with BCI technologies. Haselager and colleagues pointed out that expectations of BCI efficacy and value play a great role in ethical analysis and the way BCI scientists should approach media. Furthermore, standard protocols can be implemented to ensure ethically sound informed-consent procedures with locked-in patients.
Researchers are well aware that sound ethical guidelines, appropriately moderated enthusiasm in media coverage and education about BCI systems will be of utmost importance for the societal acceptance of this technology. Thus, recently more effort is made inside the BCI community to create consensus on ethical guidelines for BCI research, development and dissemination.

==Low-cost BCI-based Interfaces==

Recently a number of companies have scaled back medical grade EEG technology (and in one case, NeuroSky, rebuilt the technology from the ground up[tpl]Clarify|reason=How is this significant?|date=April 2014[/tpl]) to create inexpensive BCIs. This technology has been built into toys and gaming devices; some of these toys have been extremely commercially successful like the NeuroSky and Mattel MindFlex.
accessdate=2010-05-01}}[/ref]

==Fiction or speculation==

The prospect of BCIs and brain implants of all kinds have been important themes in science fiction. See brain implants in fiction and philosophy for a review of this literature.

==See also==

==References==

==Further reading==

==External links==


