[[Just-in-time compilation]]

CATEGORIES: Compiler construction, Emulation software, Virtualization software

In computing, just-in-time compilation (JIT), also known as dynamic translation, is compilation done during execution of a program – at run time – rather than prior to execution.[tpl]sfn|Aycock|2003[/tpl] Most often this consists of translation to machine code, which is then executed directly, but can also refer to translation to another format.
JIT compilation is a combination of the two traditional approaches to translation to machine code – ahead of time compilation (AOT), and interpretation – and combines some advantages and drawbacks of both.[tpl]sfn|Aycock|2003[/tpl] Roughly, JIT compilation combines the speed of compiled code with the flexibility of interpretation, with the overhead of an interpreter and the additional overhead of compiling (not just interpreting). JIT compilation is a form of dynamic compilation, and allows adaptive optimization such as dynamic recompilation – thus in principle JIT compilation can yield faster execution than static compilation. Interpretation and JIT compilation are particularly suited for dynamic programming languages, as the runtime system can handle late-bound data types and enforce security guarantees.

==Applications==

JIT compilation can be applied to a whole program, or can be used for certain capacities, particularly dynamic capacities such as regular expressions. For example, a text editor may compile a regular expression provided at runtime to machine code to allow faster matching – this cannot be done ahead of time, as the data is only provided at run time. Several modern runtime environments rely on JIT compilation for high-speed code execution, most significantly most implementations of Java, together with Microsoft's .NET Framework. Similarly, many regular expression libraries ("regular expression engines") feature JIT compilation of regular expressions, either to bytecode or to machine code.
A common implementation of JIT compilation is to first have AOT compilation to bytecode (virtual machine code), known as bytecode compilation, and then have JIT compilation to machine code (dynamic compilation), rather than interpretation of the bytecode. This improves the runtime performance compared to interpretation, at the cost of lag due to compilation. JIT compilers translate continuously, as with interpreters, but caching of compiled code minimizes lag on future execution of the same code during a given run. Since only part of the program is compiled, there is significantly less lag than if the entire program were compiled prior to execution.

==Overview==

In a bytecode-compiled system, source code is translated to an intermediate representation known as bytecode. Bytecode is not the machine code for any particular computer, and may be portable among computer architectures. The bytecode may then be interpreted by, or run on, a virtual machine. The JIT compiler reads the bytecodes in many sections (or in full, rarely) and compiles them dynamically into machine language so the program can run faster. Java performs runtime checks on various sections of the code and this is the reason the entire code is not compiled at once.[tpl]cite book|last=Kogent Solution Inc.|title=Java 6 Programming Black Book, New Ed|year=2007|publisher=Dreamtech Press|page=5|isbn=978-81-7722-736-9|url=http://books.google.com/books?id=SSyuJa04uv8C[/tpl] This can be done per-file, per-function or even on any arbitrary code fragment; the code can be compiled when it is about to be executed (hence the name "just-in-time"), and then cached and reused later without needing to be recompiled.
In contrast, a traditional interpreted virtual machine will simply interpret the bytecode, generally with much lower performance. Some interpreters even interpret source code, without the step of first compiling to bytecode, with even worse performance. Statically compiled code or native code is compiled prior to deployment. A dynamic compilation environment is one in which the compiler can be used during execution. For instance, most Common Lisp systems have a compile function which can compile new functions created during the run. This provides many of the advantages of JIT, but the programmer, rather than the runtime, is in control of what parts of the code are compiled. This can also compile dynamically generated code, which can, in many scenarios, provide substantial performance advantages over statically compiled code[tpl]Citation needed|date=September 2011[/tpl], as well as over most JIT systems.
A common goal of using JIT techniques is to reach or surpass the performance of static compilation, while maintaining the advantages of bytecode interpretation: Much of the "heavy lifting" of parsing the original source code and performing basic optimization is often handled at compile time, prior to deployment: compilation from bytecode to machine code is much faster than compiling from source. The deployed bytecode is portable, unlike native code. Since the runtime has control over the compilation, like interpreted bytecode, it can run in a secure sandbox. Compilers from bytecode to machine code are easier to write, because the portable bytecode compiler has already done much of the work.
JIT code generally offers far better performance than interpreters. In addition, it can in some cases offer better performance than static compilation, as many optimizations are only feasible at run-time:

==Startup delay and optimizations==

JIT typically causes a slight delay in initial execution of an application, due to the time taken to load and compile the bytecode. Sometimes this delay is called "startup time delay". In general, the more optimization JIT performs, the better the code it will generate, but the initial delay will also increase. A JIT compiler therefore has to make a trade-off between the compilation time and the quality of the code it hopes to generate. However, it seems that much of the startup time is sometimes due to IO-bound operations rather than JIT compilation (for example, the rt.jar class data file for the Java Virtual Machine JVM is 40 MB and the JVM must seek a lot of data in this contextually huge file).
One possible optimization, used by Sun's HotSpot Java Virtual Machine, is to combine interpretation and JIT compilation. The application code is initially interpreted, but the JVM monitors which sequences of bytecode are frequently executed and translates them to machine code for direct execution on the hardware. For bytecode which is executed only a few times, this saves the compilation time and reduces the initial latency; for frequently executed bytecode, JIT compilation is used to run at high speed, after an initial phase of slow interpretation. Additionally, since a program spends most time executing a minority of its code, the reduced compilation time is significant. Finally, during the initial code interpretation, execution statistics can be collected before compilation, which helps to perform better optimization.[tpl]cite web|url=http://www.oracle.com/technetwork/java/whitepaper-135217.html |title=The Java HotSpot Performance Engine Architecture |publisher=Oracle.com |date= |accessdate=2013-07-05[/tpl]
The correct tradeoff can vary due to circumstances. For example, Sun's Java Virtual Machine has two major modes—client and server. In client mode, minimal compilation and optimization is performed, to reduce startup time. In server mode, extensive compilation and optimization is performed, to maximize performance once the application is running by sacrificing startup time. Other Java just-in-time compilers have used a runtime measurement of the number of times a method has executed combined with the bytecode size of a method as a heuristic to decide when to compile.[tpl]cite journal | title=The simplest heuristics may be the best in Java JIT compilers| last=Schilling | first=Jonathan L. | journal=SIGPLAN Notices | volume=38 | issue=2 | date=February 2003 | pages=36–46 | doi=10.1145/772970.772975 | url=http://www.sco.com/developers/java/news/jit-heur.pdf[/tpl]  Still another uses the number of times executed combined with the detection of loops.Toshio Suganuma, Toshiaki Yasue, Motohiro Kawahito, Hideaki Komatsu, Toshio Nakatani, "A dynamic optimization framework for a Java just-in-time compiler", Proceedings of the 16th ACM SIGPLAN conference on Object-oriented programming, systems, languages, and applications (OOPSLA '01), pp. 180–195, October 14–18, 2001. In general, it is much harder to accurately predict which methods to optimize in short-running applications than in long-running ones.Matthew Arnold, Michael Hind, Barbara G. Ryder, "An Empirical Study of Selective Optimization", Proceedings of the 13th International Workshop on Languages and Compilers for Parallel Computing-Revised Papers, pp. 49–67, August 10–12, 2000.
Native Image Generator (Ngen) by Microsoft is another approach at reducing the initial delay.[tpl]cite web|url=http://msdn2.microsoft.com/en-us/library/6t9t5wcf(VS.80).aspx |title=Native Image Generator (Ngen.exe) |publisher=Msdn2.microsoft.com |date= |accessdate=2013-07-05[/tpl] Ngen pre-compiles (or "pre-JITs") bytecode in a Common Intermediate Language image into machine native code. As a result, no runtime compilation is needed. .NET framework 2.0 shipped with Visual Studio 2005 runs Ngen on all of the Microsoft library DLLs right after the installation. Pre-jitting provides a way to improve the startup time. However, the quality of code it generates might not be as good as the one that is jitted, for the same reasons why code compiled statically, without profile-guided optimization, cannot be as good as JIT compiled code in the extreme case: the lack of profiling data to drive, for instance, inline caching.Matthew R. Arnold, Stephen Fink, David P. Grove, Michael Hind, and Peter F. Sweeney, "A Survey of Adaptive Optimization in Virtual Machines", Proceedings of the IEEE, 92(2), February 2005, pp. 449–466.
There also exist Java implementations that combine an AOT (ahead-of-time) compiler with either a JIT compiler (Excelsior JET) or interpreter (GNU Compiler for Java.)

==History==

The earliest published JIT compiler is generally attributed to work on LISP by McCarthy in 1960.[tpl]sfn|Aycock|2003|loc=2. JIT Compilation Techniques, 2.1 Genesis, p. 98[/tpl] In his seminal paper Recursive functions of symbolic expressions and their computation by machine, Part I, he mentions functions that are translated during runtime, thereby sparing the need to save the compiler output to punch cards[tpl]cite journal|last=McCarthy|first=J.|title=Recursive functions of symbolic expressions and their computation by machine, Part I|journal=Communications of the ACM|date=April 1960|volume=3|issue=4|pages=184–195|doi=10.1145/367177.367199|id = [tpl]citeseerx|10.1.1.111.8833[/tpl]|accessdate=24 May 2010[/tpl] (although this would be more accurately known as a "Compile and go system"). Another early example was by Ken Thompson, who in 1968 gave one of the first applications of regular expressions, here for pattern matching in the text editor QED.[tpl]sfn|Thompson|1968[/tpl] For speed, Thompson implemented regular expression matching by JITing to IBM 7094 code on the Compatible Time-Sharing System.[tpl]sfn|Aycock|2003|loc=2. JIT Compilation Techniques, 2.1 Genesis, p. 98[/tpl] An influential technique for deriving compiled code from interpretation was pioneered by Mitchell in 1970, which he implemented for the experimental language LC².[tpl]sfn|Aycock|2003|loc=2. JIT Compilation Techniques, 2.2 LC², p. 98–99[/tpl][tpl]Cite document|last=Mitchell|first=J.G.|title=The design and construction of flexible and efficient interactive programming systems|year=1970 [/tpl]
Smalltalk (c. 1983) pioneered new aspects of JIT compilations. For example, translation to machine code was done on demand, and the result was cached for later use. When memory became scarce, the system would delete some of this code and regenerate it when it was needed again.[tpl]sfn|Aycock|2003[/tpl][tpl]Cite journal|last=Deutsch|first=L.P.|last2=Schiffman|first2=A.M.|title=Efficient implementation of the Smalltalk-80 system|journal=POPL '84: Proceedings of the 11th ACM SIGACT-SIGPLAN Symposium on Principles of Programming Languages|year=1984|pages=297–302|doi=10.1145/800017.800542|url=http://webpages.charter.net/allanms/popl84.pdf|isbn=0-89791-125-3[/tpl] Sun's Self language improved these techniques extensively and was at one point the fastest Smalltalk system in the world; achieving up to half the speed of optimized C[tpl]dead link|date=July 2013[/tpl] but with a fully object-oriented language.
Self was abandoned by Sun, but the research went into the Java language. The term "Just-in-time compilation" was borrowed from the manufacturing term "Just in time" and popularized by Java, with James Gosling using the term from 1993.[tpl]sfn|Aycock|2003|2.14 Java, p. 107, footnote 13[/tpl] Currently JITing is used by most implementations of the Java Virtual Machine, as HotSpot builds on, and extensively uses, this research base.
The HP project Dynamo[ref]
Vasanth Bala, Evelyn Duesterwald, Sanjeev Banerjia - 
PLDI '00 Proceedings of the ACM SIGPLAN 2000 conference on Programming language design and implementation - pages 1 to 12 - 
[tpl]DOI|10.1145/349299.349303[/tpl].
Retrieved March, 28 2012
[/ref] was an experimental JIT compiler where the 'bytecode' format and the machine code format were the same; the system turned HPA-6000 machine code into HPA-8000 machine code. Counterintuitively, this resulted in speed ups, in some cases of 30% since doing this permitted optimizations at the machine code level, for example, inlining code for better cache usage and optimizations of calls to dynamic libraries and many other run-time optimizations which conventional compilers are not able to attempt.[tpl]cite web|author=John Jannotti |url=http://arstechnica.com/reviews/1q00/dynamo/dynamo-1.html |title=HP's Dynamo - Page 1 - (3/2000) |publisher=Ars Technica |date= |accessdate=2013-07-05[/tpl]

==Security==

JIT compilation fundamentally uses executable data, and thus poses security challenges and possible exploits.
Implementation of JIT compilation consists of compiling source code or byte code to machine code and executing it. This is generally done directly in memory – the JIT compiler outputs the machine code directly into memory and immediately executes it, rather than outputting it to disk and then invoking the code as a separate program, as in usual ahead of time compilation. In modern architectures this runs into a problem due to executable space protection – arbitrary memory cannot be executed, as otherwise there is a potential security hole. Thus memory must be marked as executable; for security reasons this should be done after the code has been written to memory, and marked read-only, as writable/executable memory is a security hole (see W^X)."How to JIT – an introduction", Eli Bendersky, November 5th, 2013 at 5:59 am
JIT spraying is a class of computer security exploits that use JIT compilation for heap spraying – the resulting memory is then executable, which allows an exploit if execution can be moved into the heap.

==See also==

==References==

==External links==


