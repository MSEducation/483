[[Artificial neural network]]

CATEGORIES: Computational statistics, Neural networks, Classification algorithms, Computational neuroscience, Knowledge representation

In computer science and related fields, artificial neural networks (ANNs) are computational  models inspired by animals' central nervous systems (in particular the brain) that are capable of machine learning and pattern recognition. They are usually presented as systems of interconnected "neurons" that can compute values from inputs by feeding information through the network.
For example, in a neural network for handwriting recognition, a set of input neurons may be activated by the pixels of an input image representing a letter or digit. The activations of these neurons are then passed on, weighted and transformed by some function determined by the network's designer, to other neurons, etc., until finally an output neuron is activated that determines which character was read.
Like other machine learning methods, neural networks have been used to solve a wide variety of tasks that are hard to solve using ordinary rule-based programming, including computer vision and speech recognition.

==Background==

The inspiration for the neural networks came from examination of central nervous systems. In an artificial neural network, simple artificial nodes, called "neurons", "neurodes", "processing elements" or "units", are connected together to form a network which mimics a biological neural network.
There is no single formal definition of what an artificial neural network is. Commonly, a class of statistical models may be called "neural" if they
The adaptive weights are conceptually connection strengths between neurons, which are activated during training and prediction.
Neural networks are also similar to biological neural networks in performing functions collectively and in parallel by the units, rather than there being a clear delineation of subtasks to which various units are assigned. The term "neural network" usually refers to models employed in statistics, cognitive psychology and  artificial intelligence. Neural network models which emulate the central nervous system are part of theoretical neuroscience and computational neuroscience.
In modern software implementations of artificial neural networks, the approach inspired by biology has been largely abandoned for a more practical approach based on statistics and signal processing. In some of these systems, neural networks or parts of neural networks (like artificial neurons) form components in larger systems that combine both adaptive and non-adaptive elements. While the more general approach of such systems is more suitable for real-world problem solving, it has little to do with the traditional artificial intelligence connectionist models. What they do have in common, however, is the principle of non-linear, distributed, parallel and local processing and adaptation. Historically, the use of neural networks models marked a paradigm shift in the late eighties from high-level (symbolic) artificial intelligence, characterized by expert systems with knowledge embodied in if-then rules, to low-level (sub-symbolic) machine learning, characterized by knowledge embodied in the parameters of a dynamical system.

==History==

Warren McCulloch and Walter Pitts[tpl]cite journal|last=McCulloch|first=Warren|author2=Walter Pitts|title=A Logical Calculus of Ideas Immanent in Nervous Activity|journal=Bulletin of Mathematical Biophysics|year=1943|volume=5|pages=115–133|doi=10.1007/BF02478259|issue=4[/tpl]  (1943) created a computational model for neural networks based on mathematics and algorithms. They called this model threshold logic. The model paved the way for neural network research to split into two distinct approaches. One approach focused on biological processes in the brain and the other focused on the application of neural networks to artificial intelligence.
In the late 1940s psychologist Donald Hebb[tpl]cite book|last=Hebb|first=Donald|title=The Organization of Behavior|year=1949|publisher=Wiley|location=New York[/tpl]  created a hypothesis of learning based on the mechanism of neural plasticity that is now known as Hebbian learning. Hebbian learning is considered to be a 'typical' unsupervised learning rule and its later variants were early models for long term potentiation. These ideas started being applied to computational models in 1948 with Turing's B-type machines.
Farley and Wesley A. Clark[tpl]cite journal|last=Farley|first=B.G.|author2=W.A. Clark|title=Simulation of Self-Organizing Systems by Digital Computer|journal=IRE Transactions on Information Theory|year=1954|volume=4|pages=76–84|doi=10.1109/TIT.1954.1057468|issue=4[/tpl] (1954) first used computational machines, then called calculators, to simulate a Hebbian network at MIT. Other neural network computational machines were created by Rochester, Holland, Habit, and Duda[tpl]cite journal|last=Rochester|first=N.|coauthors=J.H. Holland, L.H. Habit, and W.L. Duda|title=Tests on a cell assembly theory of the action of the brain, using a large digital computer|journal=IRE Transactions on Information Theory|year=1956|volume=2|pages=80–93|doi=10.1109/TIT.1956.1056810|issue=3[/tpl] (1956).
Frank Rosenblatt[tpl]cite journal|last=Rosenblatt|first=F.|title=The Perceptron: A Probalistic Model For Information Storage And Organization In The Brain|journal=Psychological Review|year=1958|volume=65|pages=386–408|doi=10.1037/h0042519|pmid=13602029|issue=6[/tpl] (1958) created the perceptron, an algorithm for pattern recognition based on a two-layer learning computer network using simple addition and subtraction. With mathematical notation, Rosenblatt also described circuitry not in the basic perceptron, such as the exclusive-or circuit, a circuit whose mathematical computation could not be processed until after the backpropagation algorithm was created by Paul Werbos[tpl]cite book|last=Werbos|first=P.J.|title=Beyond Regression: New Tools for Prediction and Analysis in the Behavioral Sciences|year=1975[/tpl] (1975).
Neural network research stagnated after the publication of machine learning research by Marvin Minsky and Seymour Papert[tpl]cite book|last=Minsky|first=M.|title=An Introduction to Computational Geometry|year=1969|publisher=MIT Press|isbn=0-262-63022-2|author2=S. Papert[/tpl] (1969). They discovered two key issues with the computational machines that processed neural networks. The first issue was that single-layer neural networks were incapable of processing the exclusive-or circuit. The second significant issue was that computers were not sophisticated enough to effectively handle the long run time required by large neural networks. Neural network research slowed until computers achieved greater processing power. Also key later advances was the backpropagation algorithm which effectively solved the exclusive-or problem (Werbos 1975).
The parallel distributed processing of the mid-1980s became popular under the name connectionism. The text by David E. Rumelhart and James McClelland[tpl]cite book|last=Rumelhart|first=D.E|title=Parallel Distributed Processing: Explorations in the Microstructure of Cognition|year=1986|publisher=MIT Press|location=Cambridge|author2=James McClelland[/tpl] (1986) provided a full exposition on the use of connectionism in computers to simulate neural processes.
Neural networks, as used in artificial intelligence, have traditionally been viewed as simplified models of neural processing in the brain, even though the relation between this model and brain biological architecture is debated, as it is not clear to what degree artificial neural networks mirror brain function.[tpl]cite web|last= Russell|first= Ingrid|title= Neural Networks Module|url= http://uhaweb.hartford.edu/compsci/neural-networks-definition.html|accessdate= 2012[/tpl]
In the 1990s, neural networks were overtaken in popularity in machine learning by support vector machines and other, much simpler methods such as linear classifiers. Renewed interest in neural nets was sparked in the 2000s by the advent of deep learning.

===Recent improvements===

Biophysical models, such as BCM theory, have been important in understanding mechanisms for synaptic plasticity, and have had applications in both computer science and neuroscience. Research is ongoing in understanding the computational algorithms used in the brain, with some recent biological evidence for radial basis networks and neural backpropagation as mechanisms for processing data.
Computational devices have been created in CMOS, for both biophysical simulation and neuromorphic computing. More recent efforts show promise for creating nanodevices[ref]Yang, J. J.; Pickett, M. D.; Li, X. M.; Ohlberg, D. A. A.; Stewart,
D. R.; Williams, R. S. Nat. Nanotechnol. 2008, 3, 429–433.[/ref] for very large scale principal components analyses and convolution. If successful, these efforts could usher in a new era of neural computingStrukov, D. B.; Snider, G. S.; Stewart, D. R.; Williams, R. S. Nature 2008, 453, 80–83. that is a step beyond digital computing, because it depends on learning rather than programming and because it is fundamentally analog rather than digital even though the first instantiations may in fact be with CMOS digital devices.
Between 2009 and 2012, the recurrent neural networks and deep feedforward neural networks developed in the research group of Jürgen Schmidhuber at the Swiss AI Lab IDSIA have won eight international competitions in pattern recognition and machine learning.http://www.kurzweilai.net/how-bio-inspired-deep-learning-keeps-winning-competitions 2012 Kurzweil AI Interview with Jürgen Schmidhuber on the eight competitions won by his Deep Learning team 2009–2012 For example, multi-dimensional long short term memory (LSTM)Graves, Alex; and Schmidhuber, Jürgen; Offline Handwriting Recognition with Multidimensional Recurrent Neural Networks, in Bengio, Yoshua; Schuurmans, Dale; Lafferty, John; Williams, Chris K. I.; and Culotta, Aron (eds.), Advances in Neural Information Processing Systems 22 (NIPS'22), December 7th–10th, 2009, Vancouver, BC, Neural Information Processing Systems (NIPS) Foundation, 2009, pp. 545–552A. Graves, M. Liwicki, S. Fernandez, R. Bertolami, H. Bunke, J. Schmidhuber. A Novel Connectionist System for Improved Unconstrained Handwriting Recognition. IEEE Transactions on Pattern Analysis and Machine Intelligence,  vol. 31, no. 5, 2009. won three competitions in connected handwriting recognition at the 2009 International Conference on Document Analysis and Recognition (ICDAR), without any prior knowledge about the three different languages to be learned.
Variants of the back-propagation algorithm as well as unsupervised methods by Geoff Hinton and colleagues at the University of Torontohttp://www.scholarpedia.org/article/Deep_belief_networks / can be used to train deep, highly nonlinear neural architectures similar to the 1980 Neocognitron by Kunihiko Fukushima,[tpl]cite journal| author = Fukushima, K. | year = 1980 | title = Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position | journal = Biological Cybernetics | volume=36 | issue=4 | pages=93–202 | doi = 10.1007/BF00344251 | pmid=7370364[/tpl]  and the "standard architecture of vision",M Riesenhuber, T Poggio. Hierarchical models of object recognition in cortex. Nature neuroscience, 1999. inspired by the simple and complex cells identified by David H. Hubel and Torsten Wiesel in the primary visual cortex.
Deep learning feedforward networks, such as convolutional neural networks, alternate convolutional layers and max-pooling layers, topped by several pure classification layers. Fast GPU-based implementations of this approach have won several pattern recognition contests, including the IJCNN 2011 Traffic Sign Recognition CompetitionD. C. Ciresan, U. Meier, J. Masci, J. Schmidhuber. Multi-Column Deep Neural Network for Traffic Sign Classification. Neural Networks, 2012. and the ISBI 2012 Segmentation of Neuronal Structures in Electron Microscopy Stacks challenge.D. Ciresan, A. Giusti, L. Gambardella, J. Schmidhuber. Deep Neural Networks Segment Neuronal Membranes in Electron Microscopy Images. In Advances in Neural Information Processing Systems (NIPS 2012), Lake Tahoe, 2012. Such neural networks also were the first artificial pattern recognizers to achieve human-competitive or even superhuman performanceD. C. Ciresan, U. Meier, J. Schmidhuber. Multi-column Deep Neural Networks for Image Classification. IEEE Conf. on Computer Vision and Pattern Recognition CVPR 2012. on benchmarks such as traffic sign recognition (IJCNN 2012), or the MNIST handwritten digits problem of Yann LeCun and colleagues at NYU.

===Successes in pattern recognition contests since 2009===

Between 2009 and 2012, the recurrent neural networks and deep feedforward neural networks developed in the research group of Jürgen Schmidhuber at the Swiss AI Lab IDSIA have won eight international competitions in pattern recognition and machine learning.2012 Kurzweil AI Interview with Jürgen Schmidhuber on the eight competitions won by his Deep Learning team 2009–2012 For example, the bi-directional and multi-dimensional long short term memory (LSTM)[ref]
Graves, Alex; and Schmidhuber, Jürgen; Offline Handwriting Recognition with Multidimensional Recurrent Neural Networks, in Bengio, Yoshua; Schuurmans, Dale; Lafferty, John; Williams, Chris K. I.; and Culotta, Aron (eds.), Advances in Neural Information Processing Systems 22 (NIPS'22), 7–10 December 2009, Vancouver, BC, Neural Information Processing Systems (NIPS) Foundation, 2009, pp. 545–552.
[/ref][ref]
A. Graves, M. Liwicki, S. Fernandez, R. Bertolami, H. Bunke, J. Schmidhuber. A Novel Connectionist System for Improved Unconstrained Handwriting Recognition. IEEE Transactions on Pattern Analysis and Machine Intelligence,  vol. 31, no. 5, 2009.
[/ref]
of Alex Graves et al. won three competitions in connected handwriting recognition at the 2009 International Conference on Document Analysis and Recognition (ICDAR), without any prior knowledge about the three different languages to be learned.  Fast GPU-based implementations of this approach by Dan Ciresan and colleagues at IDSIA have won several pattern recognition contests, including the IJCNN 2011 Traffic Sign Recognition Competition,[ref]
D. C. Ciresan, U. Meier, J. Masci, J. Schmidhuber. Multi-Column Deep Neural Network for Traffic Sign Classification. Neural Networks, 2012.
[/ref]
the ISBI 2012 Segmentation of Neuronal Structures in Electron Microscopy Stacks challenge,
and others. Their neural networks also were the first artificial pattern recognizers to achieve human-competitive or even superhuman performance
on important benchmarks such as traffic sign recognition (IJCNN 2012), or the MNIST handwritten digits problem of Yann LeCun at NYU. Deep, highly nonlinear neural architectures similar to the 1980 neocognitron by Kunihiko Fukushima
and the "standard architecture of vision"
can also be pre-trained by unsupervised methods[ref]Deep belief networks at Scholarpedia.
[/ref][tpl]cite doi|10.1162/neco.2006.18.7.1527[/tpl]
of Geoff Hinton's lab at University of Toronto. A team from this lab won a 2012 contest sponsored by Merck to design software to help find molecules that might lead to new drugs.[tpl]cite news |url=http://www.nytimes.com/2012/11/24/science/scientists-see-advances-in-deep-learning-a-part-of-artificial-intelligence.html |author=John Markoff |newspaper=New York Times |date=November 23, 2012 |title=Scientists See Promise in Deep-Learning Programs[/tpl]

==Models==

===Network function===

The word network in the term 'artificial neural network' refers to the inter–connections between the neurons in the different layers of each system. An example system has three layers. The first layer has input neurons which send data via synapses to the second layer of neurons, and then via more synapses to the third layer of output neurons. More complex systems will have more layers of neurons with some having increased layers of input neurons and output neurons. The synapses store parameters called "weights" that manipulate the data in the calculations.
An ANN is typically defined by three types of parameters:

===Learning===

====Choosing a cost function====

While it is possible to define some arbitrary ad hoc cost function, frequently a particular cost will be used, either because it has desirable properties (such as convexity) or because it arises naturally from a particular formulation of the problem (e.g., in a probabilistic formulation the posterior probability of the model can be used as an inverse cost). Ultimately, the cost function will depend on the desired task. An overview of the three main categories of learning tasks is provided below:

===Learning paradigms===

There are three major learning paradigm, each corresponding to a particular abstract learning task. These are supervised learning, unsupervised learning and reinforcement learning.

====Supervised learning====

A commonly used cost is the mean-squared error, which tries to minimize the average squared error between the network's output, f(x), and the target value y over all the example pairs. When one tries to minimize this cost using gradient descent for the class of neural networks called multilayer perceptrons, one obtains the common and well-known backpropagation algorithm for training neural networks.
Tasks that fall within the paradigm of supervised learning are pattern recognition (also known as classification) and regression (also known as function approximation). The supervised learning paradigm is also applicable to sequential data (e.g., for speech and gesture recognition). This can be thought of as learning with a "teacher," in the form of a function that provides continuous feedback on the quality of solutions obtained thus far.

====Unsupervised learning====

The cost function is dependent on the task (what we are trying to model) and our a priori assumptions (the implicit properties of our model, its parameters and the observed variables).
Tasks that fall within the paradigm of unsupervised learning are in general estimation problems; the applications include clustering, the estimation of statistical distributions, compression and filtering.

====Reinforcement learning====

ANNs are frequently used in reinforcement learning as part of the overall algorithm.[tpl]cite conference| author = Dominic, S., Das, R., Whitley, D., Anderson, C. |date=July 1991 | title = Genetic reinforcement learning for neural networks | conference = IJCNN-91-Seattle International Joint Conference on Neural Networks | booktitle = IJCNN-91-Seattle International Joint Conference on Neural Networks | publisher = IEEE | location = Seattle, Washington, USA  | url = http://dx.doi.org/10.1109/IJCNN.1991.155315 | doi = 10.1109/IJCNN.1991.155315 | accessdate = 29 July 2012 | isbn = 0-7803-0164-1 [/tpl][tpl]cite journal|last=Hoskins|first=J.C.|author2=Himmelblau, D.M.|title=Process control via artificial neural networks and reinforcement learning|journal=Computers & Chemical Engineering|year=1992|volume=16|pages=241–251|doi=10.1016/0098-1354(92)80045-B|issue=4[/tpl] Dynamic programming has been coupled with ANNs (Neuro dynamic programming) by Bertsekas and Tsitsiklis[tpl]cite book| author = Bertsekas, D.P., Tsitsiklis, J.N. | year = 1996 | title = Neuro-dynamic programming | publisher = Athena Scientific | isbn = 1-886529-10-8 | page = 512 [/tpl] and applied to multi-dimensional nonlinear problems such as those involved in vehicle routing,[tpl]cite journal|last=Secomandi|first=Nicola|title=Comparing neuro-dynamic programming algorithms for the vehicle routing problem with stochastic demands|journal=Computers & Operations Research|year=2000|volume=27|pages=1201–1225|doi=10.1016/S0305-0548(99)00146-X|issue=11–12[/tpl] natural resources management[tpl]cite conference| author = de Rigo, D., Rizzoli, A. E., Soncini-Sessa, R., Weber, E., Zenesi, P. | year = 2001 | title = Neuro-dynamic programming for the efficient management of reservoir networks | conference = MODSIM 2001, International Congress on Modelling and Simulation | conferenceurl = http://www.mssanz.org.au/MODSIM01/MODSIM01.htm | booktitle = Proceedings of MODSIM 2001, International Congress on Modelling and Simulation | publisher = Modelling and Simulation Society of Australia and New Zealand | location = Canberra, Australia | doi = 10.5281/zenodo.7481 | url = https://zenodo.org/record/7482/files/de_Rigo_etal_MODSIM2001_activelink_authorcopy.pdf | accessdate = 29 July 2012 | isbn = 0-867405252 [/tpl][tpl]cite conference| author = Damas, M., Salmeron, M., Diaz, A., Ortega, J., Prieto, A., Olivares, G.| year = 2000 | title = Genetic algorithms and neuro-dynamic programming: application to water supply networks | conference = 2000 Congress on Evolutionary Computation | booktitle = Proceedings of 2000 Congress on Evolutionary Computation | publisher = IEEE | location = La Jolla, California, USA | url = http://dx.doi.org/10.1109/CEC.2000.870269 | doi = 10.1109/CEC.2000.870269 | accessdate = 29 July 2012 | isbn = 0-7803-6375-2  [/tpl] or medicine[tpl]cite journal|last=Deng|first=Geng|author2=Ferris, M.C.|title=Neuro-dynamic programming for fractionated radiotherapy planning|journal=Springer Optimization and Its Applications|year=2008|volume=12|pages=47–70 |doi=10.1007/978-0-387-73299-2_3[/tpl] because of the ability of ANNs to mitigate losses of accuracy even when reducing the discretization grid density for numerically approximating the solution of the original control problems.
Tasks that fall within the paradigm of reinforcement learning are control problems, games and other sequential decision making tasks.

===Learning algorithms===

Training a neural network model essentially means selecting one model from the set of allowed models (or, in a Bayesian framework, determining a distribution over the set of allowed models) that minimizes the cost criterion.  There are numerous algorithms available for training neural network models; most of them can be viewed as a straightforward application of optimization theory and statistical estimation.
Most of the algorithms used in training artificial neural networks employ some form of gradient descent. This is done by simply taking the derivative of the cost function with respect to the network parameters and then changing those parameters in a gradient-related direction.
Evolutionary methods,[ref]
