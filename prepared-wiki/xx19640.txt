[[Cultural bias]]

CATEGORIES: Cognitive biases, Cultural anthropology, Value, Ethnocentrism, Bias

Cultural bias is the phenomenon of interpreting and judging phenomena by standards inherent to one's own culture. The phenomenon is sometimes considered a problem central to social and human sciences, such as economics, psychology, anthropology, and sociology. Some practitioners of the aforementioned fields have attempted to develop methods and theories to compensate for or  a culture make assumptions about conventions, including conventions of language, notation, proof and evidence. They are then accused of mistaking these assumptions for laws of logic or nature. Numerous such biases exist, concerning cultural norms for color, location of body parts, mate selection, concepts of justice, linguistic and logical validity, acceptability of evidence, and taboos. Cultural bias extends on many more fields in the globalizing world. Ordinary people may tend to imagine other people as basically the same, not significantly more or less valuable, probably attached emotionally to different groups and different land. 

==Examples==

People who read English often assume that it is natural to scan a visual field from left to right and from top to bottom. In the United States it is typical for the "on" position of a toggle switch to be "up", whereas in the UK, Australia, and New Zealand it is "down." Also, in these countries, North is the top of a map, up is usually the larger quantity and better, as well. As another example, Japanese do not place an X in a check-box to indicate acceptance—this indicates refusal.
These conventions are generally useful, as once one is used to light switches behaving a certain way one does not need to learn a per-light switch rule but just a general rule. Unfortunately, when people move between cultures or design something for a different group they often do not attend to which conventions remain and which change.
Linguistic and ethnic groups often do not share these notational assumptions. Notational and operative assumptions can change control systems if the users implement, from a different culture than the designers, funnel interpretations from their original world view. Safety-critical systems, according to Seidner (pp. 5–7), become responses to threats of control. Through the emergence of majority and minority categories in society, cultural biases ensue.

==See also==

==Notes==

==References==


