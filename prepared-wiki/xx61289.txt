[[Survey methodology]]

CATEGORIES: Survey methodology, Marketing, Market research, Psychometrics, Research methods, Quantitative research, Evaluation methods, Data collection, Sampling (statistics), Sociology index

A field of applied statistics, survey methodology studies the sampling of individual units from a population and the associated survey data collection techniques, such as questionnaire construction and methods for improving the number and accuracy of responses to surveys.
Statistical surveys are undertaken with a view towards making statistical inferences about the population being studied, and this depends strongly on the survey questions used.  Polls about public opinion, public health surveys, market research surveys, government surveys and censuses are all examples of quantitative research that use contemporary survey methodology to answer questions about a population. Although censuses do not include a "sample", they do include other aspects of survey methodology, like questionnaires, interviewers, and nonresponse follow-up techniques. Surveys provide important information for  all kinds of public information and research fields, e.g., marketing research, psychology, health professionals and sociology.[tpl]cite web|url=http://whatisasurvey.info/ |title=WhatIsASurvey.info |publisher=WhatIsASurvey.info |date= |accessdate=2013-10-03[/tpl]

==Overview==

A single survey is made of at least a sample (or full population in the case of a census), a method of data collection (e.g., a questionnaire) and individual questions or items that become data that can be analyzed statistically. A single survey may focus on different types of topics such as preferences (e.g., for a presidential candidate), opinions (e.g., should abortion be legal?), behavior (smoking and alcohol use), or factual information (e.g., income), depending on its purpose. Since survey research is almost always based on a sample of the population, the success of the research is dependent on the representativeness of the sample with respect to a target population of interest to the researcher. That target population can range from the general population of a given country to specific groups of people within that country, to a membership list of a professional organization, or list of students enrolled in a school system  (see also sampling (statistics) and survey sampling).
Survey methodology as a scientific field seeks to identify principles about the sample design, data collection instruments, statistical adjustment of data, and data processing, and final data analysis that can create systematic and random survey errors. Survey errors are sometimes analyzed in connection with survey cost. Cost constraints are sometimes framed as improving quality within cost constraints, or alternatively, reducing costs for a fixed level of quality. Survey methodology is both a scientific field and a profession, meaning that some professionals in the field focus on survey errors empirically and others design surveys to reduce them. For survey designers, the task involves making a large set of decisions about thousands of individual features of a survey in order to improve it.

==Survey methodology topics==

The most important methodological challenges of a survey methodologist include making decisions on how to:

===Selecting samples===

Survey samples can be broadly divided into two types: probability samples and non-probability samples. Stratified sampling is a method of probability sampling such that sub-populations within an overall population are identified and included in the sample selected in a balanced way.

===Modes of data collection===

There are several ways of administering a survey. The choice between administration modes is influenced by several factors, including
Different methods create mode effects that change how respondents answer, and different methods have different advantages. The most common modes of administration can be summarized as:Mellenbergh, G.J. (2008). Chapter 9: Surveys. In H.J. Adèr & G.J. Mellenbergh (Eds.) (with contributions by D.J. Hand), Advising on Research Methods: A consultant's companion (pp. 183–209). Huizen, The Netherlands: Johannes van Kessel Publishing.

===Cross-sectional and longitudinal surveys===

There is a distinction between one-time (cross-sectional) surveys, which involve a single questionnaire or interview administered to each sample member, and surveys which repeatedly collect information from the same people over time. The latter are known as longitudinal surveys. Longitudinal surveys have considerable analytical advantages but they are also challenging to implement successfully.
Consequently, specialist methods have been developed to select longitudinal samples, to collect data repeatedly, to keep track of sample members over time, to keep respondents motivated to participate, and to process and analyse longitudinal survey data  Lynn, P. (2009) (Ed.) Methodology of Longitudinal Surveys. Wiley. ISBN 0-470-01871-2

===Response formats===

Usually, a survey consists of a number of questions that the respondent has to answer in a set format. A distinction is made between open-ended and closed-ended questions. An open-ended question asks the respondent to formulate his or her own answer, whereas a closed-ended question has the respondent pick an answer from a given number of options. The response options for a closed-ended question should be exhaustive and mutually exclusive. Four types of response scales for closed-ended questions are distinguished:
A respondent's answer to an open-ended question can be coded into a response scale afterwards, or analysed using more qualitative methods.

===Nonresponse reduction===

The following ways have been recommended for reducing nonresponseLynn, P. (2008) "The problem of non-response", chapter 3, 35-55, in International Handbook of Survey Methodology (ed.s E.de Leeuw, J.Hox & D.Dillman). Erlbaum. ISBN 0-8058-5753-2 in telephone and face-to-face surveys:Dillman, D.A. (1978) Mail and telephone surveys: The total design method. Wiley. ISBN 0-471-21555-4
Brevity is also often cited as increasing response rate.  A 1996 literature review found mixed evidence to support this claim for both written and verbal surveys, concluding that other factors may often be more important.[tpl]cite journal|title=THE EFFECT OF QUESTIONNAIRE LENGTH ON RESPONSE RATES -- A REVIEW OF THE LITERATURE|url=http://www.census.gov/srd/papers/pdf/kb9601.pdf|journal=Proceedings of the Section on Survey Research Methods|publisher=American Statistical Association|accessdate=2013-03-19|pages=1020–1025|last=Bogen|first=Karen|year=1996[/tpl]
A 2010 study by SurveyMonkey looking at 100,000 of the online surveys they host found response rate dropped by about 3% at 10 questions and about 6% at 20 questions, with dropoff slowing (for example, only 10% reduction at 40 questions)[tpl]cite web|url=http://blog.surveymonkey.com/blog/2010/12/08/survey_questions_and_completion_rates/|accessdate=2013-03-19|date=2010-12-10|title=Does Adding One More Question Impact Survey Completion Rate?[/tpl]
Other studies showed that quality of response degraded toward the end of long surveys.[tpl]cite news|url=http://www.research-live.com/news/news-headlines/respondent-engagement-and-survey-length-the-long-and-the-short-of-it/4002430.article |title=Respondent engagement and survey length: the long and the short of it |publisher=research |date=April 7, 2010 |accessdate=2013-10-03[/tpl]

===Interviewer effects===

Survey methodologists have devoted much effort to determine the extent to which interviewee responses are affected by physical characteristics of the interviewer. Main interviewer traits that have been demonstrated to influence survey responses are race,
[tpl]cite journal|first1=M.E|last1=Hill|title= Race of the interviewer and perception of skin color: Evidence from the multi-city study of urban inequality |journal=American Sociological Review|year=2002|volume=67|issue=1|pages=99–108|jstor=3088935|doi=10.2307/3088935[/tpl] gender
[tpl]cite journal|first1=F.|last1=Flores-Macias|first2=C.|last2=Lawson|title=Effects of interviewer gender on survey responses: Findings from a household survey in Mexico|journal=International Journal of Public Opinion Research|year=2008|volume=20|issue=1|pages=100–110|doi= 10.1093/ijpor/edn007[/tpl]
and relative body weight (BMI)
.[tpl]cite journal|first1=R.|last1=Eisinga|first2=M.|last2=Te Grotenhuis|first3=J.K.|last3=Larsen|first4=B.|last4=Pelzer|first5=T.|last5=Van Strien|title=BMI of interviewer effects|journal= International Journal of Public Opinion Research|year=2011|volume=23|issue=4|pages=530–543|doi=10.1093/ijpor/edr026[/tpl]
These interviewer effects are particularly operant when questions are related to the interviewer trait. Hence, race of interviewer has been shown to affect responses to measures regarding racial attitudes
,[tpl]cite journal|first1=B.A.|last1=Anderson|first2=B.D.|last2=Silver|first3=P.R.|title=The effects of the race of the interviewer on race-related attitudes of black respondents in SRC/CPS national election studies |journal= Public Opinion Quarterly |year=1988|volume=52|issue=3|pages=1–28|doi=10.1086/269108|last3=Abramson[/tpl]
interviewer sex responses to questions involving gender issues
,[tpl]cite journal|first1=E.W.|last1=Kane|first2=L.J.|last2=MacAulay|title= Interviewer gender and gender attitudes|journal= Public Opinion Quarterly |year=1993|volume=57|issue=1|pages=1–28|doi=10.1086/269352[/tpl]
and interviewer BMI answers to eating and dieting-related questions
.[tpl]cite journal|first1=R.|last1=Eisinga|first2=M.|last2=Te Grotenhuis|first3=J.K.|last3=Larsen|first4=B.|last4=Pelzer|title= Interviewer BMI effects on under- and over-reporting of restrained eating. Evidence from a national Dutch face-to-face survey and a postal follow-up |journal= International Journal of Public Health|year=2011|volume=57|issue=3|pages=643–647|doi= 10.1007/s00038-011-0323-z|pmid=22116390|pmc=3359459[/tpl]
While interviewer effects have been investigated mainly for face-to-face surveys, they have also been shown to exist for interview modes with no visual contact, such as telephone surveys and in video-enhanced web surveys. The explanation typically provided for interviewer effects is that of social desirability. Survey participants may attempt to project a positive self-image in an effort to conform to the norms they attribute to the interviewer asking questions.

==See also==

==References==

==Further reading==

==External links==


