[[Bayes' rule]]

CATEGORIES: Bayesian inference, Model selection, Statistical ratios

==The rule==

===Single event===

where
Here, the odds and conditional odds, also known as prior odds and posterior odds, are defined by 

===Many events===

In words posterior is proportional to prior times likelihood. This version of Bayes' theorem was first called "Bayes' rule" by Cournot (1843). Cournot popularized the earlier work of Laplace (1774) who had independently discovered Bayes' rule.  The work of Bayes was published posthumously (1763) but remained more or less unknown till Cournot drew attention to it; see Fienberg (2006).
In Bayesian statistics, Bayes' rule is often applied with a so-called improper prior, for instance, a uniform probability distribution over all real numbers. In that case, the prior distribution does not exist as a probability measure within conventional probability theory, and Bayes' theorem itself is not available.

===Series of events===

where

==Derivation==

Consider two instances of Bayes' theorem:
Combining these gives
Now defining
this implies
A similar derivation applies for conditioning on multiple events, using the appropriate extension of Bayes' theorem

==Examples==

===Frequentist example=== 
Consider the drug testing example in the article on Bayes' theorem.

===Model selection===

==External links==


