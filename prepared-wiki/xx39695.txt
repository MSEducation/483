[[Alpha–beta pruning]]

CATEGORIES: Game artificial intelligence, Graph algorithms, Optimization algorithms and methods, Search algorithms, Articles with example pseudocode

Alpha–beta pruning is a search algorithm that seeks to decrease the number of nodes that are evaluated by the minimax algorithm in its search tree. It is an adversarial search algorithm used commonly for machine playing of two-player games (Tic-tac-toe, Chess, Go, etc.). It stops completely evaluating a move when at least one possibility has been found that proves the move to be worse than a previously examined move. Such moves need not be evaluated further. When applied to a standard minimax tree, it returns the same move as minimax would, but prunes away branches that cannot possibly influence the final decision.

==History==

Allen Newell and Herbert A. Simon who used what John McCarthy calls an "approximation" in 1958 wrote that alpha–beta "appears to have been reinvented a number of times". Arthur Samuel had an early version and Richards, Hart, Levine and/or Edwards found alpha–beta independently in the United States. McCarthy proposed similar ideas during the Dartmouth Conference in 1956 and suggested it to a group of his students including Alan Kotok at MIT in 1961.[tpl]cite web | last=Kotok | first=Alan | title=MIT Artificial Intelligence Memo 41 | date=XHTML 3 December 2004 | url=http://www.kotok.org/AI_Memo_41.html | accessdate=2006-07-01[/tpl] Alexander Brudno independently discovered the alpha–beta algorithm, publishing his results in 1963. Donald Knuth and Ronald W. Moore refined the algorithm in 1975[ref]* 

 | last = Knuth
 | first = Donald E.
 | title = Selected Papers on Analysis of Algorithms
 | year = 2000
 | publisher = Stanford, California: Center for the Study of Language and Information - CSLI Lecture Notes, no. 102
 | url = http://www-cs-faculty.stanford.edu/~knuth/aa.html
 | isbn = 1-57586-212-3
 | oclc = 222512366
}}[/ref][ref]
 [tpl]Dead link|date=September 2010|bot=H3llBot[/tpl][/ref] and Judea Pearl proved its optimality in 1982.[tpl]cite journal|last=Pearl|first=Judea|title=The Solution for the Branching Factor of the Alpha–beta Pruning Algorithm and its Optimality|journal=Communications of the ACM|date=August 1982|volume=25|issue=8|pages=559–564|doi=10.1145/358589.358616[/tpl]

==Improvements over naive minimax==

The benefit of alpha–beta pruning lies in the fact that branches of the search tree can be eliminated. This way, the search time can be limited to the 'more promising' subtree, and a deeper search can be performed in the same time. Like its predecessor, it belongs to the branch and bound class of algorithms. The optimization reduces the effective depth to slightly more than half that of simple minimax if the nodes are evaluated in an optimal or near optimal order (best choice for side on move ordered first at each node).
the average number of nodes evaluated is roughly
Normally during alpha–beta, the subtrees are temporarily dominated by either a first player advantage (when many first player moves are good, and at each search depth the first move checked by the first player is adequate, but all second player responses are required to try to find a refutation), or vice versa. This advantage can switch sides many times during the search if the move ordering is incorrect, each time leading to inefficiency. As the number of positions searched decreases exponentially each move nearer the current position, it is worth spending considerable effort on sorting early moves. An improved sort at any depth will exponentially reduce the total number of positions searched, but sorting all positions at depths near the root node is relatively cheap as there are so few of them.  In practice, the move ordering is often determined by the results of earlier, smaller searches, such as through iterative deepening.
The algorithm maintains two values, alpha and beta, which represent the maximum score that the maximizing player is assured of and the minimum score that the minimizing player is assured of respectively. Initially alpha is negative infinity and beta is positive infinity, i.e. both players start with their lowest possible score. It can happen that when choosing a certain branch of a certain node the minimum score that the minimizing player is assured of becomes less than the maximum score that the maximizing player is assured of (betaAdditionally, this algorithm can be trivially modified to return an entire principal variation in addition to the score. Some more aggressive algorithms such as MTD(f) do not easily permit such a modification.

==Pseudocode==

 01 '''function''' alphabeta(node, depth, α, β, maximizingPlayer)
 02      '''if''' depth = 0 '''or''' node is a terminal node
 03          '''return''' the heuristic valuea of node
 04      '''if''' maximizingPlayer
 05          '''for each''' child of node
 06              α := max(α, alphabeta(child, depth - 1, α, β, FALSE))
 07              '''if''' β ≤ α
 08                  '''break''' ''(* β cut-off *)''
 09          '''return''' α
 10      '''else'''
 11          '''for each''' child of node
 12              β := min(β, alphabeta(child, depth - 1, α, β, TRUE))
 13              '''if''' β ≤ α
 14                  '''break''' ''(* α cut-off *)''
 15          '''return''' β
 '''''(* Initial call *)'''''
