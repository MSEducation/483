<!DOCTYPE HTML>
<html lang="en">
<head>
<!-- Generated by javadoc (21) on Fri Apr 04 15:37:48 CEST 2025 -->
<title>Overview (Lucene 10.2.0 icu API)</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="dc.created" content="2025-04-04">
<meta name="description" content="package index">
<meta name="generator" content="javadoc/PackageIndexWriter">
<link rel="stylesheet" type="text/css" href="stylesheet.css" title="Style">
<link rel="stylesheet" type="text/css" href="script-dir/jquery-ui.min.css" title="Style">
<script type="text/javascript" src="script.js"></script>
<script type="text/javascript" src="script-dir/jquery-3.6.1.min.js"></script>
<script type="text/javascript" src="script-dir/jquery-ui.min.js"></script>
</head>
<body class="package-index-page">
<script type="text/javascript">var pathtoroot = "./";
loadScripts(document, 'script');</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<div class="flex-box">
<header role="banner" class="flex-header">
<nav role="navigation">
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="top-nav" id="navbar-top"><button id="navbar-toggle-button" aria-controls="navbar-top" aria-expanded="false" aria-label="Toggle navigation links"><span class="nav-bar-toggle-icon">&nbsp;</span><span class="nav-bar-toggle-icon">&nbsp;</span><span class="nav-bar-toggle-icon">&nbsp;</span></button>
<div class="skip-nav"><a href="#skip-navbar-top" title="Skip navigation links">Skip navigation links</a></div>
<ul id="navbar-top-firstrow" class="nav-list" title="Navigation">
<li class="nav-bar-cell1-rev">Overview</li>
<li>Package</li>
<li>Class</li>
<li>Use</li>
<li><a href="overview-tree.html">Tree</a></li>
<li><a href="index-all.html">Index</a></li>
<li><a href="help-doc.html#overview">Help</a></li>
</ul>
</div>
<div class="sub-nav">
<div id="navbar-sub-list"></div>
<div class="nav-list-search"><a href="search.html">SEARCH</a>
<input type="text" id="search-input" disabled placeholder="Search">
<input type="reset" id="reset-button" disabled value="reset">
</div>
</div>
<!-- ========= END OF TOP NAVBAR ========= -->
<span class="skip-nav" id="skip-navbar-top"></span></nav>
</header>
<div class="flex-content">
<main role="main">
<div class="header">
<h1 class="title">Lucene 10.2.0 icu API</h1>
</div>
<div class="block"><p>
This module exposes functionality from 
<a href="http://site.icu-project.org/">ICU</a> to Apache Lucene. ICU4J is a Java
library that enhances Java's internationalization support by improving 
performance, keeping current with the Unicode Standard, and providing richer
APIs. 
<p>
For an introduction to Lucene's analysis API, see the <a href="../../core/org/apache/lucene/analysis/package-summary.html" class="external-link"><code>org.apache.lucene.analysis</code></a> package documentation.
<p>
This module exposes the following functionality:
</p>
<ul>
  <li><a href="#segmentation">Text Segmentation</a>: Tokenizes text based on 
  properties and rules defined in Unicode.</li>
  <li><a href="#collation">Collation</a>: Compare strings according to the 
  conventions and standards of a particular language, region or country.</li>
  <li><a href="#normalization">Normalization</a>: Converts text to a unique,
  equivalent form.</li>
  <li><a href="#casefolding">Case Folding</a>: Removes case distinctions with
  Unicode's Default Caseless Matching algorithm.</li>
  <li><a href="#searchfolding">Search Term Folding</a>: Removes distinctions
  (such as accent marks) between similar characters for a loose or fuzzy search.</li>
  <li><a href="#transform">Text Transformation</a>: Transforms Unicode text in
  a context-sensitive fashion: e.g. mapping Traditional to Simplified Chinese</li>
</ul>
<hr>
<h1><a id="segmentation">Text Segmentation</a></h1>
<p>
Text Segmentation (Tokenization) divides document and query text into index terms
(typically words). Unicode provides special properties and rules so that this can
be done in a manner that works well with most languages.
</p>
<p>
Text Segmentation implements the word segmentation specified in
<a href="http://unicode.org/reports/tr29/">Unicode Text Segmentation</a>.
Additionally the algorithm can be tailored based on writing system, for example
text in the Thai script is automatically delegated to a dictionary-based segmentation 
algorithm.
</p>
<h2 id="use-cases-heading">Use Cases</h2>
<ul>
  <li>
    As a more thorough replacement for StandardTokenizer that works well for
    most languages. 
  </li>
</ul>
<h2 id="example-usages-heading">Example Usages</h2>
<h3 id="tokenizing-multilanguage-text-heading">Tokenizing multilanguage text</h3>
<pre class="prettyprint">
  /**
   * This tokenizer will work well in general for most languages.
   */
  Tokenizer tokenizer = new ICUTokenizer(reader);
</pre>
<hr>
<h1><a id="collation">Collation</a></h1>
<p>
  <code>ICUCollationKeyAnalyzer</code>
  converts each token into its binary <code>CollationKey</code> using the 
  provided <code>Collator</code>, allowing it to be 
  stored as an index term.
</p>
<p>
  <code>ICUCollationKeyAnalyzer</code> depends on ICU4J to produce the 
  <code>CollationKey</code>s.
</p>

<h2 id="use-cases-heading1">Use Cases</h2>

<ul>
  <li>
    Efficient sorting of terms in languages that use non-Unicode character 
    orderings.  (Lucene Sort using a Locale can be very slow.) 
  </li>
  <li>
    Efficient range queries over fields that contain terms in languages that 
    use non-Unicode character orderings.  (Range queries using a Locale can be
    very slow.)
  </li>
  <li>
    Effective Locale-specific normalization (case differences, diacritics, etc.).
    (<a href="../../core/org/apache/lucene/analysis/LowerCaseFilter.html" title="class or interface in org.apache.lucene.analysis" class="external-link"><code>LowerCaseFilter</code></a> and 
    <a href="../common/org/apache/lucene/analysis/miscellaneous/ASCIIFoldingFilter.html" title="class or interface in org.apache.lucene.analysis.miscellaneous" class="external-link"><code>ASCIIFoldingFilter</code></a> provide these services
    in a generic way that doesn't take into account locale-specific needs.)
  </li>
</ul>

<h2 id="example-usages-heading1">Example Usages</h2>

<h3 id="farsi-range-queries-heading">Farsi Range Queries</h3>
<pre class="prettyprint">
  Collator collator = Collator.getInstance(new ULocale("ar"));
  ICUCollationKeyAnalyzer analyzer = new ICUCollationKeyAnalyzer(collator);
  Path indexPath = Files.createTempDirectory("tempIndex");
  Directory dir = FSDirectory.open(indexPath);
  IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(analyzer));
  Document doc = new Document();
  doc.add(new Field("content", "\u0633\u0627\u0628", 
                    Field.Store.YES, Field.Index.ANALYZED));
  writer.addDocument(doc);
  writer.close();
  IndexSearcher is = new IndexSearcher(dir, true);

  QueryParser aqp = new QueryParser("content", analyzer);
  aqp.setAnalyzeRangeTerms(true);
    
  // Unicode order would include U+0633 in [ U+062F - U+0698 ], but Farsi
  // orders the U+0698 character before the U+0633 character, so the single
  // indexed Term above should NOT be returned by a ConstantScoreRangeQuery
  // with a Farsi Collator (or an Arabic one for the case when Farsi is not
  // supported).
  ScoreDoc[] result
    = is.search(aqp.parse("[ \u062F TO \u0698 ]"), null, 1000).scoreDocs;
  assertEquals("The index Term should not be included.", 0, result.length);
</pre>

<h3 id="danish-sorting-heading">Danish Sorting</h3>
<pre class="prettyprint">
  Analyzer analyzer 
    = new ICUCollationKeyAnalyzer(Collator.getInstance(new ULocale("da", "dk")));
  Path indexPath = Files.createTempDirectory("tempIndex");
  Directory dir = FSDirectory.open(indexPath);
  IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(analyzer));
  String[] tracer = new String[] { "A", "B", "C", "D", "E" };
  String[] data = new String[] { "HAT", "HUT", "H\u00C5T", "H\u00D8T", "HOT" };
  String[] sortedTracerOrder = new String[] { "A", "E", "B", "D", "C" };
  for (int i = 0 ; i &lt; data.length ; ++i) {
    Document doc = new Document();
    doc.add(new Field("tracer", tracer[i], Field.Store.YES, Field.Index.NO));
    doc.add(new Field("contents", data[i], Field.Store.NO, Field.Index.ANALYZED));
    writer.addDocument(doc);
  }
  writer.close();
  IndexSearcher searcher = new IndexSearcher(dir, true);
  Sort sort = new Sort();
  sort.setSort(new SortField("contents", SortField.STRING));
  Query query = new MatchAllDocsQuery();
  ScoreDoc[] result = searcher.search(query, null, 1000, sort).scoreDocs;
  for (int i = 0 ; i &lt; result.length ; ++i) {
    Document doc = searcher.doc(result[i].doc);
    assertEquals(sortedTracerOrder[i], doc.getValues("tracer")[0]);
  }
</pre>

<h3 id="turkish-case-normalization-heading">Turkish Case Normalization</h3>
<pre class="prettyprint">
  Collator collator = Collator.getInstance(new ULocale("tr", "TR"));
  collator.setStrength(Collator.PRIMARY);
  Analyzer analyzer = new ICUCollationKeyAnalyzer(collator);
  Path indexPath = Files.createTempDirectory("tempIndex");
  Directory dir = FSDirectory.open(indexPath);
  IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(analyzer));
  Document doc = new Document();
  doc.add(new Field("contents", "DIGY", Field.Store.NO, Field.Index.ANALYZED));
  writer.addDocument(doc);
  writer.close();
  IndexSearcher is = new IndexSearcher(dir, true);
  QueryParser parser = new QueryParser("contents", analyzer);
  Query query = parser.parse("d\u0131gy");   // U+0131: dotless i
  ScoreDoc[] result = is.search(query, null, 1000).scoreDocs;
  assertEquals("The index Term should be included.", 1, result.length);
</pre>

<h2 id="caveats-and-comparisons-heading">Caveats and Comparisons</h2>
<p>
  <strong>WARNING:</strong> Make sure you use exactly the same 
  <code>Collator</code> at index and query time -- <code>CollationKey</code>s
  are only comparable when produced by
  the same <code>Collator</code>.  Since <a href="https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/text/RuleBasedCollator.html" title="class or interface in java.text" class="external-link"><code>RuleBasedCollator</code></a>s
  are not independently versioned, it is unsafe to search against stored
  <code>CollationKey</code>s unless the following are exactly the same (best 
  practice is to store this information with the index and check that they
  remain the same at query time):
</p>
<ol>
  <li>JVM vendor</li>
  <li>JVM version, including patch version</li>
  <li>
    The language (and country and variant, if specified) of the Locale
    used when constructing the collator via
    <a href="https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/text/Collator.html#getInstance-java.util.Locale-" title="class or interface in java.text" class="external-link"><code>Collator.getInstance(java.util.Locale)</code></a>.
  </li>
  <li>
    The collation strength used - see <a href="https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/text/Collator.html#setStrength-int-" title="class or interface in java.text" class="external-link"><code>Collator.setStrength(int)</code></a>
  </li>
</ol> 
<p>
  <code>ICUCollationKeyAnalyzer</code> uses ICU4J's <code>Collator</code>, which 
  makes its version available, thus allowing collation to be versioned
  independently from the JVM.  <code>ICUCollationKeyAnalyzer</code> is also 
  significantly faster and generates significantly shorter keys than 
  <code>CollationKeyAnalyzer</code>.  See
  <a href="http://site.icu-project.org/charts/collation-icu4j-sun">http://site.icu-project.org/charts/collation-icu4j-sun</a> for key
  generation timing and key length comparisons between ICU4J and
  <code>java.text.Collator</code> over several languages.
</p>
<p>
  <code>CollationKey</code>s generated by <code>java.text.Collator</code>s are 
  not compatible with those those generated by ICU Collators.  Specifically, if
  you use <code>CollationKeyAnalyzer</code> to generate index terms, do not use
  <code>ICUCollationKeyAnalyzer</code> on the query side, or vice versa.
</p>
<hr>
<h1><a id="normalization">Normalization</a></h1>
<p>
  <code>ICUNormalizer2Filter</code> normalizes term text to a 
  <a href="http://unicode.org/reports/tr15/">Unicode Normalization Form</a>, so 
  that <a href="http://en.wikipedia.org/wiki/Unicode_equivalence">equivalent</a>
  forms are standardized to a unique form.
</p>
<h2 id="use-cases-heading2">Use Cases</h2>
<ul>
  <li> Removing differences in width for Asian-language text. 
  </li>
  <li> Standardizing complex text with non-spacing marks so that characters are 
  ordered consistently.
  </li>
</ul>
<h2 id="example-usages-heading2">Example Usages</h2>
<h3 id="normalizing-text-to-nfc-heading">Normalizing text to NFC</h3>
<pre class="prettyprint">
  /**
   * Normalizer2 objects are unmodifiable and immutable.
   */
  Normalizer2 normalizer = Normalizer2.getInstance(null, "nfc", Normalizer2.Mode.COMPOSE);
  /**
   * This filter will normalize to NFC.
   */
  TokenStream tokenstream = new ICUNormalizer2Filter(tokenizer, normalizer);
</pre>
<hr>
<h1><a id="casefolding">Case Folding</a></h1>
<p>
Default caseless matching, or case-folding is more than just conversion to
lowercase. For example, it handles cases such as the Greek sigma, so that
"Μάϊος" and "ΜΆΪΟΣ" will match correctly.
</p>
<p>
Case-folding is still only an approximation of the language-specific rules
governing case. If the specific language is known, consider using
ICUCollationKeyFilter and indexing collation keys instead. This implementation
performs the "full" case-folding specified in the Unicode standard, and this
may change the length of the term. For example, the German ß is case-folded
to the string 'ss'.
</p>
<p>
Case folding is related to normalization, and as such is coupled with it in
this integration. To perform case-folding, you use normalization with the form
"nfkc_cf" (which is the default).
</p>
<h2 id="use-cases-heading3">Use Cases</h2>
<ul>
  <li>
    As a more thorough replacement for LowerCaseFilter that has good behavior
    for most languages.
  </li>
</ul>
<h2 id="example-usages-heading3">Example Usages</h2>
<h3 id="lowercasing-text-heading">Lowercasing text</h3>
<pre class="prettyprint">
  /**
   * This filter will case-fold and normalize to NFKC.
   */
  TokenStream tokenstream = new ICUNormalizer2Filter(tokenizer);
</pre>
<hr>
<h1><a id="searchfolding">Search Term Folding</a></h1>
<p>
Search term folding removes distinctions (such as accent marks) between 
similar characters. It is useful for a fuzzy or loose search.
</p>
<p>
Search term folding implements many of the foldings specified in
<a href="http://www.unicode.org/reports/tr30/tr30-4.html">Character Foldings</a>
as a special normalization form.  This folding applies NFKC, Case Folding, and
many character foldings recursively.
</p>
<h2 id="use-cases-heading4">Use Cases</h2>
<ul>
  <li>
    As a more thorough replacement for ASCIIFoldingFilter and LowerCaseFilter 
    that applies the same ideas to many more languages. 
  </li>
</ul>
<h2 id="example-usages-heading4">Example Usages</h2>
<h3 id="removing-accents-heading">Removing accents</h3>
<pre class="prettyprint">
  /**
   * This filter will case-fold, remove accents and other distinctions, and
   * normalize to NFKC.
   */
  TokenStream tokenstream = new ICUFoldingFilter(tokenizer);
</pre>
<hr>
<h1><a id="transform">Text Transformation</a></h1>
<p>
ICU provides text-transformation functionality via its Transliteration API. This allows
you to transform text in a variety of ways, taking context into account.
</p>
<p>
For more information, see the 
<a href="http://userguide.icu-project.org/transforms/general">User's Guide</a>
and 
<a href="http://userguide.icu-project.org/transforms/general/rules">Rule Tutorial</a>.
</p>
<h2 id="use-cases-heading5">Use Cases</h2>
<ul>
  <li>
    Convert Traditional to Simplified 
  </li>
  <li>
    Transliterate between different writing systems: e.g. Romanization
  </li>
</ul>
<h2 id="example-usages-heading5">Example Usages</h2>
<h3 id="convert-traditional-to-simplified-heading">Convert Traditional to Simplified</h3>
<pre class="prettyprint">
  /**
   * This filter will map Traditional Chinese to Simplified Chinese
   */
  TokenStream tokenstream = new ICUTransformFilter(tokenizer, Transliterator.getInstance("Traditional-Simplified"));
</pre>
<h3 id="transliterate-serbian-cyrillic-to-serbian-latin-heading">Transliterate Serbian Cyrillic to Serbian Latin</h3>
<pre class="prettyprint">
  /**
   * This filter will map Serbian Cyrillic to Serbian Latin according to BGN rules
   */
  TokenStream tokenstream = new ICUTransformFilter(tokenizer, Transliterator.getInstance("Serbian-Latin/BGN"));
</pre>
<hr>
<h1><a id="backcompat">Backwards Compatibility</a></h1>
<p>
This module exists to provide up-to-date Unicode functionality that supports
the most recent version of Unicode (currently 15.1). However, some users who wish
for stronger backwards compatibility can restrict
<a href="org/apache/lucene/analysis/icu/ICUNormalizer2Filter.html" title="class in org.apache.lucene.analysis.icu"><code>ICUNormalizer2Filter</code></a> to operate on only
a specific Unicode Version by using a <code>FilteredNormalizer2</code>. 
</p>
<h2 id="example-usages-heading6">Example Usages</h2>
<h3 id="restricting-normalization-to-unicode-5-0-heading">Restricting normalization to Unicode 5.0</h3>
<pre class="prettyprint">
  /**
   * This filter will do NFC normalization, but will ignore any characters that
   * did not exist as of Unicode 5.0. Because of the normalization stability policy
   * of Unicode, this is an easy way to force normalization to a specific version.
   */
    Normalizer2 normalizer = Normalizer2.getInstance(null, "nfc", Normalizer2.Mode.COMPOSE);
    UnicodeSet set = new UnicodeSet("[:age=5.0:]");
    // see FilteredNormalizer2 docs, the set should be frozen or performance will suffer
    set.freeze(); 
    FilteredNormalizer2 unicode50 = new FilteredNormalizer2(normalizer, set);
    TokenStream tokenstream = new ICUNormalizer2Filter(tokenizer, unicode50);
</pre></div>
<div id="all-packages-table">
<div class="caption"><span>Packages</span></div>
<div class="summary-table two-column-summary">
<div class="table-header col-first">Package</div>
<div class="table-header col-last">Description</div>
<div class="col-first even-row-color all-packages-table all-packages-table-tab1"><a href="org/apache/lucene/analysis/icu/package-summary.html">org.apache.lucene.analysis.icu</a></div>
<div class="col-last even-row-color all-packages-table all-packages-table-tab1">
<div class="block">Analysis components based on ICU</div>
</div>
<div class="col-first odd-row-color all-packages-table all-packages-table-tab1"><a href="org/apache/lucene/analysis/icu/segmentation/package-summary.html">org.apache.lucene.analysis.icu.segmentation</a></div>
<div class="col-last odd-row-color all-packages-table all-packages-table-tab1">
<div class="block">Tokenizer that breaks text into words with the Unicode Text Segmentation algorithm.</div>
</div>
<div class="col-first even-row-color all-packages-table all-packages-table-tab1"><a href="org/apache/lucene/analysis/icu/tokenattributes/package-summary.html">org.apache.lucene.analysis.icu.tokenattributes</a></div>
<div class="col-last even-row-color all-packages-table all-packages-table-tab1">
<div class="block">Additional ICU-specific Attributes for text analysis.</div>
</div>
</div>
</div>
</main>
<footer role="contentinfo">
<hr>
<p class="legal-copy"><small><i>Copyright &copy; 2000-2025 Apache Software Foundation. All Rights Reserved.</i></small></p>
</footer>
</div>
</div>
</body>
</html>
