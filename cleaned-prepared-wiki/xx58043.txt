[[Server farm]]

CATEGORIES: Cluster computing, Server hardware, Servers (computing), Fault-tolerant computer systems

A server farm or server cluster is a collection of computer servers usually maintained by an enterprise to accomplish server needs far beyond the capability of one machine. Server farms often consist of thousands of computers which require a large amount of power to run and keep cool. At the optimum performance level, a server farm has enormous costs associated with it, both financially and environmentally.  Server farms often have backup servers, which can take over the function of primary servers in the event of a primary server failure. Server farms are typically collocated with the network switches and/or routers which enable communication between the different parts of the cluster and the users of the cluster. The computers, routers, power supplies, and related electronics are typically mounted on 19-inch racks in a server room or data center.

Applications

Server farms are commonly used for cluster computing. Many modern supercomputers comprise giant server farms of high-speed processors connected by either Gigabit Ethernet or custom interconnects such as Infiniband or Myrinet. Web hosting is a common use of a server farm; such a system is sometimes collectively referred to as a web farm. Other uses of server farms include scientific simulations (such as computational fluid dynamics) and the rendering of 3D computer generated imagery (also see render farm).
Server farms are increasingly being used instead of or in addition to mainframe computers by large enterprises, although server farms do not yet reach the same reliability levels as mainframes. Because of the sheer number of computers in large server farms, the failure of an individual machine is a commonplace event, and the management of large server farms needs to take this into account by providing support for redundancy, automatic failover, and rapid reconfiguration of the server cluster.

Performance

The performance of the largest server farms (thousands of processors and up) is typically limited by the performance of the data center's cooling systems and the  total electricity cost rather than by the performance of the processors. Computers in server farms run 24/7 and consume large amounts of electricity, for this reason, the critical design parameter for both large and continuous systems tends to be performance per watt rather than cost of peak performance or (peak performance / (unit * initial cost)). Also, for high availability systems that must run 24/7 (unlike supercomputers that can be power-cycled to demand, and also tend to run at much higher utilizations), there is more attention placed on power saving features such as variable clock-speed and the ability to turn off both computer parts, processor parts, and entire computers (WoL and virtualization) according to demand without bringing down services.

Performance per watt

The EEMBC EnergyBench, SPECpower, and the Transaction Processing Performance Council TPC-Energy are benchmarks designed to predict performance per watt in a server farm. The power used by each rack of equipment can be measured at the power distribution unit.
Some servers include power tracking hardware so the people running the server farm can measure the power used by each server. The power used by the entire server farm may be reported in terms of power usage effectiveness or data center infrastructure efficiency.
According to some estimates, for every 100 watts spent on running the servers, roughly another 50 watts is needed to cool them. are trying to attract cloud computing data centers.  In these countries, heat from the servers can be cheaply vented or used to help heat buildings, thus reducing the energy consumption of conventional heaters.









