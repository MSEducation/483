[[Probabilistic method]]

CATEGORIES: Combinatorics, Mathematical proofs, Probabilistic arguments

The probabilistic method is a nonconstructive method, primarily used in combinatorics and pioneered by Paul Erdős, for proving the existence of a prescribed kind of mathematical object. It works by showing that if one randomly chooses objects from a specified class, the probability that the result is of the prescribed kind is more than zero. Although the proof uses probability, the final conclusion is determined for certain, without any possible error.
This method has now been applied to other areas of mathematics such as number theory, linear algebra, and real analysis, as well as in computer science (e.g. randomized rounding), and information theory.

Introduction

If every object in a collection of objects fails to have a certain property, then the probability that a random object chosen from the collection has that property is zero. Turning this around, if the probability that the random object has the property is greater than zero, then this proves the existence of at least one object in the collection that has the property. It doesn't matter if the probability is vanishingly small; any positive probability will do.
Similarly, showing that the probability is (strictly) less than 1 can be used to prove the existence of an object that does not satisfy the prescribed properties.
Another way to use the probabilistic method is by calculating the expected value of some random variable. If it can be shown that the random variable can take on a value less than the expected value, this proves that the random variable can also take on some value greater than the expected value.
Common tools used in the probabilistic method include Markov's inequality, the Chernoff bound, and the Lovász local lemma.

Two examples due to Erdős

Although others before him proved theorems via the probabilistic method (for example, Szele's 1943 result that there exist tournaments containing a large number of Hamiltonian cycles), many of the most well known proofs using this method are due to Erdős. Indeed, the Alon-Spencer textbook on the subject has his picture on the cover to highlight the method's association with Erdős. The first example below describes one such result from 1947 that gives a proof of a lower bound for the Ramsey number .

First example

Suppose we have a complete graph on  vertices which is monochromatic (every edge colored the same color).
To do so, we color the graph randomly. Color each edge independently with probability  vertices as follows:
For any set  is simply the probability that all of the 
edges in  are the same color, 
(the factor of  comes because there are two possible colors).  
This holds true for any of the  is 
The sum of an expectation is the expectation of the sum (regardless of whether the variables are independent), so the expectation of the sum (the expected number of monochromatic -subgraphs) is 
Consider what happens if this value is less than .  Thus if 
some coloring fits our desired criterion, so by definition .
A peculiarity of this argument is that it is entirely nonconstructive.  Even though it proves (for example) that almost every coloring of the complete graph on -subgraph, it gives no explicit example of such a coloring. The problem of finding such a coloring has been open for more than 50 years.

Second example

A 1959 paper of Erdős (see reference cited below) addressed the following problem in graph theory: given positive integers ?
It can be shown that such a graph exists for any .  It can be shown that with positive probability, the following two properties hold:
Proof. Let  vertices is 
and each of them is present in . Hence by Markov's inequality we have 
Proof. Let . Clearly, we have 
when 
This result gives a hint as to why the computation of the chromatic number of a graph is so difficult: even when there are no local reasons (such as small cycles) for a graph to require many colors the chromatic number can still be arbitrarily large.






