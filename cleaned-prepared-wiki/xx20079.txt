[[Prosecutor's fallacy]]

CATEGORIES: Bayesian statistics, Logical fallacies, Forensic statistics, Misuse of statistics

The prosecutor's fallacy is a fallacy of statistical reasoning, typically used by the prosecution to argue for the guilt of a defendant during a criminal trial. Although it is named after prosecutors it is not specific to them, and some variants of the fallacy can be utilized by defense lawyers arguing for the innocence of their client.  At its heart the fallacy involves assuming that the prior probability of a random match is equal to the probability that the defendant is innocent. For instance, if a perpetrator is known to have the same blood type as a defendant and 10% of the population share that blood type; then to argue on that basis alone that the probability of the defendant being guilty is 90% makes the prosecutors's fallacy, in a very simple form.

Concept

The terms "prosecutor's fallacy" and "defense attorney's fallacy" were originated by William C. Thompson and Edward Schumann in 1987. The fallacy can arise from multiple testing, such as when evidence is compared against a large database.  The size of the database elevates the likelihood of finding a match by pure chance alone; i.e., DNA evidence is soundest when a match is found after a single directed comparison because the existence of matches against a large database where the test sample is of poor quality may be less unlikely by mere chance.
The basic fallacy results from misunderstanding conditional probability and neglecting the prior odds of a defendant being guilty before that evidence was introduced. When a prosecutor has collected some evidence (for instance a DNA match) and has an expert testify that the probability of finding this evidence if the accused were innocent is tiny, the fallacy occurs if it is concluded that the probability of the accused being innocent must be comparably tiny. If the DNA match is used to confirm guilt which is otherwise suspected then it is indeed strong evidence.  However if the DNA evidence is the sole evidence against the accused and the accused was picked out of a large database of DNA profiles, the odds of the match being made at random may be reduced, and less damaging to the defendant. The odds in this scenario do not relate to the odds of being guilty, they relate to the odds of being picked at random.

Examples of prosecutor's fallacies

Conditional probability

Argument from rarity – Consider this case: a lottery winner is accused of cheating, based on the improbability of winning. At the trial, the prosecutor calculates the (very small) probability of winning the lottery without cheating and argues that this is the chance of innocence. The logical flaw is that the prosecutor has failed to account for the large number of people who play the lottery.
Berkson's paradox – mistaking conditional probability for unconditional – led to several wrongful convictions of British mothers, accused of murdering two of their children in infancy, where the primary evidence against them was the statistical improbability of two children dying accidentally in the same household (under "Meadow's law"). Though multiple accidental (SIDS) deaths are rare, so are multiple murders; with only the facts of the deaths as evidence, it is the ratio of these (prior) improbabilities that gives the correct "posterior probability" of murder.

Multiple testing

In another scenario, a crime-scene DNA sample is compared against a database of 20,000 men.  A match is found, that man is accused and at his trial, it is testified that the probability that two DNA profiles match by chance is only 1 in 10,000. This does not mean the probability that the suspect is innocent is 1 in 10,000.  Since 20,000 men were tested, there were 20,000 opportunities to find a match by chance. 
Even if none of the men in the database left the crime-scene DNA, a match by chance to an innocent is more likely than not. The chance of getting at least one match among the records is: 
So, this evidence alone is an uncompelling data dredging result. If the culprit was in the database then he and one or more other men would probably be matched; in either case, it would be a fallacy to ignore the number of records searched when weighing the evidence. "Cold hits" like this on DNA databanks are now understood to require careful presentation as trial evidence.

Mathematical analysis

Finding a person innocent or guilty can be viewed in mathematical terms as a form of binary classification.
If E is the observed evidence, and I stands for "accused is innocent" then consider the conditional probabilities: 
With forensic evidence, P(E|I) is tiny. The prosecutor wrongly concludes that P(I|E) is comparatively tiny. (The Lucia de Berk prosecution is accused of exactly this error, for example.) In fact, P(E|I) and P(I|E) are quite different; using Bayes' theorem:
Where:
The prosecutor is claiming a negligible chance of innocence, given the evidence, implying Odds(I|E) -> P(I|E), or that:
A prosecutor conflating P(I|E) with P(E|I) makes a technical error whenever Odds(I) >> 1. This may be a harmless error if P(I|E) is still negligible, but it is especially misleading otherwise (mistaking low statistical significance for high confidence).

Legal impact

Though the prosecutor's fallacy typically happens by mistake,

Defense attorney's fallacy

Suppose there is a one-in-a-million chance of a match given that the accused is innocent. The prosecutor says this means there is only a one-in-a-million chance of innocence. But if everyone in a community of 10 million people is tested, one expects 10 matches even if all are innocent. The defense fallacy would be to reason that "10 matches were expected, so the accused is no more likely to be guilty than any of the other matches, thus the evidence suggests a 90% chance that the accused is innocent." and "As such, this evidence is irrelevant." The first part of the reasoning would be correct only in the case where there is no further evidence pointing to the defendant. On the second part, Thompson & Schumann wrote that the evidence should still be highly relevant because it "drastically narrows the group of people who are or could have been suspects, while failing to exclude the defendant" (page 171).

Possible examples of fallacious defense arguments

Some authors have cited defense arguments in the O. J. Simpson murder trial as an example of this fallacy regarding the context in which the accused had been brought to court: crime scene blood matched Simpson's with characteristics shared by 1 in 400 people. The defense argued that a football stadium could be filled with Angelenos matching the sample and that the figure of 1 in 400 was useless., & Vignaux, G. A. (1995).  Interpreting evidence: Evaluating forensic evidence in the courtroom.  Chichester: John Wiley and Sons. Kim (2009).  Criminal Investigative Failures.  CRC Press Taylor & Francis Group.
Also at the O. J. Simpson murder trial, the prosecution presented evidence that Simpson had been violent toward his wife, while the defense argued that there was only one woman murdered for every 2500 women who were subjected to spousal abuse, and that any history of Simpson being violent toward his wife was irrelevant to the trial. However, some regard the reasoning behind the defense's calculation as fallacious. According to author Gerd Gigerenzer, the correct probability requires the context—that Simpson's wife had not only been subjected to domestic violence, but subjected to domestic violence and murdered—to be taken into account. Gigerenzer writes "the chances that a batterer actually murdered his partner, given that she has been killed, is about 8 in 9 or approximately 90%"., Reckoning with Risk: Learning to Live with Uncertainty, Penguin, (2003)

The Sally Clark case

Sally Clark, a British woman who was accused in 1998 of having killed her first child at 11 weeks of age, then conceived another child and allegedly killed it at 8 weeks of age. The prosecution had expert witness Sir Roy Meadow testify that the probability of two children in the same family dying from SIDS is about 1 in 73 million. That was much less frequent than the actual rate measured in historical data – Meadow estimated it from single-SIDS death data, and the assumption that the probability of such deaths should be uncorrelated between infants.g. non-smoking). In this sub-population he estimated the probability of a single death at 1 in 8,500. See: 
. Professor Ray Hill questioned even this first step (1/8,500 vs 1/1,300) in two ways: firstly, on the grounds that it was biased, excluding those factors that increased risk (especially that both children were boys) and (more importantly) because reductions in SIDS risk factors will proportionately reduce murder risk factors, so that the relative frequencies of Münchausen syndrome by proxy and SIDS will remain in the same ratio as in the general population: 

[/ref]
Meadow acknowledged that 1-in-73 million is not an impossibility, but argued that such accidents would happen "once every hundred years" and that, in a country of 15 million 2-child families, it is vastly more likely that the double-deaths are due to Münchausen syndrome by proxy than to such a rare accident. However, there is good reason to suppose that the likelihood of a death from SIDS in a family is significantly greater if a previous child has already died in these circumstances (a genetic predisposition to SIDS is likely to invalidate that assumed statistical independenceGene find casts doubt on double 'cot death' murders.  The Observer; July 15, 2001) making some families more susceptible to SIDS and the error an outcome of the ecological fallacy.
1-in-73 million greatly underestimated the chance of two successive accidents, but, even if that assessment were accurate, the court seems to have missed the fact that the 1-in-73 million number meant nothing on its own. As an a priori probability, it should have been weighed against the a priori probabilities of the alternatives. Given that two deaths had occurred, one of the following explanations must be true, and all of them are a priori extremely improbable:
It's unclear that an estimate for the second possibility was ever proposed during the trial, or that the comparison of the first two probabilities was understood to be the key estimate to make in the statistical analysis assessing the prosecution's case against the case for innocence.
Mrs. Clark was convicted in 1999, resulting in a press release by the Royal Statistical Society which pointed out the mistakes.
In 2002, Ray Hill (Mathematics professor at Salford) attempted to accurately compare the chances of these two possible explanations; he concluded that successive accidents are between 4.5 and 9 times more likely than are successive murders, so that the a priori odds of Clark's guilt were between 4.5 to 1 and 9 to 1 against.The uncertainty in this range is mainly driven by uncertainty in the likelihood of killing a second child, having killed a first, see: 
A higher court later quashed Sally Clark's conviction, on other grounds, on 29 January 2003. 
Sally Clark, a practising solicitor before the conviction, developed a number of serious psychiatric problems including serious alcohol dependency and died in 2007 from alcohol poisoning.








