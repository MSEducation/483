[[Chaos theory]]

CATEGORIES: Chaos theory

Chaos theory is a field of study in mathematics, with applications in several disciplines including meteorology, sociology, physics, engineering, economics, biology, and philosophy. Chaos theory studies the behavior of dynamical systems that are highly sensitive to initial conditions—a paradigm popularly referred to as the butterfly effect. Small differences in initial conditions (such as those due to rounding errors in numerical computation) yield widely diverging outcomes for such dynamical systems, rendering long-term prediction impossible in general.
 
 Chaos: When the present determines the future, but the approximate present does not approximately determine the future.

Chaotic behavior can be observed in many natural systems, such as weather. This behavior can be studied through analysis of a chaotic mathematical model, or through analytical techniques such as recurrence plots and Poincaré maps.

Chaotic dynamics

In common usage, "chaos" means "a state of disorder".Definition of 
The requirement for sensitive dependence on initial conditions implies that there is a set of initial conditions of positive measure that do not converge to a cycle of any length.

Sensitivity to initial conditions

Sensitivity to initial conditions means that each point in a chaotic system is arbitrarily closely approximated by other points with significantly different future paths, or trajectories. Thus, an arbitrarily small change, or perturbation, of the current trajectory may lead to significantly different future behavior.
It has been shown that in some cases the last two properties in the list above actually imply sensitivity to initial conditions, It is interesting that the most practically significant property, that of sensitivity to initial conditions, is redundant in the definition, being implied by two (or for intervals, one) purely topological properties, which are therefore of greater interest to mathematicians.
Sensitivity to initial conditions is popularly known as the "butterfly effect", so called because of the title of a paper given by Edward Lorenz in 1972 to the American Association for the Advancement of Science in Washington, D.C. entitled Predictability: Does the Flap of a Butterfly's Wings in Brazil set off a Tornado in Texas?. The flapping wing represents a small change in the initial condition of the system, which causes a chain of events leading to large-scale phenomena. Had the butterfly not flapped its wings, the trajectory of the system might have been vastly different.
A consequence of sensitivity to initial conditions is that if we start with only a finite amount of information about the system (as is usually the case in practice), then beyond a certain time the system will no longer be predictable. This is most familiar in the case of weather, which is generally predictable only about a week ahead. Of course this does not mean that we cannot say anything about events far in the future; there are some restrictions on the system. With weather, we know that the temperature will never reach 100 degrees Celsius or fall to -130 degrees Celsius on earth, but we are not able to say exactly what day we will have the hottest temperature of the year.
where λ is the Lyapunov exponent.  The rate of separation can be different for different orientations of the initial separation vector. Thus, there is a whole spectrum of Lyapunov exponents — the number of them is equal to the number of dimensions of the phase space. It is common to just refer to the largest one, for example, to the maximal Lyapunov exponent (MLE), because it determines the overall predictability of the system. A positive MLE is usually taken as an indication that the system is chaotic.
There are also measure-theoretic conditions (discussed in ergodic theory) such as mixing or being a K-system which relate to sensitivity of initial conditions and chaos.

Topological mixing

Topological mixing (or topological transitivity) means that the system will evolve over time so that any given region or open set of its phase space will eventually overlap with any other given region. This mathematical concept of "mixing" corresponds to the standard intuition, and the mixing of colored dyes or fluids is an example of a chaotic system.
Topological mixing is often omitted from popular accounts of chaos, which equate chaos with only sensitivity to initial conditions. However, sensitive dependence on initial conditions alone does not give chaos. For example, consider the simple dynamical system produced by repeatedly doubling an initial value. This system has sensitive dependence on initial conditions everywhere, since any pair of nearby points will eventually become widely separated. However, this example has no topological mixing, and therefore has no chaos. Indeed, it has extremely simple behavior: all points except 0 will tend to positive or negative infinity.

Density of periodic orbits

Sharkovskii's theorem is the basis of the Li and Yorke (1975) proof that any one-dimensional system that exhibits a regular cycle of period three will also display regular cycles of every other length as well as completely chaotic orbits.

Strange attractors

Some dynamical systems, like the one-dimensional logistic map defined by x → 4 x (1 – x), are chaotic everywhere, but in many cases chaotic behavior is found only in a subset of phase space. The cases of most interest arise when the chaotic behavior takes place on an attractor, since then a large set of initial conditions will lead to orbits that converge to this chaotic region.
An easy way to visualize a chaotic attractor is to start with a point in the basin of attraction of the attractor, and then simply plot its subsequent orbit. Because of the topological transitivity condition, this is likely to produce a picture of the entire final attractor, and indeed both orbits shown in the figure on the right give a picture of the general shape of the Lorenz attractor.  This attractor results from a simple three-dimensional model of the Lorenz weather system. The Lorenz attractor is perhaps one of the best-known chaotic system diagrams, probably because it was not only one of the first, but it is also one of the most complex and as such gives rise to a very interesting pattern, that with a little imagination, looks like the wings of a butterfly.
Unlike fixed-point attractors and limit cycles, the attractors that arise from chaotic systems, known as strange attractors, have great detail and complexity.  Strange attractors occur in both continuous dynamical systems (such as the Lorenz system) and in some discrete systems (such as the Hénon map). Other discrete dynamical systems have a repelling structure called a Julia set which forms at the boundary between basins of attraction of fixed points – Julia sets can be thought of as strange repellers. Both strange attractors and Julia sets typically have a fractal structure, and a fractal dimension can be calculated for them.

Minimum complexity of a chaotic system

Discrete chaotic systems, such as the logistic map, can exhibit strange attractors whatever their dimensionality. In contrast, for continuous dynamical systems, the Poincaré–Bendixson theorem shows that a strange attractor can only arise in three or more dimensions.  Finite-dimensional linear systems are never chaotic; for a dynamical system to display chaotic behavior, it has to be either nonlinear or infinite-dimensional.
The Poincaré–Bendixson theorem states that a two-dimensional differential equation has very regular behavior. The Lorenz attractor discussed above is generated by a system of three differential equations with a total of seven terms on the right-hand side, five of which are linear terms and two of which are quadratic (and therefore nonlinear). Another well-known chaotic attractor is generated by the Rossler equations with seven terms on the right-hand side, only one of which is (quadratic) nonlinear. Sprott  showed that, at least for dissipative and conservative quadratic systems, three-dimensional quadratic systems with only three or four terms on the right-hand side cannot exhibit chaotic behavior.  The reason is, simply put, that solutions to such systems are asymptotic to a two-dimensional surface and therefore solutions are well behaved.
While the Poincaré–Bendixson theorem means that a continuous dynamical system on the Euclidean plane cannot be chaotic, two-dimensional continuous systems with non-Euclidean geometry can exhibit chaotic behavior.  Perhaps surprisingly, chaos may occur also in linear systems, provided they are infinite-dimensional.  A theory of linear chaos is being developed in a branch of mathematical analysis known as functional analysis.

Spontaneous Order

Under the right conditions chaos will spontaneously evolve into a lockstep pattern. In the Kuramoto model, four conditions suffice to produce synchronization in a chaotic system.
Examples include the coupled oscillation of Christiaan Huygens' pendulums, fireflies, neurons, the London Millenium Bridge resonance, and large arrays of Josephson junctions. 

History

An early proponent of chaos theory was Henri Poincaré. In the 1880s, while studying the three-body problem, he found that there can be orbits that are nonperiodic, and yet not forever increasing nor approaching a fixed point. Hadamard was able to show that all trajectories are unstable, in that, all particle trajectories diverge exponentially from one another, with a positive Lyapunov exponent.
Much of the earlier theory was developed almost entirely by mathematicians under the name of ergodic theory. Later studies, also on the topic of nonlinear differential equations, were carried out by George David Birkhoff,George D. Birkhoff, Dynamical Systems, vol. 9 of the American Mathematical Society Colloquium Publications (Providence, Rhode Island: American Mathematical Society, 1927)  Although chaotic planetary motion had not been observed, experimentalists had encountered turbulence in fluid motion and nonperiodic oscillation in radio circuits without the benefit of a theory to explain what they were seeing.
Despite initial insights in the first half of the twentieth century, chaos theory became formalized as such only after mid-century, when it first became evident to some scientists that linear theory, the prevailing system theory at that time, simply could not explain the observed behavior of certain experiments like that of the logistic map. What had been attributed to measure imprecision and simple "noise" was considered by chaos theorists as a full component of the studied systems.
The main catalyst for the development of chaos theory was the electronic computer. Much of the mathematics of chaos theory involves the repeated iteration of simple mathematical formulas, which would be impractical to do by hand. Electronic computers made these repeated calculations practical, while figures and images made it possible to visualize these systems. As a graduate student in Chihiro Hayashi's laboratory at Kyoto University, Yoshisuke Ueda was experimenting with analog computers and noticed, on Nov. 27, 1961, what he called "randomly transitional phenomena".  Yet his advisor did not agree with his conclusions at the time, and did not allow him to report his findings until 1970.
An early pioneer of the theory was Edward Lorenz whose interest in chaos came about accidentally through his work on weather prediction in 1961. Lorenz's discovery, which gave its name to Lorenz attractors, showed that even detailed atmospheric modelling cannot, in general, make precise long-term weather predictions.
In 1963, Benoît Mandelbrot found recurring patterns at every scale in data on cotton prices.
In December 1977, the New York Academy of Sciences organized the first symposium on Chaos, attended by David Ruelle, Robert May, James A. Yorke (coiner of the term "chaos" as used in mathematics), Robert Shaw, and the meteorologist Edward Lorenz. The following year, independently Pierre Coullet and Charles Tresser with the article "Iterations d'endomorphismes et groupe de renormalisation" and Mitchell Feigenbaum with the article "Quantitative Universality for a Class of Nonlinear Transformations" described logistic maps. "Iterations d'endomorphismes et groupe de renormalisation." Le Journal de Physique Colloques 39.C5 (1978): C5-25  They notably discovered the universality in chaos, permitting an application of chaos theory to many different phenomena.
In 1979, Albert J. Libchaber, during a symposium organized in Aspen by Pierre Hohenberg, presented his experimental observation of the bifurcation cascade that leads to chaos and turbulence in Rayleigh–Bénard convection systems. He was awarded the Wolf Prize in Physics in 1986 along with Mitchell J. Feigenbaum "for his brilliant experimental demonstration of the transition to turbulence and chaos in dynamical systems".
In 1986, the New York Academy of Sciences co-organized with the National Institute of Mental Health and the Office of Naval Research the first important conference on chaos in biology and medicine. There, Bernardo Huberman presented a mathematical model of the eye tracking disorder among schizophrenics. This led to a renewal of physiology in the 1980s through the application of chaos theory, for example, in the study of pathological cardiac cycles.
In 1987, Per Bak, Chao Tang and Kurt Wiesenfeld published a paper in Physical Review Letters describing for the first time self-organized criticality (SOC), considered to be one of the mechanisms by which complexity arises in nature.
Alongside largely lab-based approaches such as the Bak–Tang–Wiesenfeld sandpile, many other investigations have focused on large-scale natural or social systems that are known (or suspected) to display scale-invariant behavior. Although these approaches were not always welcomed (at least initially) by specialists in the subjects examined, SOC has nevertheless become established as a strong candidate for explaining a number of natural phenomena, including earthquakes (which, long before SOC was discovered, were known as a source of scale-invariant behavior such as the Gutenberg–Richter law describing the statistical distribution of earthquake sizes, and the Omori law describing the frequency of aftershocks), solar flares, fluctuations in economic systems such as financial markets (references to SOC are common in econophysics), landscape formation, forest fires, landslides, epidemics, and biological evolution (where SOC has been invoked, for example, as the dynamical mechanism behind the theory of "punctuated equilibria" put forward by Niles Eldredge and Stephen Jay Gould). Given the implications of a scale-free distribution of event sizes, some researchers have suggested that another phenomenon that should be considered an example of SOC is the occurrence of wars. These investigations of SOC have included both attempts at modelling (either developing new models or adapting existing ones to the specifics of a given natural system), and extensive data analysis to determine the existence and/or characteristics of natural scaling laws.
In the same year, James Gleick published Chaos: Making a New Science, which became a best-seller and introduced the general principles of chaos theory as well as its history to the broad public, though his history under-emphasized important Soviet contributions. At first the domain of work of a few, isolated individuals, chaos theory progressively emerged as a transdisciplinary and institutional discipline, mainly under the name of nonlinear systems analysis. Alluding to Thomas Kuhn's concept of a paradigm shift exposed in The Structure of Scientific Revolutions (1962), many "chaologists" (as some described themselves) claimed that this new theory was an example of such a shift, a thesis upheld by Gleick.
The availability of cheaper, more powerful computers broadens the applicability of chaos theory. Currently, chaos theory continues to be a very active area of research,Motter A. E. and  Campbell D. K., Chaos at fifty, Phys. Today 66(5), 27-33 (2013). involving many different disciplines (mathematics, topology, physics, social systems, population modeling, biology, meteorology, astrophysics, information theory, computational neuroscience, etc.).

Distinguishing random from chaotic data

It can be difficult to tell from data whether a physical or other observed process is random or chaotic, because in practice no time series consists of a pure "signal". There will always be some form of corrupting noise, even if it is present as round-off or truncation error. Thus any real time series, even if mostly deterministic, will contain some randomness.
All methods for distinguishing deterministic and stochastic processes rely on the fact that a deterministic system always evolves in the same way from a given starting point. Thus, given a time series to test for determinism, one can
Define the error as the difference between the time evolution of the test state and the time evolution of the nearby state. A deterministic system will have an error that either remains small (stable, regular solution) or increases exponentially with time (chaos). A stochastic system will have a randomly distributed error.
Essentially, all measures of determinism taken from time series rely upon finding the closest states to a given test state (e.g., correlation dimension, Lyapunov exponents, etc.). To define the state of a system, one typically relies on phase space embedding methods.
Typically one chooses an embedding dimension and investigates the propagation of the error between two nearby states. If the error looks random, one increases the dimension. If the dimension can be increased to obtain a deterministically looking error, then analysis is done. Though it may sound simple, one complication is that as the dimension increases, the search for a nearby state requires a lot more computation time and a lot of data (the amount of data required increases exponentially with embedding dimension) to find a suitably close candidate. If the embedding dimension (number of measures per state) is chosen too small (less than the "true" value), deterministic data can appear to be random, but in theory there is no problem choosing the dimension too large – the method will work.
When a non-linear deterministic system is attended by external fluctuations, its trajectories present serious and permanent distortions. Furthermore, the noise is amplified due to the inherent non-linearity and reveals totally new dynamical properties. Statistical tests attempting to separate noise from the deterministic skeleton or inversely isolate the deterministic part risk failure. Things become worse when the deterministic component is a non-linear feedback system.
The question of how to distinguish deterministic chaotic systems from stochastic systems has also been discussed in philosophy. It has been shown that they might be
observationally equivalent.

Applications

Chaos theory was born from observing weather patterns, but it has become applicable to a variety of other situations. Some areas benefiting from chaos theory today are geology, mathematics, microbiology, biology, computer science, economics, psychology, and robotics. A few categories are listed below with examples, but this is by no means a comprehensive list as new applications are appearing every day.

Computer Science

Chaos theory is not new to computer science and has been used for many years in cryptography. One type of encryption, secret key or symmetric key, relies on diffusion and confusion, which is modeled well by chaos theory.

Biology

For over a hundred years, biologists have been keeping track of populations of different species with population models. Most models are deterministic systems, but recently scientists have been able to implement chaotic models in certain populations.

Other Areas

In chemistry, predicting gas solubility is essential to manufacturing polymers, but models using particle swarm optimization (PSO) tend to converge to the wrong points. An improved version of PSO has been created by introducing chaos, which keeps the simulations from getting stuck.
Chaos theory can even be applied outside of the natural sciences. By adapting a model of career counseling to include a chaotic interpretation of the relationship between employees and the job market, better suggestions can be made to people struggling with career decisions.

Cultural references

Chaos theory has been mentioned in movies and works of literature, including Michael Crichton's novels Jurassic Park and The Lost World, as well as their film adaptations; the films Chaos and The Butterfly Effect; the Indian movie "Dasavatharam" starring Kamal Hassan; the sitcoms Community and Spaced, Tom Stoppard's play Arcadia and the video games Tom Clancy's Splinter Cell: Chaos Theory and Assassin's Creed. In the computer game The Secret World the Dragon secret society uses chaos theory to achieve political dominance. Ray Bradbury's short story "A Sound of Thunder" explores chaos theory.  Chaos theory was the subject of the BBC documentaries High Anxieties — The Mathematics of Chaos directed by David Malone, and The Secret Life of Chaos presented by Jim Al-Khalili. Cultural permutations of chaos theory are explored in the book The Unity of Nature by Alan Marshall (Imperial College Press, London, 2002).





Scientific literature

Articles

Textbooks

Semitechnical and popular works




